{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_siren_and_show_inages.ipynb","provenance":[],"collapsed_sections":["laFJz7Zu9xaI","Yjsx1yjd9zwR","j62f3cAY-B0E","dC1utPkx-WDa","5K2_rjcLQ7r5","Gb19GFz--hg1","73gHw67dQB0v"],"mount_file_id":"1EkWvZCwSs_XglEyzSmTBxLuPcl6SWhW0","authorship_tag":"ABX9TyNH3Z+pz1Q+RbVJjvMx4o+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KbBwYEm396cI"},"source":["# !pip install visdom"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laFJz7Zu9xaI"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"Yjsx1yjd9zwR"},"source":["### Standard Imports"]},{"cell_type":"code","metadata":{"id":"IHt9ZFqF9s6w"},"source":["from __future__ import print_function\n","from __future__ import division\n","\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import argparse\n","import copy\n","import datetime\n","import os\n","import random\n","import skimage\n","import shutil\n","import time\n","# import visdom\n","import warnings"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j62f3cAY-B0E"},"source":["### Torch imports"]},{"cell_type":"code","metadata":{"id":"dIlC57oD-EQ8"},"source":["import torch\n","import torchvision\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dC1utPkx-WDa"},"source":["## Set seeds for repeatability"]},{"cell_type":"code","metadata":{"id":"b4wxatd1-Z0P","executionInfo":{"status":"ok","timestamp":1601545343301,"user_tz":-120,"elapsed":1779,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"d52fb390-2523-47f6-b133-a6f2f42411bd","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PyTorch Version:  1.6.0+cu101\n","Torchvision Version:  0.7.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bMjJBG5a-eIi"},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","feature_extract = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5K2_rjcLQ7r5"},"source":["## Custom Argparser"]},{"cell_type":"code","metadata":{"id":"wybP1xvhQ9rw","executionInfo":{"status":"ok","timestamp":1601545343302,"user_tz":-120,"elapsed":1763,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"66fe9011-66d8-47c5-9787-b08e1db46c3f","colab":{"base_uri":"https://localhost:8080/"}},"source":["parser = argparse.ArgumentParser(description='PyTorch SirenNet Training')\n","\"\"\"parser.add_argument('data', metavar='DIR',\n","                    help='path to dataset')\"\"\"\n","parser.add_argument('--epochs', default=90, type=int, metavar='N',\n","                    help='number of total epochs to run')\n","parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n","                    help='manual epoch number (useful on restarts)')\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    metavar='N',\n","                    help='mini-batch size (default: 256), this is the total '\n","                         'batch size of all GPUs on the current node when '\n","                         'using Data Parallel or Distributed Data Parallel')\n","parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n","                    metavar='LR', help='initial learning rate', dest='lr')\n","parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n","                    help='momentum')\n","parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n","                    metavar='W', help='weight decay (default: 1e-4)',\n","                    dest='weight_decay')\n","parser.add_argument('-p', '--print-freq', default=10, type=int,\n","                    metavar='N', help='print frequency (default: 10)')\n","parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n","                    help='evaluate model on validation set')\n","parser.add_argument('--seed', default=None, type=int,\n","                    help='seed for initializing training. ')\n","parser.add_argument('--gpu', default=None, type=int,\n","                    help='GPU id to use.')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--gpu'], dest='gpu', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='GPU id to use.', metavar=None)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Gb19GFz--hg1"},"source":["## Set device - either gpu:0 or cpu"]},{"cell_type":"code","metadata":{"id":"e_PE_VJ7-hHT","executionInfo":{"status":"ok","timestamp":1601545343302,"user_tz":-120,"elapsed":1753,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4abf95f4-f413-46c6-bdf2-0f4499d1ef33","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Detect if we have a GPU available\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = (torch.device('cuda:0') if torch.cuda.is_available()\n","    else torch.device('gpu'))\n","print(f\"Training on device {device}.\")\n","print(f\"# cuda device: {torch.cuda.device_count()}\")\n","print(f\"Id current device: {torch.cuda.current_device()}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training on device cuda:0.\n","# cuda device: 1\n","Id current device: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73gHw67dQB0v"},"source":["## Siren Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"_mhTSW7gQGhQ"},"source":["# Siren's architecture Hyper-params\n","in_features = 2\n","out_features = 1\n","sidelength = 128\n","hidden_layers = 3\n","\n","# Training phase's Hyper-params\n","learning_rate = 1e-4\n","\n","# Displaying Images\n","steps_til_summary = 10\n","\n","image_path = \"/content/drive/My Drive/Siren Deep Learning Analyses/testsets/BSD68/test001.png\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ef9EGPkzA_IG"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"7AxqxasEBCN6"},"source":["def get_mgrid(sidelen, dim=2):\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfO1Yw9sFIjU"},"source":["def show_images(model_output, coords):\n","    img_grad = gradient(model_output, coords)\n","    img_laplacian = laplace(model_output, coords)\n","\n","    fig, axes = plt.subplots(1,3, figsize=(18,6))\n","    axes[0].imshow(model_output.cpu().view(sidelength, sidelength).detach().numpy())\n","    axes[1].imshow(img_grad.norm(dim=-1).cpu().view(sidelength, sidelength).detach().numpy())\n","    axes[2].imshow(img_laplacian.cpu().view(sidelength, sidelength).detach().numpy())\n","    plt.show()\n","    pass\n","\n","def basic_traininig_loop(optimizer, criterion, model, model_input, ground_truth, total_steps, steps_til_summary = 10):\n","    \n","    train_acc_history = [] # val_acc_history = []\n","    train_loss_history = [] # val_loss_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    model.train()  # Set model to training mode\n","\n","    for step in range(total_steps):\n","        # print('Epoch {}/{}'.format(step, total_steps - 1))\n","        # print('-' * 10)\n","\n","        model_output, coords = model(model_input)\n","        loss = criterion(model_output, ground_truth)  \n","        # loss = ((model_output - ground_truth)**2).mean()\n","    \n","        if not step % steps_til_summary:\n","            print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","            show_images(model_output, coords)\n","            pass\n","        \n","        train_loss_history.append(loss)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        pass\n","    \n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    # create history as python dictionary\n","    keys_history_list = \"train_loss\".split(\",\")\n","    values_history_list = [train_loss_history]\n","\n","    history = dict(zip(keys_history_list, values_history_list))\n","\n","    return model, history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFniZVE-SaKm"},"source":["def plane_traininig_loop(optimizer, criterion, model, model_input, ground_truth, total_steps):\n","    \n","    train_acc_history = [] # val_acc_history = []\n","    train_loss_history = [] # val_loss_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    model.train()  # Set model to training mode\n","\n","    phase = 'train'\n","    for step in range(total_steps):\n","        print('Epoch {}/{}'.format(step, total_steps - 1))\n","        print('-' * 10)\n","\n","        model_output, coords = model(model_input)    \n","        loss = criterion(model_output, ground_truth)\n","        # loss = ((model_output - ground_truth)**2).mean()\n","        \n","\n","        print('{} Loss: {:.4f}'.format(phase, loss))\n","        train_loss_history.append(loss)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        pass\n","    \n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    # create history as python dictionary\n","    keys_history_list = \"train_loss\".split(\",\")\n","    values_history_list = [train_loss_history]\n","\n","    history = dict(zip(keys_history_list, values_history_list))\n","\n","    return model, history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgE6UqEN-zhD"},"source":["## Siren classes\n","\n","Now, we code up the sine layer, which will be the basic building block of SIREN. This is a much more concise implementation than the one in the main code, as here, we aren't concerned with the baseline comparisons."]},{"cell_type":"code","metadata":{"id":"VyOSBFpp-_f6"},"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)      \n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    def forward_with_intermediate(self, input): \n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):\n","            if isinstance(layer, SineLayer):\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTJvYEF__NcU"},"source":["And finally, differential operators that allow us to leverage autograd to compute gradients, the laplacian, etc."]},{"cell_type":"code","metadata":{"id":"LnGeVmLq_M62"},"source":["def laplace(y, x):\n","    grad = gradient(y, x)\n","    return divergence(grad, x)\n","\n","\n","def divergence(y, x):\n","    div = 0.\n","    for i in range(y.shape[-1]):\n","        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n","    return div\n","\n","\n","def gradient(y, x, grad_outputs=None):\n","    if grad_outputs is None:\n","        grad_outputs = torch.ones_like(y)\n","    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n","    return grad"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lptl7BN5-1qd"},"source":["## Experiments\n","\n","For the image fitting and poisson experiments, we'll use the classic cameraman image."]},{"cell_type":"code","metadata":{"id":"ruFr5hf1_V28"},"source":["def printImageAttributes(imageObject, imagePath):\n","\n","    # Retrieve the attributes of the image\n","\n","    fileFormat      = imageObject.format        # Format of the image\n","    imageMode       = imageObject.mode          # Mode of the image\n","    imageSize       = imageObject.size          # Size of the image - tupe of (width, height)\n","    colorPalette    = imageObject.palette       # Palette used in the image\n","\n","    # Print the attributes of the image\n","    print(\"Attributes of image:%s\"%imagePath)\n","\n","    print(\"The file format of the image is:%s\"%fileFormat)\n","\n","    print(\"The mode of the image is:%s\"%imageMode)\n","\n","    print(\"The size of the image is:width %d pixels,height %d pixels\"%imageSize)\n","\n","    print(\"Color palette used in image:%s\"%colorPalette)\n","\n","    print(\"Keys from image.info dictionary:%s\")\n","\n","    for key, value in imageObject.info.items() :\n","        print(key)\n","        print(value)\n","        pass\n","    pass\n","\n","def get_cameraman_tensor(sidelength):\n","    print(type(skimage.data.camera()))\n","    img = Image.fromarray(skimage.data.camera())\n","    \n","    print(type(img))\n","    printImageAttributes(img, \"cameraman\")\n","\n","    transform = Compose([\n","        Resize(sidelength),\n","        ToTensor(),\n","        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","    ])\n","    img = transform(img)\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-wC41Ve_yeW"},"source":["### Fitting an image\n","\n","First, let's simply fit that image!\n","\n","We seek to parameterize a greyscale image $f(x)$ with pixel coordinates $x$ with a SIREN $\\Phi(x)$.\n","\n","That is we seek the function $\\Phi$ such that: $\\mathcal{L}=\\int_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x}$ is minimized, in which $\\Omega$ is the domain of the image.\n","\n","We write a little datast that does nothing except calculating per-pixel coordinates:"]},{"cell_type":"code","metadata":{"id":"2dQFpki5_x-j"},"source":["class ImageFitting(Dataset):\n","    def __init__(self, sidelength, image_path = None):\n","        super().__init__()\n","        if image_path is None:\n","            img = get_cameraman_tensor(sidelength)\n","        else:\n","            imag = Image.open(image_path)\n","            imag = imag.resize((sidelength, sidelength))\n","            printImageAttributes(imag, image_path)\n","            # imag = np.asarray(imag)\n","            transform = Compose([\n","                Resize(sidelength),\n","                ToTensor(),\n","                Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","            ])\n","            img = transform(imag)\n","            pass\n","        \n","        print(type(img))\n","        print(img.size())\n","\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","        pass\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):    \n","        if idx > 0: raise IndexError\n","            \n","        return self.coords, self.pixels\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxxukLZsAam-"},"source":["Let's instantiate the dataset and our Siren. As pixel coordinates are 2D, the siren has 2 input features, and since the image is grayscale, it has one output channel."]},{"cell_type":"code","metadata":{"id":"eLo8jrPEki6-","executionInfo":{"status":"ok","timestamp":1601546001114,"user_tz":-120,"elapsed":917,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"3907366a-70bf-41e1-f584-8bfbbb13ccd4","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["cameraman = ImageFitting(sidelength, image_path = image_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Attributes of image:/content/drive/My Drive/Siren Deep Learning Analyses/testsets/BSD68/test001.png\n","The file format of the image is:None\n","The mode of the image is:L\n","The size of the image is:width 128 pixels,height 128 pixels\n","Color palette used in image:None\n","Keys from image.info dictionary:%s\n","<class 'torch.Tensor'>\n","torch.Size([1, 128, 128])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OicGFXCfisza"},"source":["# cameraman = ImageFitting(sidelength)\n","dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RviAw5djAwi","executionInfo":{"status":"ok","timestamp":1601546012370,"user_tz":-120,"elapsed":434,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"5ae2aa86-4057-4208-a68d-0cc865a6c15f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(dataloader)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"diwXkIIKAYZr","executionInfo":{"status":"ok","timestamp":1601546013737,"user_tz":-120,"elapsed":538,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"1c1a9515-afb4-4619-b057-347e488137fe","colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["img_siren = Siren(\n","    in_features = in_features,\n","    out_features = out_features,\n","    hidden_features = sidelength, \n","    hidden_layers = hidden_layers,\n","    outermost_linear=True)\n","img_siren.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Siren(\n","  (net): Sequential(\n","    (0): SineLayer(\n","      (linear): Linear(in_features=2, out_features=128, bias=True)\n","    )\n","    (1): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (2): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (3): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (4): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"CtzjKp8yLTfY","executionInfo":{"status":"ok","timestamp":1601546015962,"user_tz":-120,"elapsed":540,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"01e741bd-3de1-4d3c-825f-6e1ba789af50","colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["model = img_siren.to(device)\n","\n","numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","print(model)\n","print(sum(numel_list), numel_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Siren(\n","  (net): Sequential(\n","    (0): SineLayer(\n","      (linear): Linear(in_features=2, out_features=128, bias=True)\n","    )\n","    (1): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (2): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (3): SineLayer(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (4): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")\n","50049 [256, 128, 16384, 128, 16384, 128, 16384, 128, 128, 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i4SaZKU4AfUJ"},"source":["\n","We now fit Siren in a simple training loop. Within only hundreds of iterations, the image and its gradients are approximated well."]},{"cell_type":"code","metadata":{"id":"X3USwqBKIy_q","executionInfo":{"status":"ok","timestamp":1601546023952,"user_tz":-120,"elapsed":913,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7923f8de-6ff0-463d-d999-83e23dea8757","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["model = img_siren.to(device)\n","\n","params_to_update = model.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t net.0.linear.weight\n","\t net.0.linear.bias\n","\t net.1.linear.weight\n","\t net.1.linear.bias\n","\t net.2.linear.weight\n","\t net.2.linear.bias\n","\t net.3.linear.weight\n","\t net.3.linear.bias\n","\t net.4.weight\n","\t net.4.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R60-cp-9Au6C"},"source":["total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","\n","criterion = nn.MSELoss()\n","optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n","\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnwzLg2WG31x","executionInfo":{"status":"ok","timestamp":1601546104847,"user_tz":-120,"elapsed":77926,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"68808871-582b-48ef-ec40-dd56358971f4","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"186Vc6q_WQpUq82KzlzZAeldZJNAZZsTY"}},"source":["start = time.time()\n","model, history = basic_traininig_loop(\n","# model, history = plane_traininig_loop(\n","    optimizer = optim,\n","    criterion = criterion,\n","    model = img_siren,\n","    model_input = model_input,\n","    ground_truth = ground_truth,\n","    total_steps = total_steps, steps_til_summary = steps_til_summary)\n","    # total_steps = total_steps)\n","stop = time.time()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"wmXdqLphE0QO","executionInfo":{"status":"ok","timestamp":1601546162333,"user_tz":-120,"elapsed":6407,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"cb62b13d-c657-41ab-9d5e-8c01fdc8d1b3","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# times = (stop - start) * 1000\n","times = (stop - start)\n","print('-' * 40)\n","# print('Run time takes %d miliseconds' % times) # print('Run time takes %.3f seconds' % times)\n","print('Training complete in {:.0f}m {:.0f}s {:.0f}ms'.format(times // 60, times % 60, (times - int((times % 60))) * 1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------\n","Training complete in 0m 39s 533ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-t309bN4H-Ry","executionInfo":{"status":"ok","timestamp":1601546170435,"user_tz":-120,"elapsed":10706,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"9aabfb7c-55a5-4a39-c98a-31f83a229949","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["train_loss_h = [] # val_loss_h = []\n","train_loss_h = [h for h in history['train_loss']] # val_loss_h = [h for h in history['val_loss']]\n","\n","plt.title(\"Train Lss vs. Number of Training Epochs\")\n","plt.xlabel(\"Training Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.plot(range(1,total_steps+1), train_loss_h, label=\"train_loss\") # plt.plot(range(1,total_steps+1), val_acc_h, label=\"val_loss\")\n","# plt.ylim((0,1.))\n","plt.xticks(np.arange(1, total_steps+1, 1.0))\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"CoTxAqJdPiIf"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'siren{}_nn_weights.pt'.format(sidelength))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPH_9VrER_11","executionInfo":{"status":"ok","timestamp":1601546251718,"user_tz":-120,"elapsed":902,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"16ca3dc3-7875-4c7b-e590-2f91c18e04f7","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_loss_h[-1].item()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0014171956572681665"]},"metadata":{"tags":[]},"execution_count":59}]}]}