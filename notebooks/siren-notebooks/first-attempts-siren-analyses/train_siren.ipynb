{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_siren.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iAtD6KGyt0M2"},"source":["import torch\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","import h5py\n","import srcnn\n","import torch.optim as optim\n","import torch.nn as nn\n","import numpy as np\n","import math\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from torchvision.utils import save_image\n","matplotlib.style.use('ggplot')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7iwFgsAZGPCx"},"source":["# the dataset module\n","class SirenDataset(Dataset):\n","    def __init__(self, image_data, labels):\n","        self.image_data = image_data\n","        self.labels = labels\n","    def __len__(self):\n","        return (len(self.image_data))\n","    def __getitem__(self, index):\n","        image = self.image_data[index]\n","        label = self.labels[index]\n","        return (\n","            torch.tensor(image, dtype=torch.float),\n","            torch.tensor(label, dtype=torch.float))\n","\n","class ImageFitting(Dataset):\n","    def __init__(self, sidelength, image_path = None):\n","        super().__init__()\n","        if image_path is None:\n","            img = get_cameraman_tensor(sidelength)\n","        else:\n","            imag = Image.open(image_path)\n","            imag = imag.resize((sidelength, sidelength))\n","            # printImageAttributes(imag, image_path)\n","            # imag = np.asarray(imag)\n","            transform = Compose([\n","                Resize(sidelength),\n","                ToTensor(),\n","                Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","            ])\n","            img = transform(imag)\n","            pass\n","        \n","        # print(type(img))\n","        # print(img.size())\n","\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","        pass\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):    \n","        if idx > 0: raise IndexError\n","            \n","        return self.coords, self.pixels\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TPXhTxrGPC0"},"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)      \n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    def forward_with_intermediate(self, input): \n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):\n","            if isinstance(layer, SineLayer):\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cuEo8ZBGPC2"},"source":["# learning parameters\n","batch_size = 64 # batch size, reduce if facing OOM error\n","epochs = 100 # number of epochs to train the SRCNN model for\n","lr = 0.001 # the learning rate\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rS4l19pGPC5"},"source":["# input image dimensions\n","img_rows, img_cols = 33, 33\n","out_rows, out_cols = 33, 33"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GaRW0qdlGPC8"},"source":["file = h5py.File('../input/train_mscale.h5')\n","# `in_train` has shape (21884, 33, 33, 1) which corresponds to\n","# 21884 image patches of 33 pixels height & width and 1 color channel\n","in_train = file['data'][:] # the training data\n","out_train = file['label'][:] # the training labels\n","file.close()\n","# change the values to float32\n","in_train = in_train.astype('float32')\n","out_train = out_train.astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"55MLAtXEGPDD"},"source":["(x_train, x_val, y_train, y_val) = train_test_split(in_train, out_train, test_size=0.25)\n","print('Training samples: ', x_train.shape[0])\n","print('Validation samples: ', x_val.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQwdc_c2GPDG"},"source":["# train and validation data\n","train_data = SirenDataset(x_train, y_train)\n","val_data = SirenDataset(x_val, y_val)\n","# train and validation loaders\n","train_loader = DataLoader(train_data, batch_size=batch_size)\n","val_loader = DataLoader(val_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZY-pJvmEGPDJ"},"source":["# initialize the model\n","print('Computation device: ', device)\n","model = Siren(\n","    in_features = 2,\n","    hidden_features 256,\n","    hidden_layers = 3,\n","    out_features = 1,\n","    outermost_linear = True, \n","    first_omega_0 = 30,\n","    hidden_omega_0 = 30.\n",").to(device)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRop4SBPGPDL"},"source":["# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","# loss function \n","criterion = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nksKyHJSGPDN"},"source":["def psnr(label, outputs, max_val=1.):\n","    \"\"\"\n","    Compute Peak Signal to Noise Ratio (the higher the better).\n","    PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n","    https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition\n","    First we need to convert torch tensors to NumPy operable.\n","    \"\"\"\n","    label = label.cpu().detach().numpy()\n","    outputs = outputs.cpu().detach().numpy()\n","    img_diff = outputs - label\n","    rmse = math.sqrt(np.mean((img_diff) ** 2))\n","    if rmse == 0:\n","        return 100\n","    else:\n","        PSNR = 20 * math.log10(max_val / rmse)\n","        return PSNR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsKvMD0RGPDQ"},"source":["def train(model, dataloader):\n","    model.train()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n","        image_data = data[0].to(device)\n","        label = data[1].to(device)\n","        \n","        # zero grad the optimizer\n","        optimizer.zero_grad()\n","        outputs = model(image_data)\n","        loss = criterion(outputs, label)\n","        # backpropagation\n","        loss.backward()\n","        # update the parameters\n","        optimizer.step()\n","        # add loss of each item (total items in a batch = batch size)\n","        running_loss += loss.item()\n","        # calculate batch psnr (once every `batch_size` iterations)\n","        batch_psnr =  psnr(label, outputs)\n","        running_psnr += batch_psnr\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/int(len(train_data)/dataloader.batch_size)\n","    return final_loss, final_psnr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeFfkPcFGPDS"},"source":["def validate(model, dataloader, epoch):\n","    model.eval()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    with torch.no_grad():\n","        for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n","            image_data = data[0].to(device)\n","            label = data[1].to(device)\n","            \n","            outputs = model(image_data)\n","            loss = criterion(outputs, label)\n","            # add loss of each item (total items in a batch = batch size) \n","            running_loss += loss.item()\n","            # calculate batch psnr (once every `batch_size` iterations)\n","            batch_psnr = psnr(label, outputs)\n","            running_psnr += batch_psnr\n","        outputs = outputs.cpu()\n","        save_image(outputs, f\"../outputs/val_sr{epoch}.png\")\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/int(len(train_data)/dataloader.batch_size)\n","    return final_loss, final_psnr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gt5Dff-PGPDU"},"source":["train_loss, val_loss = [], []\n","train_psnr, val_psnr = [], []\n","start = time.time()\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1} of {epochs}\")\n","    train_epoch_loss, train_epoch_psnr = train(model, train_loader)\n","    val_epoch_loss, val_epoch_psnr = validate(model, val_loader, epoch)\n","    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n","    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n","    train_loss.append(train_epoch_loss)\n","    train_psnr.append(train_epoch_psnr)\n","    val_loss.append(val_epoch_loss)\n","    val_psnr.append(val_epoch_psnr)\n","end = time.time()\n","print(f\"Finished training in: {((end-start)/60):.3f} minutes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86AtJw6jGPDX"},"source":["# loss plots\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_loss, color='orange', label='train loss')\n","plt.plot(val_loss, color='red', label='validataion loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.savefig('../outputs/loss.png')\n","plt.show()\n","# psnr plots\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_psnr, color='green', label='train PSNR dB')\n","plt.plot(val_psnr, color='blue', label='validataion PSNR dB')\n","plt.xlabel('Epochs')\n","plt.ylabel('PSNR (dB)')\n","plt.legend()\n","plt.savefig('../outputs/psnr.png')\n","plt.show()\n","# save the model to disk\n","print('Saving model...')\n","torch.save(model.state_dict(), '../outputs/model.pth')"],"execution_count":null,"outputs":[]}]}