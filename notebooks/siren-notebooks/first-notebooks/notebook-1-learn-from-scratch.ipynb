{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"notebook-1-learn-from-scratch.ipynb","provenance":[],"collapsed_sections":["Dajy0EgFmKi5","YkQX-dwMM33q","7lLTMlO9Ug3Y","XOMVn5PXZAU0","IcN0tMHTbWiG","hQ9rktLgG_2Q","AtrpXlFffes6","8OFpGiWVhmAI","wncnNifF3mNP"],"authorship_tag":"ABX9TyNzmnueo7cBeNw7VjiUD+WD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"53cfd57a15984ed38702a59527c6fec1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_111fe34dae8c4cb183fab1c4e81b91a1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bc16232ca09648b394d3f40fa8828575","IPY_MODEL_c3ba7ec1912a48258ea34e92bee69b7b"]}},"111fe34dae8c4cb183fab1c4e81b91a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc16232ca09648b394d3f40fa8828575":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f86e87f0da504aa29cb36ba9a779033e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_029463c5c784439eb54e67e15c68a803"}},"c3ba7ec1912a48258ea34e92bee69b7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5f745d9e036841a8b90aa0d3a5b5ba53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 33415930.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf686e0f69b440f4b5233bfc70e96f24"}},"f86e87f0da504aa29cb36ba9a779033e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"029463c5c784439eb54e67e15c68a803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f745d9e036841a8b90aa0d3a5b5ba53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cf686e0f69b440f4b5233bfc70e96f24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6Z9EUhiWhRiB"},"source":["# Studing Chapter n.7 - Image Recognition Tasks Examples"]},{"cell_type":"markdown","metadata":{"id":"MpvUwndhqdE-"},"source":["## Reference's Book:\n"," - Deep Learning with PyTorch\n","   - by Eli Stevens, Luca Antiga, and Thomas Viehmann"]},{"cell_type":"markdown","metadata":{"id":"9Gde4zQ8b58q"},"source":["## Check whether CUDA-like device is available and free to be used"]},{"cell_type":"code","metadata":{"id":"hQo01DjSfr5m","executionInfo":{"status":"ok","timestamp":1601210747164,"user_tz":-120,"elapsed":5162,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"e73722a8-e9d0-4b63-b049-d9df5835ef4d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","device = (torch.device('cuda') if torch.cuda.is_available()\n","    else torch.device('gpu'))\n","print(f\"Training on device {device}.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training on device cuda.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dajy0EgFmKi5"},"source":["## Manually Download Data for any desired Reason"]},{"cell_type":"code","metadata":{"id":"4NayirdmkTgq"},"source":["# !wget -c https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBYTpP-hk9RA"},"source":[" # !tar -xf /content/cifar-10-python.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JOtxBYnamQdN"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"3RyOsxnnhODD"},"source":["import datetime\n","import torch\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchvision import datasets\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcC_9miOsOvy","executionInfo":{"status":"ok","timestamp":1601210747167,"user_tz":-120,"elapsed":5114,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"ea9f24ca-2eba-4499-fbdb-ff7ee72fc70d","colab":{"base_uri":"https://localhost:8080/","height":731}},"source":["dir(transforms)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['CenterCrop',\n"," 'ColorJitter',\n"," 'Compose',\n"," 'ConvertImageDtype',\n"," 'FiveCrop',\n"," 'Grayscale',\n"," 'Lambda',\n"," 'LinearTransformation',\n"," 'Normalize',\n"," 'PILToTensor',\n"," 'Pad',\n"," 'RandomAffine',\n"," 'RandomApply',\n"," 'RandomChoice',\n"," 'RandomCrop',\n"," 'RandomErasing',\n"," 'RandomGrayscale',\n"," 'RandomHorizontalFlip',\n"," 'RandomOrder',\n"," 'RandomPerspective',\n"," 'RandomResizedCrop',\n"," 'RandomRotation',\n"," 'RandomSizedCrop',\n"," 'RandomVerticalFlip',\n"," 'Resize',\n"," 'Scale',\n"," 'TenCrop',\n"," 'ToPILImage',\n"," 'ToTensor',\n"," '__builtins__',\n"," '__cached__',\n"," '__doc__',\n"," '__file__',\n"," '__loader__',\n"," '__name__',\n"," '__package__',\n"," '__path__',\n"," '__spec__',\n"," 'functional',\n"," 'functional_pil',\n"," 'functional_tensor',\n"," 'transforms']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"YvvXZcpRdkHQ"},"source":["## Custom Classes"]},{"cell_type":"code","metadata":{"id":"797JgiHVdmAb"},"source":["class Net(nn.Module):\n","    def __init__(self, num_classes = 2):\n","        super().__init__()\n","        \n","        # First Conv + Act + Pool full block\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, padding = 1)\n","        self.act1 = nn.Tanh()\n","        self.pool1 = nn.MaxPool2d(2)\n","        \n","        # Second Conv + Act + Pool full block\n","        self.conv2 = nn.Conv2d(16, 8, kernel_size = 3, padding = 1)\n","        self.act2 = nn.Tanh()\n","        self.pool2 = nn.MaxPool2d(2)\n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n","        self.act3 = nn.Tanh()\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = self.pool1(self.act1(self.conv1(x)))\n","        out = self.pool2(self.act2(self.conv2(out)))\n","        out = out.view(-1, 8 * 8 * 8)\n","        out = self.act3(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXm8eAjFgMT2"},"source":["class NetWidth(nn.Module):\n","    def __init__(self, num_classes = 2, n_chans1 = 32):\n","        super().__init__()\n","        self.n_chans1 = n_chans1\n","\n","        # First Conv Layer\n","        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n","        \n","        # Second Conv Layer\n","        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size = 3, padding = 1)\n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n","        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n","        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n","        out = torch.tanh(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCarvGmwrBw7"},"source":["class NetBatchNorm(nn.Module):\n","    def __init__(self, num_classes = 2, n_chans1 = 32):\n","        super().__init__()\n","        self.n_chans1 = n_chans1\n","\n","        # First Conv Layer + BatchNorm full block\n","        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n","        self.conv1_batchnorm = nn.BatchNorm2d(num_features = n_chans1)\n","        \n","        # Second Conv Layer + BatchNorm full block\n","        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size = 3, padding = 1)\n","        self.conv2_batchnorm = nn.BatchNorm2d(num_features = n_chans1 // 2)\n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = self.conv1_batchnorm(self.conv1(x))\n","        out = F.max_pool2d(torch.tanh(out), 2)\n","\n","        out = self.conv2_batchnorm(self.conv2(out))\n","        out = F.max_pool2d(torch.tanh(out), 2)\n","\n","        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n","        out = torch.tanh(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HN-nyopIxpXx"},"source":["class NetDepth(nn.Module):\n","    def __init__(self, num_classes = 2, n_chans1 = 32):\n","        super().__init__()\n","        self.n_chans1 = n_chans1\n","\n","\n","        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n","        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size = 3, padding = 1)\n","        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size = 3, padding = 1)\n","        \n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n","        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n","        out1 = out\n","\n","        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n","        \n","        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n","        out = torch.relu(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bg4sO65azF5s"},"source":["class NetDepth(nn.Module):\n","    def __init__(self, num_classes = 2, n_chans1 = 32):\n","        super().__init__()\n","        self.n_chans1 = n_chans1\n","\n","\n","        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n","        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size = 3, padding = 1)\n","        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size = 3, padding = 1)\n","        \n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n","        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n","        out1 = out\n","\n","        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n","        \n","        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n","        out = torch.relu(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLw6GB1n5hJu"},"source":["class ResBlock(nn.Module):\n","    def __init__(self, n_chans):\n","        super(ResBlock, self).__init__()\n","        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size = 3, padding = 1, bias = False)\n","        self.batch_norm = nn.BatchNorm2d(num_features = n_chans)\n","        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n","        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n","        torch.nn.init.zeros_(self.batch_norm.bias)\n","        pass\n","\n","    def forward(self, x):\n","        out = self.conv(x)\n","        out = self.batch_norm(out)\n","        out = torch.relu(out)\n","        return out + x\n","    pass\n","\n","\n","class NetResDeep(nn.Module):\n","    def __init__(self, num_classes = 2, n_chans1 = 32, n_blocks = 10):\n","        super().__init__()\n","        self.n_chans1 = n_chans1\n","\n","\n","        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n","        self.resblocks = nn.Sequential(\n","            *(n_blocks * [ResBlock(n_chans = n_chans1)])\n","        )\n","\n","        # Fully Connected layers on top NN Arch.\n","        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        pass\n","\n","    def forward(self, x):\n","        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n","        out = self.resblocks(out)\n","\n","        out = F.max_pool2d(out, 2)\n","        \n","        out = out.view(-1, 8 * 8 * self.n_chans1)\n","        out = torch.relu(self.fc1(out))\n","        out = self.fc2(out)\n","        return out\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vPfwYuHMazkT"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"rhwEuIjHa6qD"},"source":["def training_loop(model, loss_fn, optimizer):\n","    \"\"\"\n","    Basic training loop for brief tests\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    \n","    for epoch in range(1, n_epochs + 1):\n","        for img, label in cifar2:\n","            out = model(img.view(-1).unsqueeze(0))\n","            loss = loss_fn(out, torch.tensor([label]))\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n","        pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkqSA0ukcdqE"},"source":["def convnet_validate(model, train_loader, val_loader):\n","    \"\"\"\n","    Validate model's performance calculating Accuracy scores for both training\n","    set and validation set, where input model's is made of at least one convolution layer.\n","\n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","\n","    Returns:\n","    --------\n","    :result_str: str Python object for later dispalying containing as a message \n","        the Accuracy scores calculated for both train and val set passed independently to model instance \n","    \"\"\"\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    result_str = \"\"\n","\n","    for name, loader in [('train', train_loader), ('val', val_loader)]:\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for imgs, labels in loader:\n","                imgs = imgs.to(device=device)\n","                labels = labels.to(device=device)\n","\n","                outputs = model(imgs)\n","                _, predicted = torch.max(outputs, dim = 1)\n","                \n","                total += labels.shape[0]\n","                correct += int((predicted == labels).sum())\n","                pass\n","        result_str += \"Accuracy {}: {:.5f} \".format(name, correct / total)\n","    \n","    return result_str\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iBiN8PTCayXo"},"source":["def batched_training_loop(model, loss_fn, optimizer, train_loader, val_loader):\n","    \"\"\"\n","    Basic training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","\n","        for imgs, labels in train_loader:\n","            batch_size = imgs.shape[0]\n","            outputs = model(imgs.view(batch_size, -1))\n","            loss = loss_fn(outputs, labels)\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n","\n","\n","        # switch to evaluate mode\n","        model.eval()\n","        \n","        with torch.no_grad():\n","            for imgs, labels in loader:\n","                batch_size = imgs.shape[0]\n","                \n","                outputs = model(imgs.view(batch_size, -1))\n","                _, predicted = torch.max(outputs, dim = 1)\n","                \n","                total += labels.shape[0]\n","                correct += int((predicted == labels).sum())\n","                pass\n","        print(\"Accuracy: %f\" % (correct / total, ))\n","        pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeGpefJ-KBKV"},"source":["def basic_batched_convnet_training_loop(model, loss_fn, optimizer, train_loader, val_loader):\n","    \"\"\"\n","    Basic training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth, \n","    where model's arch is represented by a ConvNet.\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","\n","        for imgs, labels in train_loader:\n","            imgs = imgs.to(device=device)\n","            labels = labels.to(device=device)\n","            outputs = model(imgs)\n","            loss = loss_fn(outputs, labels)\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n","\n","        correct = 0\n","        total = 0\n","\n","        # switch to evaluate mode\n","        model.eval()\n","        \n","        with torch.no_grad():\n","            for imgs, labels in loader:\n","                batch_size = imgs.shape[0]\n","                \n","                outputs = model(imgs)\n","                _, predicted = torch.max(outputs, dim = 1)\n","                \n","                total += labels.shape[0]\n","                correct += int((predicted == labels).sum())\n","                pass\n","        print(\"Accuracy: %f\" % (correct / total, ))\n","        pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aEjTnRLgiOPD"},"source":["def batched_convnet_training_loop(model, loss_fn, optimizer, train_loader, val_loader):\n","    \"\"\"\n","    More Advanced training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth, \n","    where model's arch is represented by a ConvNet.\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","        \n","        for imgs, labels in train_loader:\n","            imgs = imgs.to(device=device)\n","            labels = labels.to(device=device)\n","            outputs = model(imgs)\n","            loss = loss_fn(outputs, labels)\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","\n","        result_validate_str = convnet_validate(model, train_loader, val_loader)\n","        \n","        epoch_msg = \"%s Epoch: %d, Trainin Loss: %.5f %s\" \\\n","              % (str(datetime.datetime.now()),\n","                 epoch, float(loss),\n","                 result_validate_str.strip()\n","                 )\n","        print(epoch_msg)\n","        pass\n","\n","def l2_reg_batched_convnet_training_loop(model, loss_fn, optimizer, train_loader, val_loader, l2_lambda = 1e-3):\n","    \"\"\"\n","    More Advanced training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth, \n","    where model's arch is represented by a ConvNet. In particular, here, it is introduced l2-Norm Regularization\n","    for controlling size of weight values which are all together model's parameters.\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","    :l2_lambda: default to 1e-3, it represent the amount of l2-norm contribute to be accounted during weights update along backward pass\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","\n","        for imgs, labels in train_loader:\n","            imgs = imgs.to(device=device)\n","            labels = labels.to(device=device)\n","            outputs = model(imgs)\n","            loss = loss_fn(outputs, labels)\n","\n","            l2_norm = sum(p.pow(2.0).sum()\n","                for p in model.parameters())\n","            loss = loss + l2_norm * l2_lambda\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","\n","        result_validate_str = convnet_validate(model, train_loader, val_loader)\n","        \n","        epoch_msg = \"%s Epoch: %d, Trainin Loss: %.5f %s\" \\\n","              % (str(datetime.datetime.now()),\n","                 epoch, float(loss),\n","                 result_validate_str.strip()\n","                 )\n","        print(epoch_msg)\n","        pass\n","\n","def l1_reg_batched_convnet_training_loop(model, loss_fn, optimizer, train_loader, val_loader, l1_lambda = 1e-3):\n","    \"\"\"\n","    More Advanced training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth, \n","    where model's arch is represented by a ConvNet. In particular, here, it is introduced l1-Norm Regularization\n","    for controlling size of weight values which are all together model's parameters.\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","    :l1_lambda: default to 1e-3, it represent the amount of l1-norm contribute to be accounted during weights update along backward pass\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","\n","        for imgs, labels in train_loader:\n","            imgs = imgs.to(device=device)\n","            labels = labels.to(device=device)\n","            outputs = model(imgs)\n","            loss = loss_fn(outputs, labels)\n","\n","            l1_norm = sum(p.abs().sum()\n","                for p in model.parameters())\n","            loss = loss + l1_norm * l1_lambda\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","\n","        result_validate_str = convnet_validate(model, train_loader, val_loader)\n","        \n","        epoch_msg = \"%s Epoch: %d, Trainin Loss: %.5f %s\" \\\n","              % (str(datetime.datetime.now()),\n","                 epoch, float(loss),\n","                 result_validate_str.strip()\n","                 )\n","        print(epoch_msg)\n","        pass\n","\n","def l1l2_reg_batched_convnet_training_loop(model, loss_fn, optimizer, train_loader, val_loader, l1_lambda = 1e-3, l2_lambda = 1e-3):\n","    \"\"\"\n","    More Advanced training loop for brief tests exploiting Batch Strategy to let training be more stable and smooth, \n","    where model's arch is represented by a ConvNet. In particular, here, it is introduced l1-Norm Regularization\n","    for controlling size of weight values which are all together model's parameters.\n","    \n","    Parameters:\n","    -----------\n","    :model: either nn.Sequential or subclass from nn.Module\n","    :loss_fn: loss function pytorch's instance, expressing a particular loss function shape to be minimized by means of a particular optimization strategy\n","    :optimizer: optimizer pytorch's instance representing the selected optimization strategy to be followed to fit the model's arch to the train data\n","    :train_loader: either nn.DataLoader or nn.DataSet instances collecting data examples employed for training the model\n","    :val_loader: either nn.DataLoader or nn.DataSet instances collecting data examples constituting validation set\n","    :l1_lambda: default to 1e-3, it represent the amount of l1-norm contribute to be accounted during weights update along backward pass\n","    :l2_lambda: default to 1e-3, it represent the amount of l2-norm contribute to be accounted during weights update along backward pass\n","\n","    Returns:\n","    --------\n","    None \n","    \"\"\"\n","    for epoch in range(1, n_epochs + 1):\n","\n","        # switch to train mode\n","        model.train()\n","\n","        for imgs, labels in train_loader:\n","            imgs = imgs.to(device=device)\n","            labels = labels.to(device=device)\n","            outputs = model(imgs)\n","            loss = loss_fn(outputs, labels)\n","\n","            l1_norm = sum(p.abs().sum()\n","                for p in model.parameters())\n","            l2_norm = sum(p.pow(2.0).sum()\n","                for p in model.parameters())\n","            loss = loss + l1_norm * l1_lambda + l2_norm * l2_lambda\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pass\n","\n","        result_validate_str = convnet_validate(model, train_loader, val_loader)\n","        \n","        epoch_msg = \"%s Epoch: %d, Trainin Loss: %.5f %s\" \\\n","              % (str(datetime.datetime.now()),\n","                 epoch, float(loss),\n","                 result_validate_str.strip()\n","                 )\n","        print(epoch_msg)\n","        pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77_dJAdDmTf4"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"0coqN8Lot16O"},"source":["### Fetch Data"]},{"cell_type":"code","metadata":{"id":"J7vUL3FSgUNs"},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti-qP17Xiyuj"},"source":["data_path = '/content/cifar-10-batches-py'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z0lEzkWnrZju"},"source":["class_objects = \"airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck\".split(\",\")\n","\n","class_indeces = range(0, 10)\n","item_pairs = zip(class_indeces, class_objects)\n","class_names = dict(item_pairs)\n","\n","class_indeces = range(0, 10)\n","item_pairs_reverse = zip(class_objects, class_indeces)\n","class_names_reverse = dict(item_pairs_reverse)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1XXxBB0lciT","executionInfo":{"status":"ok","timestamp":1601210757333,"user_tz":-120,"elapsed":15099,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"d77fb60c-5c17-4514-cf92-4102f64aa9c0","colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["53cfd57a15984ed38702a59527c6fec1","111fe34dae8c4cb183fab1c4e81b91a1","bc16232ca09648b394d3f40fa8828575","c3ba7ec1912a48258ea34e92bee69b7b","f86e87f0da504aa29cb36ba9a779033e","029463c5c784439eb54e67e15c68a803","5f745d9e036841a8b90aa0d3a5b5ba53","cf686e0f69b440f4b5233bfc70e96f24"]}},"source":["# Dowload CIFAR-10 Dataset\n","cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n","cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-batches-py/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53cfd57a15984ed38702a59527c6fec1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /content/cifar-10-batches-py/cifar-10-python.tar.gz to /content/cifar-10-batches-py\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vWK2XA3Ylx2v","executionInfo":{"status":"ok","timestamp":1601210757334,"user_tz":-120,"elapsed":15089,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"ca2f690c-60cc-46dc-afcc-671545237ce1","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["type(cifar10).__mro__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torchvision.datasets.cifar.CIFAR10,\n"," torchvision.datasets.vision.VisionDataset,\n"," torch.utils.data.dataset.Dataset,\n"," object)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"LjrGBuKAnJBe","executionInfo":{"status":"ok","timestamp":1601210757334,"user_tz":-120,"elapsed":15077,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"c6785e2e-0aff-4032-dc28-83872ff52187","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["type(cifar10_val).__mro__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torchvision.datasets.cifar.CIFAR10,\n"," torchvision.datasets.vision.VisionDataset,\n"," torch.utils.data.dataset.Dataset,\n"," object)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"V7k3_Po-pMhe","executionInfo":{"status":"ok","timestamp":1601210757335,"user_tz":-120,"elapsed":15066,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4875b540-89cb-492d-d06f-fccf75a1d752","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(f\"CIFAR-10 dataset's size for training: {len(cifar10)}\")\n","print(f\"CIFAR-10 dataset's size for validation: {len(cifar10_val)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CIFAR-10 dataset's size for training: 50000\n","CIFAR-10 dataset's size for validation: 10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fQQR-JBXqxPH"},"source":["img, label = cifar10[99]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJQpDYU5q_r7","executionInfo":{"status":"ok","timestamp":1601210757686,"user_tz":-120,"elapsed":15393,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4e060dd6-e7f1-4b8a-ebea-3fc1cdf460f9","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["img, label, class_names[label]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FC2D5B122B0>,\n"," 1,\n"," 'automobile')"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"GuqjkEN4rFzi","executionInfo":{"status":"ok","timestamp":1601210757686,"user_tz":-120,"elapsed":15381,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"a895de3c-13c3-4ab1-e501-522c36e2831a","colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"7goRq0sepMGm"},"source":["### Preprocess Data"]},{"cell_type":"markdown","metadata":{"id":"MuhY3tpJcXzw"},"source":["#### Just understand translation from Numpy to Tensor Data Structures"]},{"cell_type":"code","metadata":{"id":"QMlIRkb_t4UQ"},"source":["to_tensor = transforms.ToTensor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtGA71IruBAL","executionInfo":{"status":"ok","timestamp":1601210757687,"user_tz":-120,"elapsed":15357,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"d8f3c108-293e-49a4-d4b7-4bf6e0d3fabc","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["img_t = to_tensor(img)\n","img_t.shape, img_t.dtype"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3, 32, 32]), torch.float32)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"iupuOJKLuWu6"},"source":["tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n","    transform=transforms.ToTensor())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAdtmz40uopi","executionInfo":{"status":"ok","timestamp":1601210758805,"user_tz":-120,"elapsed":16452,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"6e5b89f1-b1b7-4bac-99ce-2c8542bf6320","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["img_t, _ = tensor_cifar10[99]\n","img_t.shape, img_t.dtype"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3, 32, 32]), torch.float32)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"Dptw3DrLu6Cf","executionInfo":{"status":"ok","timestamp":1601210758805,"user_tz":-120,"elapsed":16441,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"2a73c17f-9c14-4055-d8e1-90beaab51d61","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["img_t.min(), img_t.max()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.), tensor(1.))"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"hXBV6-HRvRK3","executionInfo":{"status":"ok","timestamp":1601210758806,"user_tz":-120,"elapsed":16430,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"af935cde-865e-4f05-c4aa-270ece8694b8","colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["plt.imshow(img_t.permute(1, 2, 0))\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"NqD9_L1kxv_e"},"source":["imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PxHoQydZyP_r","executionInfo":{"status":"ok","timestamp":1601210769574,"user_tz":-120,"elapsed":27175,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7426ca77-1506-47bf-f842-88a56111a5a1","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["imgs.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 32, 32, 50000])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"JbAA7qTzcQGo"},"source":["#### Convert to Tensor and Normalize Input Data Examples"]},{"cell_type":"code","metadata":{"id":"Vn2qgeFDyVma"},"source":["mean_by_channels = imgs.view(3, -1).mean(dim=1)\n","std_by_channels = imgs.view(3, -1).std(dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rt6XtuRAyfDK"},"source":["normalize = transforms.Normalize(mean=mean_by_channels, std=std_by_channels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdANHVZPyr0N","executionInfo":{"status":"ok","timestamp":1601210770801,"user_tz":-120,"elapsed":28367,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"600064dd-f987-48f2-a817-bc99227999b7","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["normalize"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Normalize(mean=tensor([0.4915, 0.4823, 0.4468]), std=tensor([0.2470, 0.2435, 0.2616]))"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"sdlGDaBDy2X8"},"source":["transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n","    transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=mean_by_channels, std=std_by_channels)\n","            ]\n","        )\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_kRwl3x9MLd"},"source":["transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n","    transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=mean_by_channels, std=std_by_channels)\n","            ]\n","        )\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WaLT0wLdzYyp","executionInfo":{"status":"ok","timestamp":1601210772197,"user_tz":-120,"elapsed":29724,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"56bf4a23-b8f6-4682-f6ba-73c640f2f8d0","colab":{"base_uri":"https://localhost:8080/","height":303}},"source":["img_t, _ = transformed_cifar10[99]\n","\n","plt.imshow(img_t.permute(1, 2, 0))\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"MPVESw9W1E_W"},"source":["### Builidng CIFAR-2 made out of just Bird and Airplane examples"]},{"cell_type":"code","metadata":{"id":"PJiPywMk1MsM"},"source":["label_map = {class_names_reverse['airplane']: 0, class_names_reverse['bird']: 1}\n","class_names = ['airplane', 'bird']\n","\n","cifar2 = [\n","          (img, label_map[label])\n","          for img, label in transformed_cifar10\n","          if label in [0, 2]\n","]\n","\n","cifar2_val = [\n","          (img, label_map[label])\n","          for img, label in transformed_cifar10_val\n","          if label in [0, 2]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLJqX8Bt4Y9E"},"source":["n_out = 2\n","\n","model = nn.Sequential(\n","    nn.Linear(3072, 512), nn.Tanh(),\n","    nn.Linear(512, n_out), nn.Softmax(dim=1)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XtWNTep4mVk","executionInfo":{"status":"ok","timestamp":1601210785778,"user_tz":-120,"elapsed":43271,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4930b665-3e7c-4282-add4-d6996ec745f1","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=3072, out_features=512, bias=True)\n","  (1): Tanh()\n","  (2): Linear(in_features=512, out_features=2, bias=True)\n","  (3): Softmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"U99jVD-y8c2V","executionInfo":{"status":"ok","timestamp":1601210785778,"user_tz":-120,"elapsed":43255,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"0252d39b-1046-4259-febe-d939751235a8","colab":{"base_uri":"https://localhost:8080/","height":303}},"source":["img, _ = cifar2[0]\n","\n","plt.imshow(img.permute(1, 2, 0))\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZQ0lEQVR4nO2de7jVZZXHP0suooKhgkiAAUqlpYIhecNRHLw9zahlppONNU7YxZmaaabMLtp1sic1LTNpdNQer6WWlZWIPmlpCppyVExAMSGuIgIiIrLmj70psN9a55x9ztnn6Pv9PM95zj7re9b7e/dv77V/e79rr/WauyOEeP2zVXdPQAjRHBTsQhSCgl2IQlCwC1EICnYhCkHBLkQh9O6Is5kdBVwI9AL+192/kf3/gEHmO42s1p5+InHcutq8Vb/YpY/1CrVtto3v9g79B4Xa9uxcae+dvGauYVWoLVg9N9T6D4hTom8IFegT2NclPsHpBfKrQZa0fSWwb5f4dAUrA/v6xOfF8CxCdq9Xrd4QautfTIZcm2gRzwf2V8A3ulVJ1mie3cx6AU8Ak4EFwAzgZHd/LPIZOd78CzOrtX89IjnYqGrz9nvEQTu4dxwSY/feKdSOn3haqE22j1fad06ewvdwe6h9+o53hdoBk14KtdgLBgf2OYlPcHoB6J9o2QvImsA+IfFplI2J9rPAPj/xmc2wUNtAHNC337Ek1J4OowL4Q6JF3BrYl4O/XB3sHXkbPwGY6+5Puvt64Drg2A6MJ4ToQjoS7MOAZzb7e0HdJoTogXT5Ap2ZTTGzmWY2c/Wyrj6aECKiI8G+EBix2d/D67YtcPep7j7e3ccPiD5QCiG6nI4E+wxgjJmNMrO+wEnALZ0zLSFEZ9Nw6s3dN5jZGcCvqaXeLnf3RzOfXiSru+9JHD9SbV61R7wyumqvZ0PtqcWxNvf+S2NtUvXpOnnfw0KfA5NE2fcmDQy1OcQru0FCA4hXyIcnPvFZhOWJFs++0VX30Ym2d6jMZEao/c9P/+bNJgD9R1SaawyK7/X0i+IsSd9xyZjxFOP8YEb0QCfJtQ7l2d39VuIkgBCiB6Fv0AlRCAp2IQpBwS5EISjYhSgEBbsQhdCh1fj2sgT4TqAdfnrsNz3I1+0zLst1xOm1hz/7p1i75clYO+ZTlfaWs+O00OQJs0Ity7gkBX0sSLQow3N04rNLoh2QaNszJFGj858l+uK01j0cF2rTfhqnN+877spq4d3xLN753Xge7BVL6++PNZ5KtCgK70x8GkBXdiEKQcEuRCEo2IUoBAW7EIWgYBeiEJq6Gv/CQvjd56u13b4a+338/dX2i29M+vnMTiayX6JldXtBFcDvPxavuP9DMly2Gn9+omVMDuzZGnjWlmr7tB9JdU8+gI8E924ybw599ku64S1LGmS1jDgl1CBYjU9OyFuHxtrKibH2x2zFPRmzWdUlurILUQgKdiEKQcEuRCEo2IUoBAW7EIWgYBeiEJqaemMx8LVqaV7idvE/BkJWLZI0SNst2X1mXpayu6bavDBp1PbBu5Lxkvnv3ODWKdHmVVFKDuDN6YZS8TZav+DPobYueABGsW/ocy9xL7+TsiaF8ZCE93zktNDj9mT3loUXJ4fKKpSeSbRo+5xORld2IQpBwS5EISjYhSgEBbsQhaBgF6IQFOxCFEKHUm9mNh9YDbwCbHD38Q0PdnWiRemwpB8Y/xJLG5Ktf9753Vi7L9pyZ04yj4ykwm7NBbH2sV1jLdoo9+5kGi08H2ojE+2hZMz9gv50zyWN1a7lhHhASw6WEoy5YbvQY+HFP4mHm58cKtsPqwfsYNwZefbD3D3bEkwI0QPQ23ghCqGjwe7AbWb2gJlN6YwJCSG6ho6+jT/Y3Rea2c7ANDN73N23+IJo/UVALwRCdDMdurK7+8L676XAzVRsy+3uU919fIcW74QQHabhYDez7cxswKbbwBHAI501MSFE52Lu3pij2WhqV3OofRy4xt2Dmra/+DR2sK8E9qsSn2zfoqTa7C2XxtqHA/vbk0MtTxo2Trl/YaitbYnH3Oe0WIsKqLKqwoMS7aOJFlXYAQylOj/YwiuhzymzkpziPkmnR76ZaA2Q3bFJiRb3xIR7Ey2qiGuwGs7dKxOVDX9md/cngX0a9RdCNBel3oQoBAW7EIWgYBeiEBTsQhSCgl2IQmg49dbQwRpNvR0T2LNUR1aJ9lyiRc0tAQ4J7Mnece9JsklZkdRlDyZi1rwwaFT5tmSvsfcmw2VpxaR4kJGBfTY7hT6H3rFnPODhUckhwIxYip4jeyTDnZhoWUPSxYnWpP3cIE696couRCEo2IUoBAW7EIWgYBeiEBTsQhRCc7d/yshmEq2s/3ODx7oh0W5KtGjHoFGxy40fS8ZLtnjaalysDU22O9o9sH8gmUbk0xpZW7VI28CzsdNtb25sIlckq/EBx54aa7skfpeenoi3tXsaTUVXdiEKQcEuRCEo2IUoBAW7EIWgYBeiEBTsQhRCz0m9bUi01YE9K0rISHrQpWdkcmAfkPhkxRFXJtP4RKwd3CcZMyDbsie6W63RyOnPylk4Ny6SIenl9/1Tjwq13flVpT07H/MTLXXMnsM9AF3ZhSgEBbsQhaBgF6IQFOxCFIKCXYhCULALUQitpt7M7HLgXcBSd3973bYjcD21VmPzgRPdPevs1jGi9NU1iU9SNcaYRMt61+0Q2LPqu6zCLtneZ33SZ27+6FgbHtj7MST0+SVLQi3rk/ezRJubaDHZ0eL9k0YmPeiihyyb3wbi6rt9PvFEqD28VzLolxIteq5mKeLBgf03sUtbruxXAK9OZJ4JTHf3McD0+t9CiB5Mq8Fe3299xavMx/LXr4RcCRzXyfMSQnQyjX5mH+Lui+q3F0PyHlEI0SPo8Ndl3d2zfvBmNgWY0tHjCCE6RqNX9iVmNhSg/ntp9I/uPtXdx7v7+AaPJYToBBoN9luATV28TgV+2jnTEUJ0Fa1u/2Rm1wKHAoOAJcDZwE+oJZV2BZ6mlnp79SJe1VjN22sqI+somFWpRamV7EPKNomWlJtl20a9l+2SQav3OxqULKssZ1ao/T450rdfTMTzAvtVic+cy2Jtj7hz5/seeynUJgb2t7J36LMfF4baBi4Ntd7ED9oMdgu1xcH5X0Oc5nvc51Xar9lvAUtmvlS5/VOrn9nd/eRAOrw1XyFEz0HfoBOiEBTsQhSCgl2IQlCwC1EICnYhCqHnNJzsKWSVRi2B/bOJz7di6dQkvRZVawHMJ27MOChI8fROHuqHkmN9O/sGxR2JFjVmzKoKqU4nATA5fmBWEqfeokxq/yTd2JtPh9pQ/hRqbw7zjXA47w+1qHXnChaGHjva31fa7yb+7pqu7EIUgoJdiEJQsAtRCAp2IQpBwS5EISjYhSiE13bqLZt9tu/WykRLNyMLSBpH5qmmOPfWm+OTw8UVW8OD0rzlPBv63P1gKMG902Kt0/c9+3qovHOHrUPtP5IRoylmDSfvThpYZk+PL3NKqI1OxoQ3Vlpn8ELocSSHJeNVoyu7EIWgYBeiEBTsQhSCgl2IQlCwC1EIr+3V+IZWfGlsxb1RqlvC1aTn4tXnF9edFGq7D+oVDxo8or2TjMGH9331hj9/5UP7xn5z46bCtPz6yUr7L244Nx6Qn4TKxA1xscuRf+l9+rec95e9TLakkZ2VABYl2lOJNjzpaxc9NFn/v5kvXlFpX7QxbqKoK7sQhaBgF6IQFOxCFIKCXYhCULALUQgKdiEKodXUm5ldDrwLWOrub6/bzgE+DCyr/9tZ7n5rV02yx5Ok13Zc88VQ+9HF8ZZAgwfG6bWVY+LjrQkyL3PnxKmrkWPiIpN+A+NjTZy0c6jtcmC19st3fyL02XhTnHq7N8lrPRak1wDGBvZRDAt9nkl6vw1IQmYD8WP2f0mfvOGB/ejQA/ptU10Mdc1Wz4c+bbmyXwFUJWIvcPex9Z9yA12I1witBru73wW0ummjEKJn05HP7GeY2Swzu9zMss7HQogeQKPBfgmwG7WPRIuIN+jFzKaY2Uwzm9ngsYQQnUBDwe7uS9z9FXffCPwAmJD871R3H+/ucfd6IUSX01Cwm9nQzf48Hnikc6YjhOgq2pJ6uxY4FBhkZguAs4FDzWws4MB84PQunGPIsJFxymjkIeGbDXqvi+/2b264s/0TGfWfobTiqYmx37KnQ2npmO1CbdHiOG20ouWJamHWY6HPo2uSkrg1cSrnxv3GhVrfcdVpxY03JT3tEn4Xbb0FfC/xGxDYlyXptT2S8SYnpZYDEy1re1jdNRAmkFUIfqTSug1/F3q0GuzufnKF+bLW/IQQPQt9g06IQlCwC1EICnYhCkHBLkQhKNiFKISmNpwcttMb+bdjq1MG/Q6J0zj9xu1ZaT9s1OjQp3+UcyEtUuPdu5wRatMvuq5aiNJdAC1/SiYSp9dYHu/JtGLZkMSvutEjSaoJdkq0ZG+ou+OKvvV3R2O+ITlWQpJ6y/qH/iqwz/tq4pR1lUwacJ5+Wqz9Nhkymv+BSQPOeCLxllG6sgtRCAp2IQpBwS5EISjYhSgEBbsQhaBgF6IQmpp622XkUD5z2Reaech28/jypAKMZwP7zxs7WHao2Vk67IRYGnhAtX1lkuYjSQ8m+7nlROcqsjdOtida+ATPnvlZGV1SEndp0pwzLG0DHh1Vbf9Zn3tDn68xudK+KpmCruxCFIKCXYhCULALUQgKdiEKQcEuRCE0dTX+tcCylqz4oJlkq9aXxtLKqA9a3B8NggKfnkTyTH30p4nfIdXmd5wZuzzwTDJesL0WAJnfMe33e2BB7HJJcL+y3Imu7EIUgoJdiEJQsAtRCAp2IQpBwS5EISjYhSiEtmz/NAK4ChhCbbunqe5+oZntCFwPjKS2BdSJ7v5c1021faznz6HWN0lr9W6Jtzta36EZNYvX6WY9UxJtRKIFGceW5Jn6lqQ/3cDVsTY7Scv12ybWlgb9Et8Wt2Vk3YvVdt8Y+7Tlyr4B+JS77wnsD3zczPYEzgSmu/sYYHr9byFED6XVYHf3Re7+YP32amA2MAw4Friy/m9XAsd11SSFEB2nXZ/ZzWwkMA64Dxji7pua7i6m9jZfCNFDaXOwm1l/4Ebgk+6+RY28uzu1z/NVflPMbKaZzVy2bFmHJiuEaJw2BbuZ9aEW6Fe7+0118xIzG1rXhxJ8Ldfdp7r7eHcfP3jw4M6YsxCiAVoNdjMzaku8s939/M2kW4BT67dPBbJyBCFEN9OWqreDgA8ALWb2UN12FvAN4AYzOw14Gjixa6YIKwL7GqKtjmCl3x5qu7Ak1Na2dVKiqbzz4li779extn2wS1L2xF+UtOT70K57h9rxu84Ktazm8PPB1lb7T4p9opZ2jyWX71aD3d1/C1ggH96avxCiZ6Bv0AlRCAp2IQpBwS5EISjYhSgEBbsQhfCaaDi5Y2Dvz+jQZ/GdC0Ptl8vuDrVt+8fzWJtt1yQ6TtaUMeMPsbTDkdX2rDzz+F1j7b1sHWr9kjHvTLSDDqu2Z8V8195TbV+RPEd1ZReiEBTsQhSCgl2IQlCwC1EICnYhCkHBLkQhvCZSb40waOSwUBt5WNzJb1xLnJb73deqa5fe8Zl4Hg/EUp6rmZNo12SDNpEDEu3eBsb7XCxN5g2hNvbM+Gk8N2guOqOy1UqNdVHZF3A+M0Lt6NiNZNs2JgbHW5bMccFT1fb1SVdUXdmFKAQFuxCFoGAXohAU7EIUgoJdiEJo6mr8RuIeb2uC7WwABgZb5/TmhdBn9Oi4SGbN6vavuGfMvjQRs+KOrLP2mHZPo/msbMBneKIlWyt9dVK8LRd7JGN+vtq8VVLwdH2w0g1AUmjyqwNj7ahkyImBfWWSFVj57mr7L8+LfXRlF6IQFOxCFIKCXYhCULALUQgKdiEKQcEuRCG0mnozsxHAVdS2ZHZgqrtfaGbnAB/mrwmks9z91mysrYBtA215ksbpG6TelvLz0OdH158UamfEUvrqtzGwr81SUI0WrUxr0K+ZtD9LCcFjCcAHE21xomUN3iZUmzdmTeiyIp5kk7N534q1i+NsL+OCXRI/RFzM1bJNdY/FXh3Z/onaQ/opd3/QzAYAD5jZpqfiBe6e3EUhRE+hLXu9LQIW1W+vNrPZkLzkCCF6JO36zG5mI4FxwH110xlmNsvMLjezHTp5bkKITqTNwW5m/YEbgU+6+yrgEmA3YCy1K3/lF/XMbIqZzTSzmcuWZd8PFUJ0JW0KdjPrQy3Qr3b3mwDcfYm7v+LuG4EfECyFuPtUdx/v7uMHDx7cWfMWQrSTVoPdzAy4DJjt7udvZh+62b8dDzzS+dMTQnQWbVmNPwj4ANBiZg/VbWcBJ5vZWGrpuPnA6a0NtIZ13MPsSm3RM/NCv5ZqF354R5xDu/621mZTTZRe61H8e6Jd1MnHOjuW+u4Va+tPCISst16jJOmwsJJueeJzQ6JlyeUGtwf7TlDxuVeQXgP4waxq+8tJ9WhbVuN/C1QV26U5dSFEz0LfoBOiEBTsQhSCgl2IQlCwC1EICnYhCqGpDSdXvbycaYuuqNRa7rk69FszpzoFcecfkoNlTQNf4xz+vlib3tmptytjaX1W7bdfYI93T2qcUYk2IrD3afBYDabXsgaiDwfP45uTBpaDg/u1tG/soyu7EIWgYBeiEBTsQhSCgl2IQlCwC1EICnYhCqGpqbeXXljBnPurU2y9B8QVPoOCpoETkz2+pv93rG0fS6xKtIgjk/3cft1gudDhUeoKGDcu1qZHFXGNpuTmJ9rARItSTVmTyiyVmtFI48vDEu2fEq3RBqJZtV+wV+A3kr3v9jmy2r6iV+yjK7sQhaBgF6IQFOxCFIKCXYhCULALUQgKdiEKobmpt+dfZu6t1Sm2/lF1ErAgmOUuQUoO4NifxNrypNngymQe6+6qtt/baDomYXpSHTb9zMQx6Na97fdjl7XnJOMlzRzf9v5Y2z14bPolh7o52PMMYH2WwhyeaNFjvS7xSVK6XUKUckxOVktQ6bcxuV+6sgtRCAp2IQpBwS5EISjYhSgEBbsQhdDqaryZ9QPuArau//+P3f1sMxsFXAfsBDwAfMDd12dj7dQPPhQUSDyerIJH9RYbkkKMXfaNtcUPxtrsZGV9Y+U+td1A1gftqmrz2qRf3Du+EmvPJBvvPnpuoh1Rbd82KeL5+rGxNjvRbvdYezraymlR7MPQREsKlBruT/dc+116Byv1LyeX77Zc2V8CJrn7PtS2Zz7KzPYHzgUucPfdqU33tPZNVwjRTFoNdq+x6TWrT/3HgUnAj+v2K4HjumSGQohOoa37s/eq7+C6FJgGzANWuvumSuIFwLCumaIQojNoU7C7+yvuPpbad5UmAG9t6wHMbIqZzTSzmWsa/UwjhOgw7VqNd/eVwJ3AAcBAM9u0wDccqPwerLtPdffx7j6+f/8OzVUI0QFaDXYzG2xmA+u3twEmA7OpBf0J9X87FUi+2SyE6G7MPclbAGa2N7UFuF7UXhxucPcvm9loaqm3Hal9lf8Ud38pG2vsUPPbgjX7BZ/ZOvS79rzqYa9NiiOeS4oZdkjSLs9Ni7W1sdT5DEq0pACIBnvehUxMtKToYvsg9bYq2ZbrTUk+512TYi2o/QHgoier7SsuTJyStC1JKjLdciyb5E2BPeutFxU2TQF/3K1KajXP7u6zgL/Jjrr7k+RPOyFED0LfoBOiEBTsQhSCgl2IQlCwC1EICnYhCqHV1FunHsxsGfB0/c9BxB3CmonmsSWax5a81ubxJnevTPQ1Ndi3OLDZTHcf3y0H1zw0jwLnobfxQhSCgl2IQujOYJ/ajcfeHM1jSzSPLXndzKPbPrMLIZqL3sYLUQjdEuxmdpSZ/dHM5ppZtplRV89jvpm1mNlDZjazice93MyWmtkjm9l2NLNpZjan/nuHbprHOWa2sH5OHjKzY5owjxFmdqeZPWZmj5rZJ+r2pp6TZB5NPSdm1s/M7jezh+vz+FLdPsrM7qvHzfVm1rddA7t7U3+olcrOA0YDfYGHgT2bPY/6XOYDg7rhuIdQK6R8ZDPbN4Ez67fPBM7tpnmcA/xXk8/HUGDf+u0BwBPAns0+J8k8mnpOAAP612/3Ae4D9gduAE6q278PfLQ943bHlX0CMNfdn/Ra6+nrgKRR8OsPd78LWPEq87HU+gZAkxp4BvNoOu6+yN0frN9eTa05yjCafE6SeTQVr9HpTV67I9iHAc9s9nd3Nqt04DYze8DMpnTTHDYxxN03tdVYDAzpxrmcYWaz6m/zu/zjxOaY2Uhq/RPuoxvPyavmAU0+J13R5LX0BbqD3X1f4Gjg42Z2SHdPCGqv7NReiLqDS4DdqO0RsAho2tYYZtYfuBH4pLuv2lxr5jmpmEfTz4l3oMlrRHcE+0Jg8/1fwmaVXY27L6z/XgrcTPd23lliZkMB6r+Xdsck3H1J/Ym2EfgBTTonZtaHWoBd7e6bGjU1/ZxUzaO7zkn92O1u8hrRHcE+AxhTX1nsC5wE3NLsSZjZdmY2YNNt4AjgkdyrS7mFWuNO6MYGnpuCq87xNOGcmJkBlwGz3f38zaSmnpNoHs0+J13W5LVZK4yvWm08htpK5zzgc900h9HUMgEPA482cx7AtdTeDr5M7bPXadT2zJsOzAFuB3bspnn8EGgBZlELtqFNmMfB1N6izwIeqv8c0+xzksyjqecE2JtaE9dZ1F5YvrjZc/Z+YC7wI2Dr9oyrb9AJUQilL9AJUQwKdiEKQcEuRCEo2IUoBAW7EIWgYBeiEBTsQhSCgl2IQvh/Ns0asD4gawYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"eCjnBFk29lXw","executionInfo":{"status":"ok","timestamp":1601210785779,"user_tz":-120,"elapsed":43245,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7fb14a57-c5b3-4845-fafe-983e8c7bbf54","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["img_batch = img.view(-1).unsqueeze(0)\n","\n","out = model(img_batch)\n","out"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5384, 0.4616]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"_3bhydS3-mQs","executionInfo":{"status":"ok","timestamp":1601210785779,"user_tz":-120,"elapsed":43233,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"6b50d3ea-02ba-4afe-a200-ce8feb8ba814","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["_, index = torch.max(out, dim = 1)\n","index, class_names[index]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0]), 'airplane')"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"vl4fLEw4dYQA"},"source":["## Perform Training Loop w/ nn.Sequential-like Instance"]},{"cell_type":"markdown","metadata":{"id":"YkQX-dwMM33q"},"source":["### LogSoftmax instead of Softmax - Test w/Modular Pytorch API"]},{"cell_type":"code","metadata":{"id":"618v2NBuNYUK"},"source":["model = nn.Sequential(\n","    nn.Linear(3072, 512), nn.Tanh(),\n","    nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqJp1hBvNw5E","executionInfo":{"status":"ok","timestamp":1601210786129,"user_tz":-120,"elapsed":43559,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"dd81d3d8-2f47-477e-e859-941cd7d0044d","colab":{"base_uri":"https://localhost:8080/"}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=3072, out_features=512, bias=True)\n","  (1): Tanh()\n","  (2): Linear(in_features=512, out_features=2, bias=True)\n","  (3): LogSoftmax(dim=1)\n",")"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"wICGI2B5e70H","executionInfo":{"status":"ok","timestamp":1601210786130,"user_tz":-120,"elapsed":43549,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7a6d569c-76bc-48a4-b6c4-90e29b3e4aaf","colab":{"base_uri":"https://localhost:8080/"}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1574402, [1572864, 512, 1024, 2])"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"XUxTZg4OO_EP"},"source":["loss = nn.NLLLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hex2MmRmPETv","executionInfo":{"status":"ok","timestamp":1601210786131,"user_tz":-120,"elapsed":43527,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"bc17b46b-3390-46ea-be11-1e02323a3432","colab":{"base_uri":"https://localhost:8080/"}},"source":["img, label = cifar2[0]\n","out = model(img.view(-1).unsqueeze(0))\n","\n","loss(out, torch.tensor([label]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5532, grad_fn=<NllLossBackward>)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"Fj190RmgPizO"},"source":["learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgzW46YlQCUe"},"source":["n_epochs = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rG8bDdcOQCTb"},"source":["# training_loop(model, loss, optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7lLTMlO9Ug3Y"},"source":["### Minibatch Strategy for Updating in a wiser way Model's Parameters"]},{"cell_type":"code","metadata":{"id":"5ObQ4FOJUfi0"},"source":["learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.NLLLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOMVn5PXZAU0"},"source":["### Somewhat Arbitrarily Deeper Model - LogSoftmax + NLLLoss - Test w/ Modular Pytorch API"]},{"cell_type":"code","metadata":{"id":"yhQvDoeFY7AV"},"source":["model = nn.Sequential(\n","    nn.Linear(3072, 1024), nn.Tanh(),\n","    nn.Linear(1024, 512), nn.Tanh(),\n","    nn.Linear(512, 128), nn.Tanh(),\n","    nn.Linear(128, 2), nn.LogSoftmax(dim=1)\n",")\n","\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.NLLLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRvpiJSce24r"},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaAqIcAafA7d","executionInfo":{"status":"ok","timestamp":1601210786134,"user_tz":-120,"elapsed":43421,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"3e60fe62-db09-4fad-c03b-10740f6ffc90","colab":{"base_uri":"https://localhost:8080/"}},"source":["sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"jSbl0FlKY_kv"},"source":["# batched_training_loop(model, loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Vb4s9kEcFUj"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"IcN0tMHTbWiG"},"source":["### Somewhat Arbitrarily Deeper Model - CrossEntropyLoss - Test w/ Modular Pytorch API"]},{"cell_type":"code","metadata":{"id":"VlOrNJFnbCMO"},"source":["model = nn.Sequential(\n","    nn.Linear(3072, 1024), nn.Tanh(),\n","    nn.Linear(1024, 512), nn.Tanh(),\n","    nn.Linear(512, 128), nn.Tanh(),\n","    nn.Linear(128, 2)\n",")\n","\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k34Fd1VResV6"},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quWpuHKWe_la","executionInfo":{"status":"ok","timestamp":1601210786136,"user_tz":-120,"elapsed":43372,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"55923f0f-df88-428c-8415-aac241f655d1","colab":{"base_uri":"https://localhost:8080/"}},"source":["sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"-sgDKwZVa__F"},"source":["# batched_training_loop(model, loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYwz3C7Qe9dP"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'fc_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQ9rktLgG_2Q"},"source":["### Convolutional Neural Network Example - Modular Pytorch API"]},{"cell_type":"code","metadata":{"id":"uMs31SfdHAJ4"},"source":["model = nn.Sequential(\n","    nn.Conv2d(3, 16, kernel_size = 3, padding = 1), nn.Tanh(),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(16, 8, kernel_size = 3, padding = 1), nn.Tanh(),\n","    nn.MaxPool2d(2),\n","    nn.Flatten(),\n","    nn.Linear(8 * 8 * 8, 32), nn.Tanh(),\n","    nn.Linear(32, 2)\n",")\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HB5bxEnHI6r","executionInfo":{"status":"ok","timestamp":1601210786138,"user_tz":-120,"elapsed":43328,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"fc1b4ca1-955c-4293-c9ce-5cc3fc3d9c1a","colab":{"base_uri":"https://localhost:8080/"}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): Tanh()\n","  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (4): Tanh()\n","  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (6): Flatten()\n","  (7): Linear(in_features=512, out_features=32, bias=True)\n","  (8): Tanh()\n","  (9): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"TUGI1X3VHC4v"},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78usGyo_HFbp","executionInfo":{"status":"ok","timestamp":1601210786139,"user_tz":-120,"elapsed":43306,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"97f420db-d708-47a2-cf60-577790183c60","colab":{"base_uri":"https://localhost:8080/"}},"source":["sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"_oC8plROHS1E"},"source":["# batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5X3LfV8eDu8"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'convnet_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzbo5a8AjH_Z","executionInfo":{"status":"ok","timestamp":1601210786140,"user_tz":-120,"elapsed":43271,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"6d2b3507-f3a6-4e7f-b95b-b996d8823045","colab":{"base_uri":"https://localhost:8080/"}},"source":["\"\"\"loaded_model = model.load_state_dict(\n","    torch.load(\n","        data_path + 'convnet_birds_vs_airplane.pt',\n","        map_location = device\n","    )\n",")\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"loaded_model = model.load_state_dict(\\n    torch.load(\\n        data_path + 'convnet_birds_vs_airplane.pt',\\n        map_location = device\\n    )\\n)\\n\""]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"g1S3Rp9X3rPX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Frw9Su0wpqVp"},"source":["## Perform Training Loop w/ subclassing nn.Module"]},{"cell_type":"markdown","metadata":{"id":"AtrpXlFffes6"},"source":["### Training by means of an instance of subclassed nn.Module Net class"]},{"cell_type":"code","metadata":{"id":"7J1VK7i6feTc"},"source":["model = Net()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EtvBh8lfsY5","executionInfo":{"status":"ok","timestamp":1601210786142,"user_tz":-120,"elapsed":43237,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"f9aff4cd-abdc-4a7b-d4fe-82f59ebffc75","colab":{"base_uri":"https://localhost:8080/"}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): Tanh()\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): Tanh()\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=512, out_features=32, bias=True)\n","  (act3): Tanh()\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"3F_50tZWfu97","executionInfo":{"status":"ok","timestamp":1601210786142,"user_tz":-120,"elapsed":43225,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4711bda2-d4a0-42d8-95c0-9f69a30f5703","colab":{"base_uri":"https://localhost:8080/"}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"E_hSlc9Ifzlv","executionInfo":{"status":"ok","timestamp":1601210895291,"user_tz":-120,"elapsed":152362,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"1db02441-9ac0-4cd5-b048-623125aaf924","colab":{"base_uri":"https://localhost:8080/"}},"source":["batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:46:33.693786 Epoch: 1, Trainin Loss: 0.46000 Accuracy train: 0.77140 Accuracy val: 0.78150\n","2020-09-27 12:46:34.694737 Epoch: 2, Trainin Loss: 0.38923 Accuracy train: 0.78570 Accuracy val: 0.80300\n","2020-09-27 12:46:35.693035 Epoch: 3, Trainin Loss: 0.35483 Accuracy train: 0.79960 Accuracy val: 0.81200\n","2020-09-27 12:46:36.701816 Epoch: 4, Trainin Loss: 0.32905 Accuracy train: 0.80820 Accuracy val: 0.82100\n","2020-09-27 12:46:37.695642 Epoch: 5, Trainin Loss: 0.48191 Accuracy train: 0.82660 Accuracy val: 0.82750\n","2020-09-27 12:46:38.696044 Epoch: 6, Trainin Loss: 0.42500 Accuracy train: 0.83170 Accuracy val: 0.83350\n","2020-09-27 12:46:39.715881 Epoch: 7, Trainin Loss: 0.33206 Accuracy train: 0.84450 Accuracy val: 0.84100\n","2020-09-27 12:46:40.723368 Epoch: 8, Trainin Loss: 0.59311 Accuracy train: 0.85200 Accuracy val: 0.84000\n","2020-09-27 12:46:41.729142 Epoch: 9, Trainin Loss: 0.58132 Accuracy train: 0.84850 Accuracy val: 0.84350\n","2020-09-27 12:46:42.732085 Epoch: 10, Trainin Loss: 0.29605 Accuracy train: 0.85530 Accuracy val: 0.85650\n","2020-09-27 12:46:43.745446 Epoch: 11, Trainin Loss: 0.53464 Accuracy train: 0.86000 Accuracy val: 0.85450\n","2020-09-27 12:46:44.746938 Epoch: 12, Trainin Loss: 0.21302 Accuracy train: 0.86380 Accuracy val: 0.85900\n","2020-09-27 12:46:45.755073 Epoch: 13, Trainin Loss: 0.28849 Accuracy train: 0.86120 Accuracy val: 0.86400\n","2020-09-27 12:46:46.769445 Epoch: 14, Trainin Loss: 0.25050 Accuracy train: 0.87000 Accuracy val: 0.86150\n","2020-09-27 12:46:47.764009 Epoch: 15, Trainin Loss: 0.41668 Accuracy train: 0.87060 Accuracy val: 0.86650\n","2020-09-27 12:46:48.764801 Epoch: 16, Trainin Loss: 0.24872 Accuracy train: 0.85880 Accuracy val: 0.85350\n","2020-09-27 12:46:49.777612 Epoch: 17, Trainin Loss: 0.20314 Accuracy train: 0.87780 Accuracy val: 0.87100\n","2020-09-27 12:46:50.779621 Epoch: 18, Trainin Loss: 0.27807 Accuracy train: 0.87570 Accuracy val: 0.86700\n","2020-09-27 12:46:51.789894 Epoch: 19, Trainin Loss: 0.33426 Accuracy train: 0.86830 Accuracy val: 0.85750\n","2020-09-27 12:46:52.805395 Epoch: 20, Trainin Loss: 0.25084 Accuracy train: 0.87970 Accuracy val: 0.87450\n","2020-09-27 12:46:53.809561 Epoch: 21, Trainin Loss: 0.43540 Accuracy train: 0.87700 Accuracy val: 0.87700\n","2020-09-27 12:46:54.817319 Epoch: 22, Trainin Loss: 0.11123 Accuracy train: 0.88190 Accuracy val: 0.87450\n","2020-09-27 12:46:55.808014 Epoch: 23, Trainin Loss: 0.62957 Accuracy train: 0.85500 Accuracy val: 0.84050\n","2020-09-27 12:46:56.797976 Epoch: 24, Trainin Loss: 0.11835 Accuracy train: 0.87050 Accuracy val: 0.85850\n","2020-09-27 12:46:57.799465 Epoch: 25, Trainin Loss: 0.42984 Accuracy train: 0.88040 Accuracy val: 0.87600\n","2020-09-27 12:46:58.801919 Epoch: 26, Trainin Loss: 0.32591 Accuracy train: 0.88220 Accuracy val: 0.86950\n","2020-09-27 12:46:59.822128 Epoch: 27, Trainin Loss: 0.39717 Accuracy train: 0.88820 Accuracy val: 0.87200\n","2020-09-27 12:47:00.820435 Epoch: 28, Trainin Loss: 0.12954 Accuracy train: 0.89210 Accuracy val: 0.87600\n","2020-09-27 12:47:01.828016 Epoch: 29, Trainin Loss: 0.16701 Accuracy train: 0.89200 Accuracy val: 0.88200\n","2020-09-27 12:47:02.827804 Epoch: 30, Trainin Loss: 0.20118 Accuracy train: 0.88220 Accuracy val: 0.87350\n","2020-09-27 12:47:03.824327 Epoch: 31, Trainin Loss: 0.32984 Accuracy train: 0.89090 Accuracy val: 0.87050\n","2020-09-27 12:47:04.830131 Epoch: 32, Trainin Loss: 0.29632 Accuracy train: 0.89030 Accuracy val: 0.87300\n","2020-09-27 12:47:05.836204 Epoch: 33, Trainin Loss: 0.29210 Accuracy train: 0.88790 Accuracy val: 0.87900\n","2020-09-27 12:47:06.842527 Epoch: 34, Trainin Loss: 0.10208 Accuracy train: 0.89350 Accuracy val: 0.88200\n","2020-09-27 12:47:07.836968 Epoch: 35, Trainin Loss: 0.30369 Accuracy train: 0.88670 Accuracy val: 0.86550\n","2020-09-27 12:47:08.842738 Epoch: 36, Trainin Loss: 0.19914 Accuracy train: 0.88910 Accuracy val: 0.87950\n","2020-09-27 12:47:09.836612 Epoch: 37, Trainin Loss: 0.15508 Accuracy train: 0.89920 Accuracy val: 0.88050\n","2020-09-27 12:47:10.846792 Epoch: 38, Trainin Loss: 0.66531 Accuracy train: 0.90080 Accuracy val: 0.88150\n","2020-09-27 12:47:11.848192 Epoch: 39, Trainin Loss: 0.18407 Accuracy train: 0.89510 Accuracy val: 0.88150\n","2020-09-27 12:47:12.848004 Epoch: 40, Trainin Loss: 0.18403 Accuracy train: 0.90030 Accuracy val: 0.88400\n","2020-09-27 12:47:13.865303 Epoch: 41, Trainin Loss: 0.28925 Accuracy train: 0.89930 Accuracy val: 0.88400\n","2020-09-27 12:47:14.868855 Epoch: 42, Trainin Loss: 0.29639 Accuracy train: 0.89600 Accuracy val: 0.88200\n","2020-09-27 12:47:15.869881 Epoch: 43, Trainin Loss: 0.21565 Accuracy train: 0.90050 Accuracy val: 0.87500\n","2020-09-27 12:47:16.875281 Epoch: 44, Trainin Loss: 0.18545 Accuracy train: 0.90240 Accuracy val: 0.88550\n","2020-09-27 12:47:17.876977 Epoch: 45, Trainin Loss: 0.29778 Accuracy train: 0.90770 Accuracy val: 0.88550\n","2020-09-27 12:47:18.889011 Epoch: 46, Trainin Loss: 0.10520 Accuracy train: 0.90430 Accuracy val: 0.88300\n","2020-09-27 12:47:19.901975 Epoch: 47, Trainin Loss: 0.18941 Accuracy train: 0.90220 Accuracy val: 0.88100\n","2020-09-27 12:47:20.912832 Epoch: 48, Trainin Loss: 0.32779 Accuracy train: 0.90680 Accuracy val: 0.88150\n","2020-09-27 12:47:21.912568 Epoch: 49, Trainin Loss: 0.18626 Accuracy train: 0.90510 Accuracy val: 0.87400\n","2020-09-27 12:47:22.928507 Epoch: 50, Trainin Loss: 0.17090 Accuracy train: 0.90740 Accuracy val: 0.88950\n","2020-09-27 12:47:23.945984 Epoch: 51, Trainin Loss: 0.24447 Accuracy train: 0.90520 Accuracy val: 0.88300\n","2020-09-27 12:47:24.958917 Epoch: 52, Trainin Loss: 0.23579 Accuracy train: 0.89970 Accuracy val: 0.88500\n","2020-09-27 12:47:25.967107 Epoch: 53, Trainin Loss: 0.23627 Accuracy train: 0.90300 Accuracy val: 0.86950\n","2020-09-27 12:47:26.988596 Epoch: 54, Trainin Loss: 0.08295 Accuracy train: 0.91150 Accuracy val: 0.88450\n","2020-09-27 12:47:28.004125 Epoch: 55, Trainin Loss: 0.14344 Accuracy train: 0.91330 Accuracy val: 0.88700\n","2020-09-27 12:47:29.018103 Epoch: 56, Trainin Loss: 0.17648 Accuracy train: 0.90030 Accuracy val: 0.86750\n","2020-09-27 12:47:30.045122 Epoch: 57, Trainin Loss: 0.17587 Accuracy train: 0.90860 Accuracy val: 0.87550\n","2020-09-27 12:47:31.073782 Epoch: 58, Trainin Loss: 0.03441 Accuracy train: 0.91620 Accuracy val: 0.88650\n","2020-09-27 12:47:32.081226 Epoch: 59, Trainin Loss: 0.20883 Accuracy train: 0.91120 Accuracy val: 0.88750\n","2020-09-27 12:47:33.089642 Epoch: 60, Trainin Loss: 0.27619 Accuracy train: 0.89470 Accuracy val: 0.85350\n","2020-09-27 12:47:34.094336 Epoch: 61, Trainin Loss: 0.05742 Accuracy train: 0.91880 Accuracy val: 0.88150\n","2020-09-27 12:47:35.095251 Epoch: 62, Trainin Loss: 0.16995 Accuracy train: 0.91320 Accuracy val: 0.88550\n","2020-09-27 12:47:36.091500 Epoch: 63, Trainin Loss: 0.27411 Accuracy train: 0.90100 Accuracy val: 0.86600\n","2020-09-27 12:47:37.087451 Epoch: 64, Trainin Loss: 0.29085 Accuracy train: 0.91720 Accuracy val: 0.88400\n","2020-09-27 12:47:38.088542 Epoch: 65, Trainin Loss: 0.12585 Accuracy train: 0.91360 Accuracy val: 0.86750\n","2020-09-27 12:47:39.091181 Epoch: 66, Trainin Loss: 0.25033 Accuracy train: 0.92340 Accuracy val: 0.88450\n","2020-09-27 12:47:40.098299 Epoch: 67, Trainin Loss: 0.08001 Accuracy train: 0.91570 Accuracy val: 0.88500\n","2020-09-27 12:47:41.105375 Epoch: 68, Trainin Loss: 0.33098 Accuracy train: 0.90890 Accuracy val: 0.86700\n","2020-09-27 12:47:42.116096 Epoch: 69, Trainin Loss: 0.12905 Accuracy train: 0.92310 Accuracy val: 0.88250\n","2020-09-27 12:47:43.116569 Epoch: 70, Trainin Loss: 0.17786 Accuracy train: 0.92450 Accuracy val: 0.88400\n","2020-09-27 12:47:44.127748 Epoch: 71, Trainin Loss: 0.09720 Accuracy train: 0.92570 Accuracy val: 0.88500\n","2020-09-27 12:47:45.127386 Epoch: 72, Trainin Loss: 0.12837 Accuracy train: 0.92750 Accuracy val: 0.89400\n","2020-09-27 12:47:46.129939 Epoch: 73, Trainin Loss: 0.43663 Accuracy train: 0.90060 Accuracy val: 0.85600\n","2020-09-27 12:47:47.134893 Epoch: 74, Trainin Loss: 0.08107 Accuracy train: 0.92610 Accuracy val: 0.88500\n","2020-09-27 12:47:48.133445 Epoch: 75, Trainin Loss: 0.18374 Accuracy train: 0.92160 Accuracy val: 0.88550\n","2020-09-27 12:47:49.137305 Epoch: 76, Trainin Loss: 0.05903 Accuracy train: 0.92790 Accuracy val: 0.88750\n","2020-09-27 12:47:50.140384 Epoch: 77, Trainin Loss: 0.11312 Accuracy train: 0.92340 Accuracy val: 0.89050\n","2020-09-27 12:47:51.147565 Epoch: 78, Trainin Loss: 0.08681 Accuracy train: 0.92520 Accuracy val: 0.88950\n","2020-09-27 12:47:52.160790 Epoch: 79, Trainin Loss: 0.05044 Accuracy train: 0.93110 Accuracy val: 0.88850\n","2020-09-27 12:47:53.165246 Epoch: 80, Trainin Loss: 0.11632 Accuracy train: 0.92990 Accuracy val: 0.89100\n","2020-09-27 12:47:54.180686 Epoch: 81, Trainin Loss: 0.24781 Accuracy train: 0.91360 Accuracy val: 0.87900\n","2020-09-27 12:47:55.182648 Epoch: 82, Trainin Loss: 0.05892 Accuracy train: 0.93260 Accuracy val: 0.88900\n","2020-09-27 12:47:56.180935 Epoch: 83, Trainin Loss: 0.03122 Accuracy train: 0.93550 Accuracy val: 0.88400\n","2020-09-27 12:47:57.171161 Epoch: 84, Trainin Loss: 0.13504 Accuracy train: 0.93090 Accuracy val: 0.89050\n","2020-09-27 12:47:58.173306 Epoch: 85, Trainin Loss: 0.08645 Accuracy train: 0.93460 Accuracy val: 0.88550\n","2020-09-27 12:47:59.180234 Epoch: 86, Trainin Loss: 0.15405 Accuracy train: 0.93220 Accuracy val: 0.88700\n","2020-09-27 12:48:00.179826 Epoch: 87, Trainin Loss: 0.16955 Accuracy train: 0.90300 Accuracy val: 0.85300\n","2020-09-27 12:48:01.183723 Epoch: 88, Trainin Loss: 0.18679 Accuracy train: 0.93290 Accuracy val: 0.88250\n","2020-09-27 12:48:02.202615 Epoch: 89, Trainin Loss: 0.15370 Accuracy train: 0.92810 Accuracy val: 0.88050\n","2020-09-27 12:48:03.206037 Epoch: 90, Trainin Loss: 0.21143 Accuracy train: 0.92700 Accuracy val: 0.87450\n","2020-09-27 12:48:04.203849 Epoch: 91, Trainin Loss: 0.09303 Accuracy train: 0.93200 Accuracy val: 0.88250\n","2020-09-27 12:48:05.200412 Epoch: 92, Trainin Loss: 0.14518 Accuracy train: 0.92920 Accuracy val: 0.88500\n","2020-09-27 12:48:06.194171 Epoch: 93, Trainin Loss: 0.19745 Accuracy train: 0.93990 Accuracy val: 0.88600\n","2020-09-27 12:48:07.187137 Epoch: 94, Trainin Loss: 0.02277 Accuracy train: 0.93700 Accuracy val: 0.89000\n","2020-09-27 12:48:08.183184 Epoch: 95, Trainin Loss: 0.30802 Accuracy train: 0.93210 Accuracy val: 0.86950\n","2020-09-27 12:48:09.183647 Epoch: 96, Trainin Loss: 0.04512 Accuracy train: 0.94560 Accuracy val: 0.88300\n","2020-09-27 12:48:10.184530 Epoch: 97, Trainin Loss: 0.11447 Accuracy train: 0.94460 Accuracy val: 0.89000\n","2020-09-27 12:48:11.179041 Epoch: 98, Trainin Loss: 0.16255 Accuracy train: 0.94200 Accuracy val: 0.88550\n","2020-09-27 12:48:12.173096 Epoch: 99, Trainin Loss: 0.14146 Accuracy train: 0.94500 Accuracy val: 0.88350\n","2020-09-27 12:48:13.190085 Epoch: 100, Trainin Loss: 0.12319 Accuracy train: 0.93400 Accuracy val: 0.88100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UUvUHnmCf23C"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'Net_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uq4rnCCRqrzY"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'Net_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8OFpGiWVhmAI"},"source":["### Setting Width of first Conv Layer via an instance of NetWidth Class w/ Functional API exploited for Pool Layer"]},{"cell_type":"code","metadata":{"id":"uVLgxpNxhmUj"},"source":["model = NetWidth()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDvl8cOeh6yW","executionInfo":{"status":"ok","timestamp":1601210895293,"user_tz":-120,"elapsed":152319,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"1192f2df-310a-454c-aea4-8e8e63af5787","colab":{"base_uri":"https://localhost:8080/"}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NetWidth(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"fOt9jn6Hh77F","executionInfo":{"status":"ok","timestamp":1601210895294,"user_tz":-120,"elapsed":152306,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"8e3bffd3-d960-4a99-efff-b30f5d1c0848","colab":{"base_uri":"https://localhost:8080/"}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(38386, [864, 32, 4608, 16, 32768, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"p5HmgeLmh9ZA","executionInfo":{"status":"ok","timestamp":1601211009941,"user_tz":-120,"elapsed":266943,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"a500a03e-22f8-45e9-e880-9058721fa188","colab":{"base_uri":"https://localhost:8080/"}},"source":["batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:48:14.426536 Epoch: 1, Trainin Loss: 0.61545 Accuracy train: 0.78270 Accuracy val: 0.79000\n","2020-09-27 12:48:15.570275 Epoch: 2, Trainin Loss: 0.47434 Accuracy train: 0.79840 Accuracy val: 0.80650\n","2020-09-27 12:48:16.715613 Epoch: 3, Trainin Loss: 0.36708 Accuracy train: 0.80960 Accuracy val: 0.81300\n","2020-09-27 12:48:17.854553 Epoch: 4, Trainin Loss: 0.41275 Accuracy train: 0.83520 Accuracy val: 0.82950\n","2020-09-27 12:48:19.000445 Epoch: 5, Trainin Loss: 0.42313 Accuracy train: 0.84630 Accuracy val: 0.83650\n","2020-09-27 12:48:20.149989 Epoch: 6, Trainin Loss: 0.39545 Accuracy train: 0.85050 Accuracy val: 0.83850\n","2020-09-27 12:48:21.296088 Epoch: 7, Trainin Loss: 0.20841 Accuracy train: 0.85260 Accuracy val: 0.84350\n","2020-09-27 12:48:22.436530 Epoch: 8, Trainin Loss: 0.25730 Accuracy train: 0.85830 Accuracy val: 0.84000\n","2020-09-27 12:48:23.589588 Epoch: 9, Trainin Loss: 0.47417 Accuracy train: 0.86350 Accuracy val: 0.84400\n","2020-09-27 12:48:24.727997 Epoch: 10, Trainin Loss: 0.19551 Accuracy train: 0.85880 Accuracy val: 0.84800\n","2020-09-27 12:48:25.876627 Epoch: 11, Trainin Loss: 0.27683 Accuracy train: 0.86830 Accuracy val: 0.85350\n","2020-09-27 12:48:27.019310 Epoch: 12, Trainin Loss: 0.47861 Accuracy train: 0.86750 Accuracy val: 0.85900\n","2020-09-27 12:48:28.158260 Epoch: 13, Trainin Loss: 0.29184 Accuracy train: 0.85590 Accuracy val: 0.84550\n","2020-09-27 12:48:29.301946 Epoch: 14, Trainin Loss: 0.13986 Accuracy train: 0.87350 Accuracy val: 0.86250\n","2020-09-27 12:48:30.442571 Epoch: 15, Trainin Loss: 0.28284 Accuracy train: 0.87000 Accuracy val: 0.86000\n","2020-09-27 12:48:31.583752 Epoch: 16, Trainin Loss: 0.19718 Accuracy train: 0.88020 Accuracy val: 0.87100\n","2020-09-27 12:48:32.728725 Epoch: 17, Trainin Loss: 0.15798 Accuracy train: 0.88370 Accuracy val: 0.86800\n","2020-09-27 12:48:33.887255 Epoch: 18, Trainin Loss: 0.17469 Accuracy train: 0.86580 Accuracy val: 0.85750\n","2020-09-27 12:48:35.037868 Epoch: 19, Trainin Loss: 0.08297 Accuracy train: 0.88070 Accuracy val: 0.87300\n","2020-09-27 12:48:36.181766 Epoch: 20, Trainin Loss: 0.10837 Accuracy train: 0.88620 Accuracy val: 0.87300\n","2020-09-27 12:48:37.319743 Epoch: 21, Trainin Loss: 0.34367 Accuracy train: 0.86420 Accuracy val: 0.85600\n","2020-09-27 12:48:38.457471 Epoch: 22, Trainin Loss: 0.27988 Accuracy train: 0.88570 Accuracy val: 0.87500\n","2020-09-27 12:48:39.600423 Epoch: 23, Trainin Loss: 0.25853 Accuracy train: 0.89330 Accuracy val: 0.87850\n","2020-09-27 12:48:40.740849 Epoch: 24, Trainin Loss: 0.22160 Accuracy train: 0.89330 Accuracy val: 0.87900\n","2020-09-27 12:48:41.888317 Epoch: 25, Trainin Loss: 0.63275 Accuracy train: 0.89000 Accuracy val: 0.87800\n","2020-09-27 12:48:43.034460 Epoch: 26, Trainin Loss: 0.36127 Accuracy train: 0.89260 Accuracy val: 0.86750\n","2020-09-27 12:48:44.192772 Epoch: 27, Trainin Loss: 0.24332 Accuracy train: 0.88150 Accuracy val: 0.87750\n","2020-09-27 12:48:45.340488 Epoch: 28, Trainin Loss: 0.39574 Accuracy train: 0.83780 Accuracy val: 0.81750\n","2020-09-27 12:48:46.488647 Epoch: 29, Trainin Loss: 0.16224 Accuracy train: 0.88750 Accuracy val: 0.87700\n","2020-09-27 12:48:47.641763 Epoch: 30, Trainin Loss: 0.26182 Accuracy train: 0.90000 Accuracy val: 0.88600\n","2020-09-27 12:48:48.791191 Epoch: 31, Trainin Loss: 0.18322 Accuracy train: 0.90090 Accuracy val: 0.88550\n","2020-09-27 12:48:49.936783 Epoch: 32, Trainin Loss: 0.04781 Accuracy train: 0.90750 Accuracy val: 0.88750\n","2020-09-27 12:48:51.080684 Epoch: 33, Trainin Loss: 0.37667 Accuracy train: 0.91040 Accuracy val: 0.88800\n","2020-09-27 12:48:52.225937 Epoch: 34, Trainin Loss: 0.11670 Accuracy train: 0.90930 Accuracy val: 0.88700\n","2020-09-27 12:48:53.371060 Epoch: 35, Trainin Loss: 0.14230 Accuracy train: 0.91140 Accuracy val: 0.89600\n","2020-09-27 12:48:54.531291 Epoch: 36, Trainin Loss: 0.17458 Accuracy train: 0.91610 Accuracy val: 0.88850\n","2020-09-27 12:48:55.667398 Epoch: 37, Trainin Loss: 0.27405 Accuracy train: 0.91580 Accuracy val: 0.88900\n","2020-09-27 12:48:56.803524 Epoch: 38, Trainin Loss: 0.31111 Accuracy train: 0.89270 Accuracy val: 0.88000\n","2020-09-27 12:48:57.936664 Epoch: 39, Trainin Loss: 0.22004 Accuracy train: 0.91070 Accuracy val: 0.87850\n","2020-09-27 12:48:59.074581 Epoch: 40, Trainin Loss: 0.41829 Accuracy train: 0.85500 Accuracy val: 0.82300\n","2020-09-27 12:49:00.219791 Epoch: 41, Trainin Loss: 0.25842 Accuracy train: 0.91180 Accuracy val: 0.88250\n","2020-09-27 12:49:01.361109 Epoch: 42, Trainin Loss: 0.27023 Accuracy train: 0.90690 Accuracy val: 0.88800\n","2020-09-27 12:49:02.504648 Epoch: 43, Trainin Loss: 0.12894 Accuracy train: 0.89160 Accuracy val: 0.85700\n","2020-09-27 12:49:03.649164 Epoch: 44, Trainin Loss: 0.39695 Accuracy train: 0.88100 Accuracy val: 0.83850\n","2020-09-27 12:49:04.798429 Epoch: 45, Trainin Loss: 0.18781 Accuracy train: 0.92580 Accuracy val: 0.89200\n","2020-09-27 12:49:05.950317 Epoch: 46, Trainin Loss: 0.24207 Accuracy train: 0.91210 Accuracy val: 0.87700\n","2020-09-27 12:49:07.094206 Epoch: 47, Trainin Loss: 0.28685 Accuracy train: 0.90820 Accuracy val: 0.86750\n","2020-09-27 12:49:08.237835 Epoch: 48, Trainin Loss: 0.09763 Accuracy train: 0.92430 Accuracy val: 0.88400\n","2020-09-27 12:49:09.379297 Epoch: 49, Trainin Loss: 0.31771 Accuracy train: 0.91980 Accuracy val: 0.88000\n","2020-09-27 12:49:10.539012 Epoch: 50, Trainin Loss: 0.40492 Accuracy train: 0.90090 Accuracy val: 0.87850\n","2020-09-27 12:49:11.685758 Epoch: 51, Trainin Loss: 0.31268 Accuracy train: 0.91180 Accuracy val: 0.88600\n","2020-09-27 12:49:12.826098 Epoch: 52, Trainin Loss: 0.17679 Accuracy train: 0.92190 Accuracy val: 0.87550\n","2020-09-27 12:49:13.972483 Epoch: 53, Trainin Loss: 0.05405 Accuracy train: 0.93580 Accuracy val: 0.89350\n","2020-09-27 12:49:15.110762 Epoch: 54, Trainin Loss: 0.49967 Accuracy train: 0.90310 Accuracy val: 0.84950\n","2020-09-27 12:49:16.256505 Epoch: 55, Trainin Loss: 0.37575 Accuracy train: 0.93210 Accuracy val: 0.89050\n","2020-09-27 12:49:17.393666 Epoch: 56, Trainin Loss: 0.14797 Accuracy train: 0.93560 Accuracy val: 0.89500\n","2020-09-27 12:49:18.549209 Epoch: 57, Trainin Loss: 0.25414 Accuracy train: 0.93370 Accuracy val: 0.88800\n","2020-09-27 12:49:19.690326 Epoch: 58, Trainin Loss: 0.08364 Accuracy train: 0.93670 Accuracy val: 0.89000\n","2020-09-27 12:49:20.830306 Epoch: 59, Trainin Loss: 0.19491 Accuracy train: 0.92300 Accuracy val: 0.88400\n","2020-09-27 12:49:21.975826 Epoch: 60, Trainin Loss: 0.06712 Accuracy train: 0.93390 Accuracy val: 0.88950\n","2020-09-27 12:49:23.122756 Epoch: 61, Trainin Loss: 0.00759 Accuracy train: 0.94430 Accuracy val: 0.88800\n","2020-09-27 12:49:24.269837 Epoch: 62, Trainin Loss: 0.25016 Accuracy train: 0.93810 Accuracy val: 0.89050\n","2020-09-27 12:49:25.416118 Epoch: 63, Trainin Loss: 0.11119 Accuracy train: 0.94070 Accuracy val: 0.89300\n","2020-09-27 12:49:26.571795 Epoch: 64, Trainin Loss: 0.20150 Accuracy train: 0.93560 Accuracy val: 0.88900\n","2020-09-27 12:49:27.716730 Epoch: 65, Trainin Loss: 0.18479 Accuracy train: 0.92590 Accuracy val: 0.87450\n","2020-09-27 12:49:28.862586 Epoch: 66, Trainin Loss: 0.10806 Accuracy train: 0.94410 Accuracy val: 0.89050\n","2020-09-27 12:49:30.007644 Epoch: 67, Trainin Loss: 0.10639 Accuracy train: 0.93790 Accuracy val: 0.88600\n","2020-09-27 12:49:31.151290 Epoch: 68, Trainin Loss: 0.31290 Accuracy train: 0.87750 Accuracy val: 0.82600\n","2020-09-27 12:49:32.295117 Epoch: 69, Trainin Loss: 0.04877 Accuracy train: 0.94590 Accuracy val: 0.89700\n","2020-09-27 12:49:33.432640 Epoch: 70, Trainin Loss: 0.04025 Accuracy train: 0.93210 Accuracy val: 0.88950\n","2020-09-27 12:49:34.566733 Epoch: 71, Trainin Loss: 0.20980 Accuracy train: 0.94350 Accuracy val: 0.88050\n","2020-09-27 12:49:35.702979 Epoch: 72, Trainin Loss: 0.09729 Accuracy train: 0.94640 Accuracy val: 0.88050\n","2020-09-27 12:49:36.858066 Epoch: 73, Trainin Loss: 0.10876 Accuracy train: 0.93540 Accuracy val: 0.89000\n","2020-09-27 12:49:38.006990 Epoch: 74, Trainin Loss: 0.12962 Accuracy train: 0.92780 Accuracy val: 0.88450\n","2020-09-27 12:49:39.150492 Epoch: 75, Trainin Loss: 0.07389 Accuracy train: 0.95610 Accuracy val: 0.88200\n","2020-09-27 12:49:40.304996 Epoch: 76, Trainin Loss: 0.12061 Accuracy train: 0.95210 Accuracy val: 0.89100\n","2020-09-27 12:49:41.458902 Epoch: 77, Trainin Loss: 0.06732 Accuracy train: 0.93960 Accuracy val: 0.89250\n","2020-09-27 12:49:42.606124 Epoch: 78, Trainin Loss: 0.13389 Accuracy train: 0.95470 Accuracy val: 0.88900\n","2020-09-27 12:49:43.750367 Epoch: 79, Trainin Loss: 0.10418 Accuracy train: 0.95640 Accuracy val: 0.89150\n","2020-09-27 12:49:44.902739 Epoch: 80, Trainin Loss: 0.13976 Accuracy train: 0.95570 Accuracy val: 0.89150\n","2020-09-27 12:49:46.051366 Epoch: 81, Trainin Loss: 0.08022 Accuracy train: 0.94630 Accuracy val: 0.88650\n","2020-09-27 12:49:47.204220 Epoch: 82, Trainin Loss: 0.06844 Accuracy train: 0.96000 Accuracy val: 0.88750\n","2020-09-27 12:49:48.347679 Epoch: 83, Trainin Loss: 0.12201 Accuracy train: 0.95110 Accuracy val: 0.88950\n","2020-09-27 12:49:49.503242 Epoch: 84, Trainin Loss: 0.08163 Accuracy train: 0.96200 Accuracy val: 0.88400\n","2020-09-27 12:49:50.651087 Epoch: 85, Trainin Loss: 0.04094 Accuracy train: 0.96400 Accuracy val: 0.89300\n","2020-09-27 12:49:51.797292 Epoch: 86, Trainin Loss: 0.26167 Accuracy train: 0.93380 Accuracy val: 0.88450\n","2020-09-27 12:49:52.948015 Epoch: 87, Trainin Loss: 0.07733 Accuracy train: 0.94410 Accuracy val: 0.87550\n","2020-09-27 12:49:54.096184 Epoch: 88, Trainin Loss: 0.09955 Accuracy train: 0.96490 Accuracy val: 0.89350\n","2020-09-27 12:49:55.243702 Epoch: 89, Trainin Loss: 0.14992 Accuracy train: 0.95560 Accuracy val: 0.87650\n","2020-09-27 12:49:56.384948 Epoch: 90, Trainin Loss: 0.11060 Accuracy train: 0.95490 Accuracy val: 0.87650\n","2020-09-27 12:49:57.535135 Epoch: 91, Trainin Loss: 0.10906 Accuracy train: 0.94750 Accuracy val: 0.87900\n","2020-09-27 12:49:58.683376 Epoch: 92, Trainin Loss: 0.25043 Accuracy train: 0.91020 Accuracy val: 0.84350\n","2020-09-27 12:49:59.833577 Epoch: 93, Trainin Loss: 0.05551 Accuracy train: 0.96840 Accuracy val: 0.88400\n","2020-09-27 12:50:00.970903 Epoch: 94, Trainin Loss: 0.05881 Accuracy train: 0.97010 Accuracy val: 0.89000\n","2020-09-27 12:50:02.108791 Epoch: 95, Trainin Loss: 0.19653 Accuracy train: 0.95920 Accuracy val: 0.88200\n","2020-09-27 12:50:03.264245 Epoch: 96, Trainin Loss: 0.10799 Accuracy train: 0.94650 Accuracy val: 0.87350\n","2020-09-27 12:50:04.404847 Epoch: 97, Trainin Loss: 0.08055 Accuracy train: 0.97290 Accuracy val: 0.88700\n","2020-09-27 12:50:05.550808 Epoch: 98, Trainin Loss: 0.00815 Accuracy train: 0.98050 Accuracy val: 0.89000\n","2020-09-27 12:50:06.690913 Epoch: 99, Trainin Loss: 0.05098 Accuracy train: 0.98130 Accuracy val: 0.89100\n","2020-09-27 12:50:07.839120 Epoch: 100, Trainin Loss: 0.15485 Accuracy train: 0.96920 Accuracy val: 0.88700\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GKYQMreth-kn"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'NetWidth_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEw0sSydqvAL"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'NetWidth_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tq-k3-_1q7Jb"},"source":["### BatchNorm Network Model"]},{"cell_type":"code","metadata":{"id":"n-XPtbEBrzxG"},"source":["model = NetBatchNorm()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_adF0b_rrz3P","executionInfo":{"status":"ok","timestamp":1601211009945,"user_tz":-120,"elapsed":266897,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"d90ba950-2458-4b49-cccb-16b19a194290","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NetBatchNorm(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv1_batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2_batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"KVI_V4_xrzpj","executionInfo":{"status":"ok","timestamp":1601211009946,"user_tz":-120,"elapsed":266880,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7168e8a7-3b9f-4862-8744-528d99ff487f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(38482, [864, 32, 32, 32, 4608, 16, 16, 16, 32768, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"TZOfs-uks6Nw","executionInfo":{"status":"ok","timestamp":1601211138504,"user_tz":-120,"elapsed":395421,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"cf8861cd-efa0-4b83-b8c4-a4ddfc3b8ac8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:50:09.191545 Epoch: 1, Trainin Loss: 0.31038 Accuracy train: 0.82830 Accuracy val: 0.83000\n","2020-09-27 12:50:10.476591 Epoch: 2, Trainin Loss: 0.34808 Accuracy train: 0.84130 Accuracy val: 0.84450\n","2020-09-27 12:50:11.756672 Epoch: 3, Trainin Loss: 0.33030 Accuracy train: 0.84660 Accuracy val: 0.83300\n","2020-09-27 12:50:13.044131 Epoch: 4, Trainin Loss: 0.21864 Accuracy train: 0.85660 Accuracy val: 0.85900\n","2020-09-27 12:50:14.336110 Epoch: 5, Trainin Loss: 0.38716 Accuracy train: 0.86700 Accuracy val: 0.85650\n","2020-09-27 12:50:15.628518 Epoch: 6, Trainin Loss: 0.22246 Accuracy train: 0.86610 Accuracy val: 0.86700\n","2020-09-27 12:50:16.906988 Epoch: 7, Trainin Loss: 0.25192 Accuracy train: 0.86390 Accuracy val: 0.85450\n","2020-09-27 12:50:18.199515 Epoch: 8, Trainin Loss: 0.36261 Accuracy train: 0.83610 Accuracy val: 0.81550\n","2020-09-27 12:50:19.483882 Epoch: 9, Trainin Loss: 0.22106 Accuracy train: 0.88600 Accuracy val: 0.86200\n","2020-09-27 12:50:20.766013 Epoch: 10, Trainin Loss: 0.29165 Accuracy train: 0.86290 Accuracy val: 0.84250\n","2020-09-27 12:50:22.043479 Epoch: 11, Trainin Loss: 0.32760 Accuracy train: 0.88720 Accuracy val: 0.86350\n","2020-09-27 12:50:23.324030 Epoch: 12, Trainin Loss: 0.49010 Accuracy train: 0.90400 Accuracy val: 0.87650\n","2020-09-27 12:50:24.611105 Epoch: 13, Trainin Loss: 0.46603 Accuracy train: 0.90150 Accuracy val: 0.88500\n","2020-09-27 12:50:25.891245 Epoch: 14, Trainin Loss: 0.52317 Accuracy train: 0.81150 Accuracy val: 0.78950\n","2020-09-27 12:50:27.177967 Epoch: 15, Trainin Loss: 0.25375 Accuracy train: 0.90050 Accuracy val: 0.87200\n","2020-09-27 12:50:28.456902 Epoch: 16, Trainin Loss: 0.15594 Accuracy train: 0.87430 Accuracy val: 0.86150\n","2020-09-27 12:50:29.754389 Epoch: 17, Trainin Loss: 0.39960 Accuracy train: 0.80200 Accuracy val: 0.77800\n","2020-09-27 12:50:31.032928 Epoch: 18, Trainin Loss: 0.14206 Accuracy train: 0.83910 Accuracy val: 0.81050\n","2020-09-27 12:50:32.328583 Epoch: 19, Trainin Loss: 0.05063 Accuracy train: 0.92040 Accuracy val: 0.88450\n","2020-09-27 12:50:33.619203 Epoch: 20, Trainin Loss: 0.25926 Accuracy train: 0.86400 Accuracy val: 0.84750\n","2020-09-27 12:50:34.916917 Epoch: 21, Trainin Loss: 0.11000 Accuracy train: 0.90360 Accuracy val: 0.87400\n","2020-09-27 12:50:36.210923 Epoch: 22, Trainin Loss: 0.10338 Accuracy train: 0.91350 Accuracy val: 0.88100\n","2020-09-27 12:50:37.497073 Epoch: 23, Trainin Loss: 0.17668 Accuracy train: 0.86710 Accuracy val: 0.83850\n","2020-09-27 12:50:38.786647 Epoch: 24, Trainin Loss: 0.18730 Accuracy train: 0.92190 Accuracy val: 0.87450\n","2020-09-27 12:50:40.081248 Epoch: 25, Trainin Loss: 0.21250 Accuracy train: 0.91220 Accuracy val: 0.87500\n","2020-09-27 12:50:41.363425 Epoch: 26, Trainin Loss: 0.15881 Accuracy train: 0.92570 Accuracy val: 0.88550\n","2020-09-27 12:50:42.652007 Epoch: 27, Trainin Loss: 0.43960 Accuracy train: 0.92120 Accuracy val: 0.87750\n","2020-09-27 12:50:43.931051 Epoch: 28, Trainin Loss: 0.05828 Accuracy train: 0.93790 Accuracy val: 0.87700\n","2020-09-27 12:50:45.225458 Epoch: 29, Trainin Loss: 0.59597 Accuracy train: 0.85840 Accuracy val: 0.82550\n","2020-09-27 12:50:46.516001 Epoch: 30, Trainin Loss: 0.30059 Accuracy train: 0.92470 Accuracy val: 0.88300\n","2020-09-27 12:50:47.795115 Epoch: 31, Trainin Loss: 0.29731 Accuracy train: 0.88060 Accuracy val: 0.83950\n","2020-09-27 12:50:49.087969 Epoch: 32, Trainin Loss: 0.05708 Accuracy train: 0.93230 Accuracy val: 0.88200\n","2020-09-27 12:50:50.376374 Epoch: 33, Trainin Loss: 0.28668 Accuracy train: 0.81190 Accuracy val: 0.77500\n","2020-09-27 12:50:51.645122 Epoch: 34, Trainin Loss: 0.06319 Accuracy train: 0.93360 Accuracy val: 0.87600\n","2020-09-27 12:50:52.929156 Epoch: 35, Trainin Loss: 0.03847 Accuracy train: 0.95130 Accuracy val: 0.89400\n","2020-09-27 12:50:54.215329 Epoch: 36, Trainin Loss: 0.05187 Accuracy train: 0.95530 Accuracy val: 0.89550\n","2020-09-27 12:50:55.500441 Epoch: 37, Trainin Loss: 0.07444 Accuracy train: 0.95280 Accuracy val: 0.88800\n","2020-09-27 12:50:56.765493 Epoch: 38, Trainin Loss: 0.13635 Accuracy train: 0.91690 Accuracy val: 0.86450\n","2020-09-27 12:50:58.044250 Epoch: 39, Trainin Loss: 0.25586 Accuracy train: 0.91770 Accuracy val: 0.86700\n","2020-09-27 12:50:59.332929 Epoch: 40, Trainin Loss: 0.17987 Accuracy train: 0.90650 Accuracy val: 0.87150\n","2020-09-27 12:51:00.622218 Epoch: 41, Trainin Loss: 0.13288 Accuracy train: 0.93850 Accuracy val: 0.87300\n","2020-09-27 12:51:01.909748 Epoch: 42, Trainin Loss: 0.03250 Accuracy train: 0.94640 Accuracy val: 0.87350\n","2020-09-27 12:51:03.196764 Epoch: 43, Trainin Loss: 0.19096 Accuracy train: 0.94010 Accuracy val: 0.88300\n","2020-09-27 12:51:04.475227 Epoch: 44, Trainin Loss: 0.42614 Accuracy train: 0.82110 Accuracy val: 0.77000\n","2020-09-27 12:51:05.775913 Epoch: 45, Trainin Loss: 0.00939 Accuracy train: 0.96780 Accuracy val: 0.89550\n","2020-09-27 12:51:07.057160 Epoch: 46, Trainin Loss: 0.19798 Accuracy train: 0.93460 Accuracy val: 0.88300\n","2020-09-27 12:51:08.335946 Epoch: 47, Trainin Loss: 0.32219 Accuracy train: 0.91300 Accuracy val: 0.83250\n","2020-09-27 12:51:09.619117 Epoch: 48, Trainin Loss: 0.10586 Accuracy train: 0.96060 Accuracy val: 0.89400\n","2020-09-27 12:51:10.897890 Epoch: 49, Trainin Loss: 0.01660 Accuracy train: 0.96710 Accuracy val: 0.88600\n","2020-09-27 12:51:12.181672 Epoch: 50, Trainin Loss: 0.04337 Accuracy train: 0.97070 Accuracy val: 0.89550\n","2020-09-27 12:51:13.457387 Epoch: 51, Trainin Loss: 0.11095 Accuracy train: 0.93840 Accuracy val: 0.87050\n","2020-09-27 12:51:14.749295 Epoch: 52, Trainin Loss: 0.01801 Accuracy train: 0.96420 Accuracy val: 0.88900\n","2020-09-27 12:51:16.045137 Epoch: 53, Trainin Loss: 0.15377 Accuracy train: 0.95790 Accuracy val: 0.87050\n","2020-09-27 12:51:17.318989 Epoch: 54, Trainin Loss: 0.05468 Accuracy train: 0.97760 Accuracy val: 0.89100\n","2020-09-27 12:51:18.611454 Epoch: 55, Trainin Loss: 0.10421 Accuracy train: 0.91010 Accuracy val: 0.84000\n","2020-09-27 12:51:19.901671 Epoch: 56, Trainin Loss: 0.11035 Accuracy train: 0.94520 Accuracy val: 0.86650\n","2020-09-27 12:51:21.184106 Epoch: 57, Trainin Loss: 0.02852 Accuracy train: 0.96920 Accuracy val: 0.88900\n","2020-09-27 12:51:22.461878 Epoch: 58, Trainin Loss: 0.09746 Accuracy train: 0.94310 Accuracy val: 0.87150\n","2020-09-27 12:51:23.735077 Epoch: 59, Trainin Loss: 0.13008 Accuracy train: 0.91510 Accuracy val: 0.85850\n","2020-09-27 12:51:25.018597 Epoch: 60, Trainin Loss: 0.15069 Accuracy train: 0.89850 Accuracy val: 0.83150\n","2020-09-27 12:51:26.300032 Epoch: 61, Trainin Loss: 0.06793 Accuracy train: 0.96720 Accuracy val: 0.88000\n","2020-09-27 12:51:27.582864 Epoch: 62, Trainin Loss: 0.01299 Accuracy train: 0.97160 Accuracy val: 0.87900\n","2020-09-27 12:51:28.878302 Epoch: 63, Trainin Loss: 0.14722 Accuracy train: 0.97040 Accuracy val: 0.87350\n","2020-09-27 12:51:30.166929 Epoch: 64, Trainin Loss: 0.10620 Accuracy train: 0.96820 Accuracy val: 0.86700\n","2020-09-27 12:51:31.450561 Epoch: 65, Trainin Loss: 0.23604 Accuracy train: 0.83310 Accuracy val: 0.76000\n","2020-09-27 12:51:32.733464 Epoch: 66, Trainin Loss: 0.13098 Accuracy train: 0.96360 Accuracy val: 0.86750\n","2020-09-27 12:51:34.021602 Epoch: 67, Trainin Loss: 0.33688 Accuracy train: 0.80920 Accuracy val: 0.73600\n","2020-09-27 12:51:35.308842 Epoch: 68, Trainin Loss: 0.14849 Accuracy train: 0.89550 Accuracy val: 0.80300\n","2020-09-27 12:51:36.593547 Epoch: 69, Trainin Loss: 0.04363 Accuracy train: 0.96930 Accuracy val: 0.86000\n","2020-09-27 12:51:37.876486 Epoch: 70, Trainin Loss: 0.04510 Accuracy train: 0.98550 Accuracy val: 0.88500\n","2020-09-27 12:51:39.163375 Epoch: 71, Trainin Loss: 0.13261 Accuracy train: 0.88380 Accuracy val: 0.83250\n","2020-09-27 12:51:40.449988 Epoch: 72, Trainin Loss: 0.16272 Accuracy train: 0.91620 Accuracy val: 0.85550\n","2020-09-27 12:51:41.742117 Epoch: 73, Trainin Loss: 0.02814 Accuracy train: 0.98970 Accuracy val: 0.88200\n","2020-09-27 12:51:43.023021 Epoch: 74, Trainin Loss: 0.09819 Accuracy train: 0.96300 Accuracy val: 0.85800\n","2020-09-27 12:51:44.305796 Epoch: 75, Trainin Loss: 0.03972 Accuracy train: 0.98230 Accuracy val: 0.86050\n","2020-09-27 12:51:45.597048 Epoch: 76, Trainin Loss: 0.21410 Accuracy train: 0.91110 Accuracy val: 0.84350\n","2020-09-27 12:51:46.894030 Epoch: 77, Trainin Loss: 0.01787 Accuracy train: 0.99420 Accuracy val: 0.88200\n","2020-09-27 12:51:48.173971 Epoch: 78, Trainin Loss: 0.03420 Accuracy train: 0.98560 Accuracy val: 0.88700\n","2020-09-27 12:51:49.444393 Epoch: 79, Trainin Loss: 0.06510 Accuracy train: 0.94130 Accuracy val: 0.86400\n","2020-09-27 12:51:50.729095 Epoch: 80, Trainin Loss: 0.02271 Accuracy train: 0.99280 Accuracy val: 0.87950\n","2020-09-27 12:51:52.015566 Epoch: 81, Trainin Loss: 0.13748 Accuracy train: 0.89580 Accuracy val: 0.84500\n","2020-09-27 12:51:53.293663 Epoch: 82, Trainin Loss: 0.01371 Accuracy train: 0.99090 Accuracy val: 0.87650\n","2020-09-27 12:51:54.569224 Epoch: 83, Trainin Loss: 0.09047 Accuracy train: 0.94090 Accuracy val: 0.87450\n","2020-09-27 12:51:55.860555 Epoch: 84, Trainin Loss: 0.01502 Accuracy train: 0.99230 Accuracy val: 0.89000\n","2020-09-27 12:51:57.139030 Epoch: 85, Trainin Loss: 0.04212 Accuracy train: 0.99060 Accuracy val: 0.88350\n","2020-09-27 12:51:58.418940 Epoch: 86, Trainin Loss: 0.00766 Accuracy train: 0.99500 Accuracy val: 0.88900\n","2020-09-27 12:51:59.705847 Epoch: 87, Trainin Loss: 0.02422 Accuracy train: 0.98860 Accuracy val: 0.87350\n","2020-09-27 12:52:00.999625 Epoch: 88, Trainin Loss: 0.05673 Accuracy train: 0.97020 Accuracy val: 0.87250\n","2020-09-27 12:52:02.293245 Epoch: 89, Trainin Loss: 0.02276 Accuracy train: 0.99270 Accuracy val: 0.87300\n","2020-09-27 12:52:03.582689 Epoch: 90, Trainin Loss: 0.04920 Accuracy train: 0.98480 Accuracy val: 0.87600\n","2020-09-27 12:52:04.860169 Epoch: 91, Trainin Loss: 0.02111 Accuracy train: 0.99700 Accuracy val: 0.87950\n","2020-09-27 12:52:06.146581 Epoch: 92, Trainin Loss: 0.04042 Accuracy train: 0.97880 Accuracy val: 0.88200\n","2020-09-27 12:52:07.424862 Epoch: 93, Trainin Loss: 0.10253 Accuracy train: 0.97030 Accuracy val: 0.87200\n","2020-09-27 12:52:08.705655 Epoch: 94, Trainin Loss: 0.13327 Accuracy train: 0.86210 Accuracy val: 0.80000\n","2020-09-27 12:52:09.991282 Epoch: 95, Trainin Loss: 0.00654 Accuracy train: 0.99770 Accuracy val: 0.87350\n","2020-09-27 12:52:11.266658 Epoch: 96, Trainin Loss: 0.00304 Accuracy train: 0.99420 Accuracy val: 0.86750\n","2020-09-27 12:52:12.542864 Epoch: 97, Trainin Loss: 0.04402 Accuracy train: 0.99160 Accuracy val: 0.87600\n","2020-09-27 12:52:13.820557 Epoch: 98, Trainin Loss: 0.00166 Accuracy train: 0.99670 Accuracy val: 0.88400\n","2020-09-27 12:52:15.107283 Epoch: 99, Trainin Loss: 0.12402 Accuracy train: 0.92660 Accuracy val: 0.82550\n","2020-09-27 12:52:16.374010 Epoch: 100, Trainin Loss: 0.00892 Accuracy train: 0.99580 Accuracy val: 0.87850\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8CYfncar-zh"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'NetBatchNorm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HXhl_q5sCVT"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'NetBatchNorm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMcSUHM3yzCd"},"source":["model = NetDepth()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7g2t6HD9y2uY","executionInfo":{"status":"ok","timestamp":1601211138509,"user_tz":-120,"elapsed":395372,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"b0692d43-87c5-4ac6-c362-7bad3e719569","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NetDepth(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=256, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"CZiJNkJUy2qy","executionInfo":{"status":"ok","timestamp":1601211138510,"user_tz":-120,"elapsed":395354,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"7af68ccd-e242-4a68-84ec-0c4fe995eaf0","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16130, [864, 32, 4608, 16, 2304, 16, 8192, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"6KiA02gxzA7Y","executionInfo":{"status":"ok","timestamp":1601211275538,"user_tz":-120,"elapsed":532366,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"5deef029-fe69-407d-b07b-bcb7d4c7a773","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:52:17.839012 Epoch: 1, Trainin Loss: 0.67686 Accuracy train: 0.65830 Accuracy val: 0.66250\n","2020-09-27 12:52:19.210456 Epoch: 2, Trainin Loss: 0.48574 Accuracy train: 0.74900 Accuracy val: 0.75800\n","2020-09-27 12:52:20.576214 Epoch: 3, Trainin Loss: 0.46508 Accuracy train: 0.76530 Accuracy val: 0.77200\n","2020-09-27 12:52:21.943077 Epoch: 4, Trainin Loss: 0.31254 Accuracy train: 0.81510 Accuracy val: 0.81400\n","2020-09-27 12:52:23.311524 Epoch: 5, Trainin Loss: 0.39935 Accuracy train: 0.78520 Accuracy val: 0.78800\n","2020-09-27 12:52:24.673420 Epoch: 6, Trainin Loss: 0.44025 Accuracy train: 0.72930 Accuracy val: 0.72750\n","2020-09-27 12:52:26.039206 Epoch: 7, Trainin Loss: 0.25971 Accuracy train: 0.81980 Accuracy val: 0.82350\n","2020-09-27 12:52:27.401646 Epoch: 8, Trainin Loss: 0.26750 Accuracy train: 0.84580 Accuracy val: 0.83850\n","2020-09-27 12:52:28.767675 Epoch: 9, Trainin Loss: 0.50860 Accuracy train: 0.79250 Accuracy val: 0.79750\n","2020-09-27 12:52:30.132321 Epoch: 10, Trainin Loss: 0.44877 Accuracy train: 0.80650 Accuracy val: 0.80700\n","2020-09-27 12:52:31.495526 Epoch: 11, Trainin Loss: 0.31291 Accuracy train: 0.86280 Accuracy val: 0.84950\n","2020-09-27 12:52:32.865645 Epoch: 12, Trainin Loss: 0.13828 Accuracy train: 0.86560 Accuracy val: 0.85450\n","2020-09-27 12:52:34.239808 Epoch: 13, Trainin Loss: 0.15152 Accuracy train: 0.84770 Accuracy val: 0.84250\n","2020-09-27 12:52:35.615940 Epoch: 14, Trainin Loss: 0.17111 Accuracy train: 0.86660 Accuracy val: 0.86150\n","2020-09-27 12:52:36.993016 Epoch: 15, Trainin Loss: 0.48967 Accuracy train: 0.86040 Accuracy val: 0.85750\n","2020-09-27 12:52:38.379813 Epoch: 16, Trainin Loss: 0.32113 Accuracy train: 0.85890 Accuracy val: 0.86050\n","2020-09-27 12:52:39.764118 Epoch: 17, Trainin Loss: 0.18602 Accuracy train: 0.87570 Accuracy val: 0.86150\n","2020-09-27 12:52:41.129089 Epoch: 18, Trainin Loss: 0.64724 Accuracy train: 0.87980 Accuracy val: 0.86500\n","2020-09-27 12:52:42.504630 Epoch: 19, Trainin Loss: 0.54867 Accuracy train: 0.86890 Accuracy val: 0.86500\n","2020-09-27 12:52:43.880569 Epoch: 20, Trainin Loss: 0.28420 Accuracy train: 0.88150 Accuracy val: 0.87000\n","2020-09-27 12:52:45.254843 Epoch: 21, Trainin Loss: 0.29474 Accuracy train: 0.74270 Accuracy val: 0.75100\n","2020-09-27 12:52:46.618752 Epoch: 22, Trainin Loss: 0.49347 Accuracy train: 0.85220 Accuracy val: 0.85350\n","2020-09-27 12:52:47.990152 Epoch: 23, Trainin Loss: 0.16354 Accuracy train: 0.89130 Accuracy val: 0.88450\n","2020-09-27 12:52:49.352639 Epoch: 24, Trainin Loss: 0.29542 Accuracy train: 0.88660 Accuracy val: 0.88300\n","2020-09-27 12:52:50.718193 Epoch: 25, Trainin Loss: 0.42853 Accuracy train: 0.86630 Accuracy val: 0.86800\n","2020-09-27 12:52:52.076587 Epoch: 26, Trainin Loss: 0.18565 Accuracy train: 0.88560 Accuracy val: 0.87050\n","2020-09-27 12:52:53.446834 Epoch: 27, Trainin Loss: 0.31580 Accuracy train: 0.89100 Accuracy val: 0.88650\n","2020-09-27 12:52:54.811736 Epoch: 28, Trainin Loss: 0.23321 Accuracy train: 0.88990 Accuracy val: 0.87700\n","2020-09-27 12:52:56.179525 Epoch: 29, Trainin Loss: 0.30969 Accuracy train: 0.90200 Accuracy val: 0.88650\n","2020-09-27 12:52:57.552389 Epoch: 30, Trainin Loss: 0.31270 Accuracy train: 0.90110 Accuracy val: 0.88700\n","2020-09-27 12:52:58.925162 Epoch: 31, Trainin Loss: 0.45512 Accuracy train: 0.90420 Accuracy val: 0.88600\n","2020-09-27 12:53:00.304982 Epoch: 32, Trainin Loss: 0.42544 Accuracy train: 0.90550 Accuracy val: 0.89000\n","2020-09-27 12:53:01.667371 Epoch: 33, Trainin Loss: 0.26184 Accuracy train: 0.89800 Accuracy val: 0.88800\n","2020-09-27 12:53:03.028413 Epoch: 34, Trainin Loss: 0.22242 Accuracy train: 0.90920 Accuracy val: 0.89550\n","2020-09-27 12:53:04.403664 Epoch: 35, Trainin Loss: 0.31718 Accuracy train: 0.86720 Accuracy val: 0.86500\n","2020-09-27 12:53:05.788275 Epoch: 36, Trainin Loss: 0.08439 Accuracy train: 0.89460 Accuracy val: 0.87850\n","2020-09-27 12:53:07.146966 Epoch: 37, Trainin Loss: 0.05998 Accuracy train: 0.91280 Accuracy val: 0.89750\n","2020-09-27 12:53:08.510380 Epoch: 38, Trainin Loss: 0.15156 Accuracy train: 0.91440 Accuracy val: 0.89800\n","2020-09-27 12:53:09.883277 Epoch: 39, Trainin Loss: 0.18926 Accuracy train: 0.91410 Accuracy val: 0.89550\n","2020-09-27 12:53:11.242459 Epoch: 40, Trainin Loss: 0.44963 Accuracy train: 0.80200 Accuracy val: 0.79450\n","2020-09-27 12:53:12.615647 Epoch: 41, Trainin Loss: 0.29023 Accuracy train: 0.90490 Accuracy val: 0.88650\n","2020-09-27 12:53:13.984356 Epoch: 42, Trainin Loss: 0.06059 Accuracy train: 0.91960 Accuracy val: 0.89300\n","2020-09-27 12:53:15.354410 Epoch: 43, Trainin Loss: 0.45358 Accuracy train: 0.89010 Accuracy val: 0.87950\n","2020-09-27 12:53:16.741993 Epoch: 44, Trainin Loss: 0.33393 Accuracy train: 0.89080 Accuracy val: 0.87650\n","2020-09-27 12:53:18.118522 Epoch: 45, Trainin Loss: 0.20595 Accuracy train: 0.92210 Accuracy val: 0.89650\n","2020-09-27 12:53:19.492599 Epoch: 46, Trainin Loss: 0.14217 Accuracy train: 0.92380 Accuracy val: 0.89900\n","2020-09-27 12:53:20.870116 Epoch: 47, Trainin Loss: 0.09575 Accuracy train: 0.92750 Accuracy val: 0.89750\n","2020-09-27 12:53:22.234994 Epoch: 48, Trainin Loss: 0.12475 Accuracy train: 0.88390 Accuracy val: 0.87000\n","2020-09-27 12:53:23.604881 Epoch: 49, Trainin Loss: 0.08575 Accuracy train: 0.90550 Accuracy val: 0.88900\n","2020-09-27 12:53:24.979619 Epoch: 50, Trainin Loss: 0.19155 Accuracy train: 0.88260 Accuracy val: 0.86750\n","2020-09-27 12:53:26.346660 Epoch: 51, Trainin Loss: 0.05936 Accuracy train: 0.92400 Accuracy val: 0.89600\n","2020-09-27 12:53:27.722818 Epoch: 52, Trainin Loss: 0.20202 Accuracy train: 0.92640 Accuracy val: 0.89600\n","2020-09-27 12:53:29.098311 Epoch: 53, Trainin Loss: 0.06226 Accuracy train: 0.92700 Accuracy val: 0.89800\n","2020-09-27 12:53:30.474193 Epoch: 54, Trainin Loss: 0.10476 Accuracy train: 0.92120 Accuracy val: 0.89950\n","2020-09-27 12:53:31.845361 Epoch: 55, Trainin Loss: 0.20646 Accuracy train: 0.92910 Accuracy val: 0.90200\n","2020-09-27 12:53:33.211504 Epoch: 56, Trainin Loss: 0.07428 Accuracy train: 0.93630 Accuracy val: 0.90300\n","2020-09-27 12:53:34.583182 Epoch: 57, Trainin Loss: 0.22917 Accuracy train: 0.92210 Accuracy val: 0.89050\n","2020-09-27 12:53:35.965148 Epoch: 58, Trainin Loss: 0.09464 Accuracy train: 0.93940 Accuracy val: 0.89700\n","2020-09-27 12:53:37.328102 Epoch: 59, Trainin Loss: 0.15123 Accuracy train: 0.93650 Accuracy val: 0.89600\n","2020-09-27 12:53:38.695544 Epoch: 60, Trainin Loss: 0.30289 Accuracy train: 0.93770 Accuracy val: 0.90300\n","2020-09-27 12:53:40.064731 Epoch: 61, Trainin Loss: 0.09111 Accuracy train: 0.93520 Accuracy val: 0.89900\n","2020-09-27 12:53:41.426938 Epoch: 62, Trainin Loss: 0.23657 Accuracy train: 0.92320 Accuracy val: 0.88600\n","2020-09-27 12:53:42.794867 Epoch: 63, Trainin Loss: 0.40413 Accuracy train: 0.90530 Accuracy val: 0.87650\n","2020-09-27 12:53:44.165582 Epoch: 64, Trainin Loss: 0.15157 Accuracy train: 0.90600 Accuracy val: 0.87400\n","2020-09-27 12:53:45.538319 Epoch: 65, Trainin Loss: 0.16735 Accuracy train: 0.94350 Accuracy val: 0.90300\n","2020-09-27 12:53:46.907754 Epoch: 66, Trainin Loss: 0.27787 Accuracy train: 0.93530 Accuracy val: 0.88900\n","2020-09-27 12:53:48.271771 Epoch: 67, Trainin Loss: 0.13358 Accuracy train: 0.93000 Accuracy val: 0.89150\n","2020-09-27 12:53:49.639210 Epoch: 68, Trainin Loss: 0.04229 Accuracy train: 0.95160 Accuracy val: 0.90250\n","2020-09-27 12:53:50.999122 Epoch: 69, Trainin Loss: 0.07059 Accuracy train: 0.91430 Accuracy val: 0.87750\n","2020-09-27 12:53:52.365205 Epoch: 70, Trainin Loss: 0.03603 Accuracy train: 0.95450 Accuracy val: 0.89800\n","2020-09-27 12:53:53.722742 Epoch: 71, Trainin Loss: 0.03718 Accuracy train: 0.95280 Accuracy val: 0.90100\n","2020-09-27 12:53:55.083504 Epoch: 72, Trainin Loss: 0.11760 Accuracy train: 0.95470 Accuracy val: 0.89950\n","2020-09-27 12:53:56.452498 Epoch: 73, Trainin Loss: 0.12297 Accuracy train: 0.95470 Accuracy val: 0.89500\n","2020-09-27 12:53:57.811098 Epoch: 74, Trainin Loss: 0.05540 Accuracy train: 0.94490 Accuracy val: 0.90500\n","2020-09-27 12:53:59.174164 Epoch: 75, Trainin Loss: 0.07011 Accuracy train: 0.95660 Accuracy val: 0.89600\n","2020-09-27 12:54:00.541419 Epoch: 76, Trainin Loss: 0.03164 Accuracy train: 0.93810 Accuracy val: 0.88900\n","2020-09-27 12:54:01.908993 Epoch: 77, Trainin Loss: 0.11965 Accuracy train: 0.94800 Accuracy val: 0.90000\n","2020-09-27 12:54:03.283118 Epoch: 78, Trainin Loss: 0.09886 Accuracy train: 0.90350 Accuracy val: 0.87700\n","2020-09-27 12:54:04.654391 Epoch: 79, Trainin Loss: 0.10502 Accuracy train: 0.91910 Accuracy val: 0.87150\n","2020-09-27 12:54:06.025043 Epoch: 80, Trainin Loss: 0.07045 Accuracy train: 0.95590 Accuracy val: 0.89700\n","2020-09-27 12:54:07.393413 Epoch: 81, Trainin Loss: 0.06163 Accuracy train: 0.94680 Accuracy val: 0.90200\n","2020-09-27 12:54:08.765489 Epoch: 82, Trainin Loss: 0.42690 Accuracy train: 0.77070 Accuracy val: 0.76500\n","2020-09-27 12:54:10.126261 Epoch: 83, Trainin Loss: 0.03063 Accuracy train: 0.95800 Accuracy val: 0.88900\n","2020-09-27 12:54:11.487443 Epoch: 84, Trainin Loss: 0.12103 Accuracy train: 0.94620 Accuracy val: 0.88650\n","2020-09-27 12:54:12.872169 Epoch: 85, Trainin Loss: 0.07248 Accuracy train: 0.96880 Accuracy val: 0.89850\n","2020-09-27 12:54:14.245401 Epoch: 86, Trainin Loss: 0.30999 Accuracy train: 0.86000 Accuracy val: 0.84000\n","2020-09-27 12:54:15.608413 Epoch: 87, Trainin Loss: 0.01129 Accuracy train: 0.95970 Accuracy val: 0.89800\n","2020-09-27 12:54:16.987422 Epoch: 88, Trainin Loss: 0.02666 Accuracy train: 0.96890 Accuracy val: 0.89650\n","2020-09-27 12:54:18.351878 Epoch: 89, Trainin Loss: 0.14549 Accuracy train: 0.84540 Accuracy val: 0.82400\n","2020-09-27 12:54:19.722578 Epoch: 90, Trainin Loss: 0.21311 Accuracy train: 0.97200 Accuracy val: 0.89750\n","2020-09-27 12:54:21.094287 Epoch: 91, Trainin Loss: 0.03792 Accuracy train: 0.97300 Accuracy val: 0.90550\n","2020-09-27 12:54:22.459920 Epoch: 92, Trainin Loss: 0.02138 Accuracy train: 0.97760 Accuracy val: 0.89850\n","2020-09-27 12:54:23.816857 Epoch: 93, Trainin Loss: 0.03139 Accuracy train: 0.96830 Accuracy val: 0.90400\n","2020-09-27 12:54:25.184074 Epoch: 94, Trainin Loss: 0.03490 Accuracy train: 0.97900 Accuracy val: 0.90100\n","2020-09-27 12:54:26.553547 Epoch: 95, Trainin Loss: 0.22432 Accuracy train: 0.96840 Accuracy val: 0.89650\n","2020-09-27 12:54:27.943634 Epoch: 96, Trainin Loss: 0.08061 Accuracy train: 0.97270 Accuracy val: 0.89700\n","2020-09-27 12:54:29.324320 Epoch: 97, Trainin Loss: 0.06171 Accuracy train: 0.97770 Accuracy val: 0.89850\n","2020-09-27 12:54:30.690363 Epoch: 98, Trainin Loss: 0.16796 Accuracy train: 0.87860 Accuracy val: 0.83350\n","2020-09-27 12:54:32.057299 Epoch: 99, Trainin Loss: 0.01973 Accuracy train: 0.97500 Accuracy val: 0.90200\n","2020-09-27 12:54:33.429919 Epoch: 100, Trainin Loss: 0.01486 Accuracy train: 0.97060 Accuracy val: 0.90050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ttvDpFShy4_3"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'NetDepth_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KF-y4iz6y7xN"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'NetDepth_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wncnNifF3mNP"},"source":["## Perform Training Loop w/ subclassing nn.Module + L2 or L1 or Both Regularizations"]},{"cell_type":"code","metadata":{"id":"mfAZBA3f3yRj"},"source":["model = NetBatchNorm()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XvNmvyM39sL","executionInfo":{"status":"ok","timestamp":1601211275542,"user_tz":-120,"elapsed":532323,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"98c67119-c491-4664-9a8e-d40953451bf1","colab":{"base_uri":"https://localhost:8080/"}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NetBatchNorm(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv1_batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2_batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"uFIPEKnY4ALk","executionInfo":{"status":"ok","timestamp":1601211275543,"user_tz":-120,"elapsed":532312,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"d0a873ec-4e8b-4e51-a9fd-19c653c2cff8","colab":{"base_uri":"https://localhost:8080/"}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(38482, [864, 32, 32, 32, 4608, 16, 16, 16, 32768, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"id":"bUNGYFl74IjX","executionInfo":{"status":"ok","timestamp":1601211437768,"user_tz":-120,"elapsed":694526,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"b34d8b67-0414-4911-e3ca-d60a9ba63116","colab":{"base_uri":"https://localhost:8080/"}},"source":["l2_reg_batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:54:35.173028 Epoch: 1, Trainin Loss: 0.46052 Accuracy train: 0.82620 Accuracy val: 0.82050\n","2020-09-27 12:54:36.796161 Epoch: 2, Trainin Loss: 0.25513 Accuracy train: 0.84500 Accuracy val: 0.83200\n","2020-09-27 12:54:38.419471 Epoch: 3, Trainin Loss: 0.18011 Accuracy train: 0.84680 Accuracy val: 0.83050\n","2020-09-27 12:54:40.031936 Epoch: 4, Trainin Loss: 0.33627 Accuracy train: 0.85990 Accuracy val: 0.85200\n","2020-09-27 12:54:41.653520 Epoch: 5, Trainin Loss: 0.40905 Accuracy train: 0.87010 Accuracy val: 0.85350\n","2020-09-27 12:54:43.269698 Epoch: 6, Trainin Loss: 0.36559 Accuracy train: 0.86520 Accuracy val: 0.86550\n","2020-09-27 12:54:44.898102 Epoch: 7, Trainin Loss: 0.41334 Accuracy train: 0.87310 Accuracy val: 0.86400\n","2020-09-27 12:54:46.523676 Epoch: 8, Trainin Loss: 0.33587 Accuracy train: 0.87860 Accuracy val: 0.86150\n","2020-09-27 12:54:48.145014 Epoch: 9, Trainin Loss: 0.10226 Accuracy train: 0.88940 Accuracy val: 0.87250\n","2020-09-27 12:54:49.769606 Epoch: 10, Trainin Loss: 0.41097 Accuracy train: 0.85280 Accuracy val: 0.85300\n","2020-09-27 12:54:51.393879 Epoch: 11, Trainin Loss: 0.15039 Accuracy train: 0.89400 Accuracy val: 0.88100\n","2020-09-27 12:54:53.009007 Epoch: 12, Trainin Loss: 0.41903 Accuracy train: 0.84810 Accuracy val: 0.83100\n","2020-09-27 12:54:54.626420 Epoch: 13, Trainin Loss: 0.31099 Accuracy train: 0.89930 Accuracy val: 0.87750\n","2020-09-27 12:54:56.244998 Epoch: 14, Trainin Loss: 0.56621 Accuracy train: 0.84720 Accuracy val: 0.82750\n","2020-09-27 12:54:57.846248 Epoch: 15, Trainin Loss: 0.31484 Accuracy train: 0.89590 Accuracy val: 0.87650\n","2020-09-27 12:54:59.476359 Epoch: 16, Trainin Loss: 0.37690 Accuracy train: 0.89000 Accuracy val: 0.87300\n","2020-09-27 12:55:01.092537 Epoch: 17, Trainin Loss: 0.37366 Accuracy train: 0.88910 Accuracy val: 0.87050\n","2020-09-27 12:55:02.710164 Epoch: 18, Trainin Loss: 0.30092 Accuracy train: 0.89720 Accuracy val: 0.86850\n","2020-09-27 12:55:04.321175 Epoch: 19, Trainin Loss: 0.16342 Accuracy train: 0.91320 Accuracy val: 0.88400\n","2020-09-27 12:55:05.952641 Epoch: 20, Trainin Loss: 0.43156 Accuracy train: 0.89960 Accuracy val: 0.87350\n","2020-09-27 12:55:07.579128 Epoch: 21, Trainin Loss: 0.46763 Accuracy train: 0.90430 Accuracy val: 0.87550\n","2020-09-27 12:55:09.198096 Epoch: 22, Trainin Loss: 0.26980 Accuracy train: 0.91130 Accuracy val: 0.86800\n","2020-09-27 12:55:10.814321 Epoch: 23, Trainin Loss: 0.13206 Accuracy train: 0.91500 Accuracy val: 0.87500\n","2020-09-27 12:55:12.434502 Epoch: 24, Trainin Loss: 0.13374 Accuracy train: 0.91510 Accuracy val: 0.89150\n","2020-09-27 12:55:14.050400 Epoch: 25, Trainin Loss: 0.28241 Accuracy train: 0.84040 Accuracy val: 0.79000\n","2020-09-27 12:55:15.675599 Epoch: 26, Trainin Loss: 0.51848 Accuracy train: 0.87850 Accuracy val: 0.85600\n","2020-09-27 12:55:17.293768 Epoch: 27, Trainin Loss: 0.14060 Accuracy train: 0.93530 Accuracy val: 0.88600\n","2020-09-27 12:55:18.913159 Epoch: 28, Trainin Loss: 0.25499 Accuracy train: 0.92010 Accuracy val: 0.88900\n","2020-09-27 12:55:20.541566 Epoch: 29, Trainin Loss: 0.20905 Accuracy train: 0.93140 Accuracy val: 0.89400\n","2020-09-27 12:55:22.154094 Epoch: 30, Trainin Loss: 0.25833 Accuracy train: 0.89340 Accuracy val: 0.87050\n","2020-09-27 12:55:23.775143 Epoch: 31, Trainin Loss: 0.26745 Accuracy train: 0.94300 Accuracy val: 0.89300\n","2020-09-27 12:55:25.390218 Epoch: 32, Trainin Loss: 0.17144 Accuracy train: 0.93450 Accuracy val: 0.87250\n","2020-09-27 12:55:27.000492 Epoch: 33, Trainin Loss: 0.17852 Accuracy train: 0.93300 Accuracy val: 0.89100\n","2020-09-27 12:55:28.616085 Epoch: 34, Trainin Loss: 0.21313 Accuracy train: 0.93010 Accuracy val: 0.87900\n","2020-09-27 12:55:30.255888 Epoch: 35, Trainin Loss: 0.12204 Accuracy train: 0.93400 Accuracy val: 0.89800\n","2020-09-27 12:55:31.872975 Epoch: 36, Trainin Loss: 0.30853 Accuracy train: 0.92830 Accuracy val: 0.86300\n","2020-09-27 12:55:33.499183 Epoch: 37, Trainin Loss: 0.24878 Accuracy train: 0.90750 Accuracy val: 0.85200\n","2020-09-27 12:55:35.118832 Epoch: 38, Trainin Loss: 0.28493 Accuracy train: 0.93660 Accuracy val: 0.87600\n","2020-09-27 12:55:36.732008 Epoch: 39, Trainin Loss: 0.18494 Accuracy train: 0.93970 Accuracy val: 0.87600\n","2020-09-27 12:55:38.358568 Epoch: 40, Trainin Loss: 0.23060 Accuracy train: 0.93970 Accuracy val: 0.88350\n","2020-09-27 12:55:39.979528 Epoch: 41, Trainin Loss: 0.30685 Accuracy train: 0.92730 Accuracy val: 0.88400\n","2020-09-27 12:55:41.642820 Epoch: 42, Trainin Loss: 0.16330 Accuracy train: 0.89120 Accuracy val: 0.84650\n","2020-09-27 12:55:43.263976 Epoch: 43, Trainin Loss: 0.23878 Accuracy train: 0.93900 Accuracy val: 0.87000\n","2020-09-27 12:55:44.886931 Epoch: 44, Trainin Loss: 0.43817 Accuracy train: 0.85630 Accuracy val: 0.81000\n","2020-09-27 12:55:46.510780 Epoch: 45, Trainin Loss: 0.23219 Accuracy train: 0.94320 Accuracy val: 0.87800\n","2020-09-27 12:55:48.177176 Epoch: 46, Trainin Loss: 0.24739 Accuracy train: 0.91740 Accuracy val: 0.84600\n","2020-09-27 12:55:49.788972 Epoch: 47, Trainin Loss: 0.26523 Accuracy train: 0.92250 Accuracy val: 0.86350\n","2020-09-27 12:55:51.415127 Epoch: 48, Trainin Loss: 0.24443 Accuracy train: 0.90340 Accuracy val: 0.86350\n","2020-09-27 12:55:53.049930 Epoch: 49, Trainin Loss: 0.08701 Accuracy train: 0.96190 Accuracy val: 0.88600\n","2020-09-27 12:55:54.671964 Epoch: 50, Trainin Loss: 0.21362 Accuracy train: 0.91110 Accuracy val: 0.85200\n","2020-09-27 12:55:56.279481 Epoch: 51, Trainin Loss: 0.11941 Accuracy train: 0.95580 Accuracy val: 0.89350\n","2020-09-27 12:55:57.895608 Epoch: 52, Trainin Loss: 0.19636 Accuracy train: 0.94050 Accuracy val: 0.88800\n","2020-09-27 12:55:59.511080 Epoch: 53, Trainin Loss: 0.29218 Accuracy train: 0.94290 Accuracy val: 0.86950\n","2020-09-27 12:56:01.132854 Epoch: 54, Trainin Loss: 0.13793 Accuracy train: 0.96970 Accuracy val: 0.87950\n","2020-09-27 12:56:02.783025 Epoch: 55, Trainin Loss: 0.15072 Accuracy train: 0.96180 Accuracy val: 0.89650\n","2020-09-27 12:56:04.393455 Epoch: 56, Trainin Loss: 0.11771 Accuracy train: 0.96440 Accuracy val: 0.89600\n","2020-09-27 12:56:06.014953 Epoch: 57, Trainin Loss: 0.15740 Accuracy train: 0.90600 Accuracy val: 0.83300\n","2020-09-27 12:56:07.630095 Epoch: 58, Trainin Loss: 0.32504 Accuracy train: 0.92130 Accuracy val: 0.84350\n","2020-09-27 12:56:09.270448 Epoch: 59, Trainin Loss: 0.12092 Accuracy train: 0.95930 Accuracy val: 0.88900\n","2020-09-27 12:56:10.898156 Epoch: 60, Trainin Loss: 0.17882 Accuracy train: 0.96390 Accuracy val: 0.88300\n","2020-09-27 12:56:12.505425 Epoch: 61, Trainin Loss: 0.08143 Accuracy train: 0.97120 Accuracy val: 0.89600\n","2020-09-27 12:56:14.134981 Epoch: 62, Trainin Loss: 0.08442 Accuracy train: 0.97870 Accuracy val: 0.88900\n","2020-09-27 12:56:15.745850 Epoch: 63, Trainin Loss: 0.21127 Accuracy train: 0.94650 Accuracy val: 0.86900\n","2020-09-27 12:56:17.374931 Epoch: 64, Trainin Loss: 0.10430 Accuracy train: 0.98040 Accuracy val: 0.88250\n","2020-09-27 12:56:19.011413 Epoch: 65, Trainin Loss: 0.11921 Accuracy train: 0.96260 Accuracy val: 0.87850\n","2020-09-27 12:56:20.622429 Epoch: 66, Trainin Loss: 0.14938 Accuracy train: 0.96560 Accuracy val: 0.88200\n","2020-09-27 12:56:22.236153 Epoch: 67, Trainin Loss: 0.09439 Accuracy train: 0.95940 Accuracy val: 0.86150\n","2020-09-27 12:56:23.836946 Epoch: 68, Trainin Loss: 0.12157 Accuracy train: 0.97030 Accuracy val: 0.88450\n","2020-09-27 12:56:25.430070 Epoch: 69, Trainin Loss: 0.27491 Accuracy train: 0.97710 Accuracy val: 0.88100\n","2020-09-27 12:56:27.044976 Epoch: 70, Trainin Loss: 0.23836 Accuracy train: 0.91870 Accuracy val: 0.84400\n","2020-09-27 12:56:28.659090 Epoch: 71, Trainin Loss: 0.11012 Accuracy train: 0.96460 Accuracy val: 0.88650\n","2020-09-27 12:56:30.274087 Epoch: 72, Trainin Loss: 0.10419 Accuracy train: 0.97950 Accuracy val: 0.88800\n","2020-09-27 12:56:31.917851 Epoch: 73, Trainin Loss: 0.12446 Accuracy train: 0.98030 Accuracy val: 0.88600\n","2020-09-27 12:56:33.534955 Epoch: 74, Trainin Loss: 0.11117 Accuracy train: 0.97540 Accuracy val: 0.88250\n","2020-09-27 12:56:35.155815 Epoch: 75, Trainin Loss: 0.15751 Accuracy train: 0.86710 Accuracy val: 0.79300\n","2020-09-27 12:56:36.766986 Epoch: 76, Trainin Loss: 0.13734 Accuracy train: 0.97790 Accuracy val: 0.88150\n","2020-09-27 12:56:38.399106 Epoch: 77, Trainin Loss: 0.11895 Accuracy train: 0.97390 Accuracy val: 0.87700\n","2020-09-27 12:56:40.004960 Epoch: 78, Trainin Loss: 0.15372 Accuracy train: 0.97100 Accuracy val: 0.86900\n","2020-09-27 12:56:41.609953 Epoch: 79, Trainin Loss: 0.09519 Accuracy train: 0.97700 Accuracy val: 0.87700\n","2020-09-27 12:56:43.215495 Epoch: 80, Trainin Loss: 0.09740 Accuracy train: 0.98270 Accuracy val: 0.87750\n","2020-09-27 12:56:44.853959 Epoch: 81, Trainin Loss: 0.12949 Accuracy train: 0.94360 Accuracy val: 0.87550\n","2020-09-27 12:56:46.471973 Epoch: 82, Trainin Loss: 0.10096 Accuracy train: 0.97950 Accuracy val: 0.88350\n","2020-09-27 12:56:48.090576 Epoch: 83, Trainin Loss: 0.10890 Accuracy train: 0.97430 Accuracy val: 0.88050\n","2020-09-27 12:56:49.722965 Epoch: 84, Trainin Loss: 0.10716 Accuracy train: 0.98310 Accuracy val: 0.88600\n","2020-09-27 12:56:51.340348 Epoch: 85, Trainin Loss: 0.11782 Accuracy train: 0.96390 Accuracy val: 0.85900\n","2020-09-27 12:56:52.961175 Epoch: 86, Trainin Loss: 0.09473 Accuracy train: 0.98430 Accuracy val: 0.88500\n","2020-09-27 12:56:54.603965 Epoch: 87, Trainin Loss: 0.15048 Accuracy train: 0.91180 Accuracy val: 0.83000\n","2020-09-27 12:56:56.227598 Epoch: 88, Trainin Loss: 0.13243 Accuracy train: 0.98220 Accuracy val: 0.87900\n","2020-09-27 12:56:57.847854 Epoch: 89, Trainin Loss: 0.17220 Accuracy train: 0.96010 Accuracy val: 0.86400\n","2020-09-27 12:56:59.468043 Epoch: 90, Trainin Loss: 0.12280 Accuracy train: 0.97440 Accuracy val: 0.88300\n","2020-09-27 12:57:01.076337 Epoch: 91, Trainin Loss: 0.08981 Accuracy train: 0.99160 Accuracy val: 0.89650\n","2020-09-27 12:57:02.689113 Epoch: 92, Trainin Loss: 0.11905 Accuracy train: 0.98660 Accuracy val: 0.87350\n","2020-09-27 12:57:04.293967 Epoch: 93, Trainin Loss: 0.11027 Accuracy train: 0.98980 Accuracy val: 0.88100\n","2020-09-27 12:57:05.911151 Epoch: 94, Trainin Loss: 0.14928 Accuracy train: 0.95890 Accuracy val: 0.87200\n","2020-09-27 12:57:07.556344 Epoch: 95, Trainin Loss: 0.13077 Accuracy train: 0.98960 Accuracy val: 0.89250\n","2020-09-27 12:57:09.176018 Epoch: 96, Trainin Loss: 0.13337 Accuracy train: 0.97380 Accuracy val: 0.87600\n","2020-09-27 12:57:10.779905 Epoch: 97, Trainin Loss: 0.16105 Accuracy train: 0.93360 Accuracy val: 0.86300\n","2020-09-27 12:57:12.390273 Epoch: 98, Trainin Loss: 0.12336 Accuracy train: 0.98380 Accuracy val: 0.88100\n","2020-09-27 12:57:14.014175 Epoch: 99, Trainin Loss: 0.09091 Accuracy train: 0.99360 Accuracy val: 0.88200\n","2020-09-27 12:57:15.651953 Epoch: 100, Trainin Loss: 0.09163 Accuracy train: 0.99630 Accuracy val: 0.88900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KC9fRgxM4An8"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'NetBatchNorm_l2_norm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fujmirkt4Fpx"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'NetBatchNorm_l2_norm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiWgMr7b5FII"},"source":["model = NetBatchNorm()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-io7aq05Htq","executionInfo":{"status":"ok","timestamp":1601211590361,"user_tz":-120,"elapsed":847073,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"e39bf224-e959-4a02-848b-2929bf82f947","colab":{"base_uri":"https://localhost:8080/"}},"source":["l1_reg_batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:57:17.244141 Epoch: 1, Trainin Loss: 1.12505 Accuracy train: 0.82200 Accuracy val: 0.82650\n","2020-09-27 12:57:18.767728 Epoch: 2, Trainin Loss: 1.14112 Accuracy train: 0.83610 Accuracy val: 0.83500\n","2020-09-27 12:57:20.298483 Epoch: 3, Trainin Loss: 1.03120 Accuracy train: 0.83890 Accuracy val: 0.83500\n","2020-09-27 12:57:21.818882 Epoch: 4, Trainin Loss: 0.86870 Accuracy train: 0.86360 Accuracy val: 0.85300\n","2020-09-27 12:57:23.347770 Epoch: 5, Trainin Loss: 0.96213 Accuracy train: 0.85830 Accuracy val: 0.85650\n","2020-09-27 12:57:24.876524 Epoch: 6, Trainin Loss: 0.92415 Accuracy train: 0.86610 Accuracy val: 0.84100\n","2020-09-27 12:57:26.400898 Epoch: 7, Trainin Loss: 1.03559 Accuracy train: 0.86490 Accuracy val: 0.86600\n","2020-09-27 12:57:27.925949 Epoch: 8, Trainin Loss: 0.84257 Accuracy train: 0.85520 Accuracy val: 0.85050\n","2020-09-27 12:57:29.462961 Epoch: 9, Trainin Loss: 0.68387 Accuracy train: 0.87700 Accuracy val: 0.87450\n","2020-09-27 12:57:30.982781 Epoch: 10, Trainin Loss: 0.64384 Accuracy train: 0.88260 Accuracy val: 0.86800\n","2020-09-27 12:57:32.507943 Epoch: 11, Trainin Loss: 0.58884 Accuracy train: 0.85110 Accuracy val: 0.83500\n","2020-09-27 12:57:34.051002 Epoch: 12, Trainin Loss: 0.57597 Accuracy train: 0.87480 Accuracy val: 0.85200\n","2020-09-27 12:57:35.577639 Epoch: 13, Trainin Loss: 0.49125 Accuracy train: 0.88820 Accuracy val: 0.87550\n","2020-09-27 12:57:37.106002 Epoch: 14, Trainin Loss: 0.50974 Accuracy train: 0.88450 Accuracy val: 0.87900\n","2020-09-27 12:57:38.629976 Epoch: 15, Trainin Loss: 0.53238 Accuracy train: 0.87350 Accuracy val: 0.85850\n","2020-09-27 12:57:40.145787 Epoch: 16, Trainin Loss: 0.44603 Accuracy train: 0.88240 Accuracy val: 0.86250\n","2020-09-27 12:57:41.672272 Epoch: 17, Trainin Loss: 0.51282 Accuracy train: 0.88460 Accuracy val: 0.86950\n","2020-09-27 12:57:43.206314 Epoch: 18, Trainin Loss: 0.56036 Accuracy train: 0.85400 Accuracy val: 0.85750\n","2020-09-27 12:57:44.741099 Epoch: 19, Trainin Loss: 0.58097 Accuracy train: 0.82650 Accuracy val: 0.82550\n","2020-09-27 12:57:46.265767 Epoch: 20, Trainin Loss: 0.44809 Accuracy train: 0.89120 Accuracy val: 0.88850\n","2020-09-27 12:57:47.810263 Epoch: 21, Trainin Loss: 0.37264 Accuracy train: 0.87080 Accuracy val: 0.85400\n","2020-09-27 12:57:49.342891 Epoch: 22, Trainin Loss: 0.58680 Accuracy train: 0.70320 Accuracy val: 0.69050\n","2020-09-27 12:57:50.879977 Epoch: 23, Trainin Loss: 0.48756 Accuracy train: 0.89810 Accuracy val: 0.87750\n","2020-09-27 12:57:52.406970 Epoch: 24, Trainin Loss: 0.35279 Accuracy train: 0.89270 Accuracy val: 0.87800\n","2020-09-27 12:57:53.933728 Epoch: 25, Trainin Loss: 0.47877 Accuracy train: 0.83970 Accuracy val: 0.83600\n","2020-09-27 12:57:55.463544 Epoch: 26, Trainin Loss: 0.38325 Accuracy train: 0.86440 Accuracy val: 0.86200\n","2020-09-27 12:57:56.980959 Epoch: 27, Trainin Loss: 0.43692 Accuracy train: 0.88110 Accuracy val: 0.86400\n","2020-09-27 12:57:58.503509 Epoch: 28, Trainin Loss: 0.40462 Accuracy train: 0.87070 Accuracy val: 0.84450\n","2020-09-27 12:58:00.048060 Epoch: 29, Trainin Loss: 0.31991 Accuracy train: 0.88390 Accuracy val: 0.85750\n","2020-09-27 12:58:01.575089 Epoch: 30, Trainin Loss: 0.48137 Accuracy train: 0.88230 Accuracy val: 0.87250\n","2020-09-27 12:58:03.105051 Epoch: 31, Trainin Loss: 0.51042 Accuracy train: 0.88850 Accuracy val: 0.87300\n","2020-09-27 12:58:04.619038 Epoch: 32, Trainin Loss: 0.33194 Accuracy train: 0.88800 Accuracy val: 0.87250\n","2020-09-27 12:58:06.154931 Epoch: 33, Trainin Loss: 0.47972 Accuracy train: 0.83610 Accuracy val: 0.80750\n","2020-09-27 12:58:07.668695 Epoch: 34, Trainin Loss: 0.37552 Accuracy train: 0.89020 Accuracy val: 0.88150\n","2020-09-27 12:58:09.214190 Epoch: 35, Trainin Loss: 0.34306 Accuracy train: 0.82680 Accuracy val: 0.80200\n","2020-09-27 12:58:10.737003 Epoch: 36, Trainin Loss: 0.50446 Accuracy train: 0.85890 Accuracy val: 0.84800\n","2020-09-27 12:58:12.262379 Epoch: 37, Trainin Loss: 0.33255 Accuracy train: 0.87860 Accuracy val: 0.85700\n","2020-09-27 12:58:13.773905 Epoch: 38, Trainin Loss: 0.31437 Accuracy train: 0.90730 Accuracy val: 0.87900\n","2020-09-27 12:58:15.295182 Epoch: 39, Trainin Loss: 0.31361 Accuracy train: 0.90380 Accuracy val: 0.87750\n","2020-09-27 12:58:16.832398 Epoch: 40, Trainin Loss: 0.47070 Accuracy train: 0.90070 Accuracy val: 0.87550\n","2020-09-27 12:58:18.359353 Epoch: 41, Trainin Loss: 0.33828 Accuracy train: 0.89670 Accuracy val: 0.88150\n","2020-09-27 12:58:19.882269 Epoch: 42, Trainin Loss: 0.50344 Accuracy train: 0.86590 Accuracy val: 0.84000\n","2020-09-27 12:58:21.411349 Epoch: 43, Trainin Loss: 0.33508 Accuracy train: 0.87570 Accuracy val: 0.86000\n","2020-09-27 12:58:22.930948 Epoch: 44, Trainin Loss: 0.38538 Accuracy train: 0.86310 Accuracy val: 0.85000\n","2020-09-27 12:58:24.466906 Epoch: 45, Trainin Loss: 0.56245 Accuracy train: 0.86390 Accuracy val: 0.82900\n","2020-09-27 12:58:26.007758 Epoch: 46, Trainin Loss: 0.28059 Accuracy train: 0.88790 Accuracy val: 0.86950\n","2020-09-27 12:58:27.530231 Epoch: 47, Trainin Loss: 0.33965 Accuracy train: 0.90630 Accuracy val: 0.88350\n","2020-09-27 12:58:29.061058 Epoch: 48, Trainin Loss: 0.40402 Accuracy train: 0.75190 Accuracy val: 0.72850\n","2020-09-27 12:58:30.588085 Epoch: 49, Trainin Loss: 0.38786 Accuracy train: 0.89590 Accuracy val: 0.87500\n","2020-09-27 12:58:32.102759 Epoch: 50, Trainin Loss: 0.53726 Accuracy train: 0.81490 Accuracy val: 0.79000\n","2020-09-27 12:58:33.632258 Epoch: 51, Trainin Loss: 0.53999 Accuracy train: 0.85370 Accuracy val: 0.85100\n","2020-09-27 12:58:35.168282 Epoch: 52, Trainin Loss: 0.48093 Accuracy train: 0.81990 Accuracy val: 0.78700\n","2020-09-27 12:58:36.697845 Epoch: 53, Trainin Loss: 0.20983 Accuracy train: 0.92900 Accuracy val: 0.88950\n","2020-09-27 12:58:38.217970 Epoch: 54, Trainin Loss: 0.48518 Accuracy train: 0.84690 Accuracy val: 0.83300\n","2020-09-27 12:58:39.761188 Epoch: 55, Trainin Loss: 0.35570 Accuracy train: 0.87100 Accuracy val: 0.85650\n","2020-09-27 12:58:41.294954 Epoch: 56, Trainin Loss: 0.29963 Accuracy train: 0.89680 Accuracy val: 0.86650\n","2020-09-27 12:58:42.839907 Epoch: 57, Trainin Loss: 0.25706 Accuracy train: 0.92120 Accuracy val: 0.88600\n","2020-09-27 12:58:44.361930 Epoch: 58, Trainin Loss: 0.65460 Accuracy train: 0.87240 Accuracy val: 0.83950\n","2020-09-27 12:58:45.883422 Epoch: 59, Trainin Loss: 0.33362 Accuracy train: 0.87730 Accuracy val: 0.85300\n","2020-09-27 12:58:47.407077 Epoch: 60, Trainin Loss: 0.28377 Accuracy train: 0.91490 Accuracy val: 0.87850\n","2020-09-27 12:58:48.936344 Epoch: 61, Trainin Loss: 0.32616 Accuracy train: 0.90750 Accuracy val: 0.85650\n","2020-09-27 12:58:50.446136 Epoch: 62, Trainin Loss: 0.37218 Accuracy train: 0.91260 Accuracy val: 0.88250\n","2020-09-27 12:58:51.954066 Epoch: 63, Trainin Loss: 0.48441 Accuracy train: 0.85750 Accuracy val: 0.83000\n","2020-09-27 12:58:53.466060 Epoch: 64, Trainin Loss: 0.33552 Accuracy train: 0.89650 Accuracy val: 0.86050\n","2020-09-27 12:58:54.996928 Epoch: 65, Trainin Loss: 0.29465 Accuracy train: 0.90620 Accuracy val: 0.86850\n","2020-09-27 12:58:56.514890 Epoch: 66, Trainin Loss: 0.28912 Accuracy train: 0.91800 Accuracy val: 0.86600\n","2020-09-27 12:58:58.006689 Epoch: 67, Trainin Loss: 0.35282 Accuracy train: 0.90690 Accuracy val: 0.87350\n","2020-09-27 12:58:59.520984 Epoch: 68, Trainin Loss: 0.41566 Accuracy train: 0.85410 Accuracy val: 0.80650\n","2020-09-27 12:59:01.036421 Epoch: 69, Trainin Loss: 0.42681 Accuracy train: 0.89610 Accuracy val: 0.86150\n","2020-09-27 12:59:02.560848 Epoch: 70, Trainin Loss: 0.48009 Accuracy train: 0.87650 Accuracy val: 0.85300\n","2020-09-27 12:59:04.077093 Epoch: 71, Trainin Loss: 0.46767 Accuracy train: 0.84890 Accuracy val: 0.82050\n","2020-09-27 12:59:05.611153 Epoch: 72, Trainin Loss: 0.33599 Accuracy train: 0.92100 Accuracy val: 0.88550\n","2020-09-27 12:59:07.132562 Epoch: 73, Trainin Loss: 0.46069 Accuracy train: 0.83190 Accuracy val: 0.80800\n","2020-09-27 12:59:08.661492 Epoch: 74, Trainin Loss: 0.25562 Accuracy train: 0.91730 Accuracy val: 0.87600\n","2020-09-27 12:59:10.190696 Epoch: 75, Trainin Loss: 0.27116 Accuracy train: 0.90230 Accuracy val: 0.87450\n","2020-09-27 12:59:11.696099 Epoch: 76, Trainin Loss: 0.34274 Accuracy train: 0.91430 Accuracy val: 0.87600\n","2020-09-27 12:59:13.216890 Epoch: 77, Trainin Loss: 0.25811 Accuracy train: 0.92380 Accuracy val: 0.88800\n","2020-09-27 12:59:14.734758 Epoch: 78, Trainin Loss: 0.32422 Accuracy train: 0.89870 Accuracy val: 0.86850\n","2020-09-27 12:59:16.252739 Epoch: 79, Trainin Loss: 0.27918 Accuracy train: 0.93100 Accuracy val: 0.88750\n","2020-09-27 12:59:17.781773 Epoch: 80, Trainin Loss: 0.27303 Accuracy train: 0.91830 Accuracy val: 0.88450\n","2020-09-27 12:59:19.326884 Epoch: 81, Trainin Loss: 0.50565 Accuracy train: 0.85540 Accuracy val: 0.81500\n","2020-09-27 12:59:20.855544 Epoch: 82, Trainin Loss: 0.43731 Accuracy train: 0.92410 Accuracy val: 0.87300\n","2020-09-27 12:59:22.388896 Epoch: 83, Trainin Loss: 0.38687 Accuracy train: 0.91530 Accuracy val: 0.88250\n","2020-09-27 12:59:23.913098 Epoch: 84, Trainin Loss: 0.29995 Accuracy train: 0.92780 Accuracy val: 0.87900\n","2020-09-27 12:59:25.436167 Epoch: 85, Trainin Loss: 0.24182 Accuracy train: 0.93950 Accuracy val: 0.88550\n","2020-09-27 12:59:26.965431 Epoch: 86, Trainin Loss: 0.18865 Accuracy train: 0.90370 Accuracy val: 0.87000\n","2020-09-27 12:59:28.484930 Epoch: 87, Trainin Loss: 0.30662 Accuracy train: 0.92000 Accuracy val: 0.88550\n","2020-09-27 12:59:29.997458 Epoch: 88, Trainin Loss: 0.46529 Accuracy train: 0.74210 Accuracy val: 0.72600\n","2020-09-27 12:59:31.509057 Epoch: 89, Trainin Loss: 0.25574 Accuracy train: 0.86590 Accuracy val: 0.80450\n","2020-09-27 12:59:33.026185 Epoch: 90, Trainin Loss: 0.32191 Accuracy train: 0.84480 Accuracy val: 0.80850\n","2020-09-27 12:59:34.571293 Epoch: 91, Trainin Loss: 0.26480 Accuracy train: 0.90340 Accuracy val: 0.87250\n","2020-09-27 12:59:36.089978 Epoch: 92, Trainin Loss: 0.49429 Accuracy train: 0.82200 Accuracy val: 0.76950\n","2020-09-27 12:59:37.603050 Epoch: 93, Trainin Loss: 0.28268 Accuracy train: 0.93400 Accuracy val: 0.87950\n","2020-09-27 12:59:39.130996 Epoch: 94, Trainin Loss: 0.31549 Accuracy train: 0.89810 Accuracy val: 0.85950\n","2020-09-27 12:59:40.665434 Epoch: 95, Trainin Loss: 0.38015 Accuracy train: 0.91790 Accuracy val: 0.87900\n","2020-09-27 12:59:42.171327 Epoch: 96, Trainin Loss: 0.41601 Accuracy train: 0.89600 Accuracy val: 0.84750\n","2020-09-27 12:59:43.683904 Epoch: 97, Trainin Loss: 0.32863 Accuracy train: 0.88580 Accuracy val: 0.84500\n","2020-09-27 12:59:45.198810 Epoch: 98, Trainin Loss: 0.29261 Accuracy train: 0.90800 Accuracy val: 0.86250\n","2020-09-27 12:59:46.720335 Epoch: 99, Trainin Loss: 0.41976 Accuracy train: 0.80010 Accuracy val: 0.78600\n","2020-09-27 12:59:48.232098 Epoch: 100, Trainin Loss: 0.46153 Accuracy train: 0.79900 Accuracy val: 0.74250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iwrRM1b25J_q"},"source":["model = NetBatchNorm()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AL0xn8V5K6s","executionInfo":{"status":"ok","timestamp":1601211775828,"user_tz":-120,"elapsed":1032518,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"66db5242-f5b6-4a83-8a9f-1cc0492e70e0","colab":{"base_uri":"https://localhost:8080/"}},"source":["l1l2_reg_batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 12:59:50.134550 Epoch: 1, Trainin Loss: 1.15520 Accuracy train: 0.83380 Accuracy val: 0.83400\n","2020-09-27 12:59:52.005043 Epoch: 2, Trainin Loss: 0.96265 Accuracy train: 0.84990 Accuracy val: 0.84500\n","2020-09-27 12:59:53.856942 Epoch: 3, Trainin Loss: 1.02143 Accuracy train: 0.84750 Accuracy val: 0.83600\n","2020-09-27 12:59:55.715170 Epoch: 4, Trainin Loss: 1.22355 Accuracy train: 0.84160 Accuracy val: 0.83550\n","2020-09-27 12:59:57.557948 Epoch: 5, Trainin Loss: 0.94101 Accuracy train: 0.84640 Accuracy val: 0.85500\n","2020-09-27 12:59:59.415697 Epoch: 6, Trainin Loss: 0.82718 Accuracy train: 0.84610 Accuracy val: 0.85100\n","2020-09-27 13:00:01.285933 Epoch: 7, Trainin Loss: 0.97372 Accuracy train: 0.82850 Accuracy val: 0.81450\n","2020-09-27 13:00:03.119094 Epoch: 8, Trainin Loss: 1.07134 Accuracy train: 0.84500 Accuracy val: 0.83200\n","2020-09-27 13:00:04.974150 Epoch: 9, Trainin Loss: 0.68900 Accuracy train: 0.86640 Accuracy val: 0.85800\n","2020-09-27 13:00:06.824434 Epoch: 10, Trainin Loss: 0.69634 Accuracy train: 0.87210 Accuracy val: 0.85200\n","2020-09-27 13:00:08.674108 Epoch: 11, Trainin Loss: 0.72990 Accuracy train: 0.85290 Accuracy val: 0.85300\n","2020-09-27 13:00:10.524543 Epoch: 12, Trainin Loss: 0.89706 Accuracy train: 0.82010 Accuracy val: 0.81250\n","2020-09-27 13:00:12.368103 Epoch: 13, Trainin Loss: 0.63662 Accuracy train: 0.87920 Accuracy val: 0.87000\n","2020-09-27 13:00:14.228190 Epoch: 14, Trainin Loss: 0.58761 Accuracy train: 0.86720 Accuracy val: 0.85800\n","2020-09-27 13:00:16.090115 Epoch: 15, Trainin Loss: 0.72869 Accuracy train: 0.80880 Accuracy val: 0.78650\n","2020-09-27 13:00:17.939435 Epoch: 16, Trainin Loss: 0.66304 Accuracy train: 0.87770 Accuracy val: 0.87000\n","2020-09-27 13:00:19.807009 Epoch: 17, Trainin Loss: 0.47971 Accuracy train: 0.85960 Accuracy val: 0.86100\n","2020-09-27 13:00:21.660145 Epoch: 18, Trainin Loss: 0.59910 Accuracy train: 0.84290 Accuracy val: 0.83100\n","2020-09-27 13:00:23.508194 Epoch: 19, Trainin Loss: 0.61358 Accuracy train: 0.89420 Accuracy val: 0.88300\n","2020-09-27 13:00:25.354851 Epoch: 20, Trainin Loss: 0.52744 Accuracy train: 0.87250 Accuracy val: 0.86600\n","2020-09-27 13:00:27.226101 Epoch: 21, Trainin Loss: 0.66004 Accuracy train: 0.85140 Accuracy val: 0.85700\n","2020-09-27 13:00:29.090024 Epoch: 22, Trainin Loss: 0.35377 Accuracy train: 0.88790 Accuracy val: 0.86650\n","2020-09-27 13:00:30.944145 Epoch: 23, Trainin Loss: 0.56441 Accuracy train: 0.87560 Accuracy val: 0.86600\n","2020-09-27 13:00:32.781221 Epoch: 24, Trainin Loss: 0.57509 Accuracy train: 0.88300 Accuracy val: 0.86900\n","2020-09-27 13:00:34.625967 Epoch: 25, Trainin Loss: 0.56609 Accuracy train: 0.84040 Accuracy val: 0.83750\n","2020-09-27 13:00:36.479354 Epoch: 26, Trainin Loss: 0.36301 Accuracy train: 0.87440 Accuracy val: 0.86950\n","2020-09-27 13:00:38.329674 Epoch: 27, Trainin Loss: 0.48178 Accuracy train: 0.90350 Accuracy val: 0.88250\n","2020-09-27 13:00:40.181515 Epoch: 28, Trainin Loss: 0.47672 Accuracy train: 0.85220 Accuracy val: 0.83600\n","2020-09-27 13:00:42.037092 Epoch: 29, Trainin Loss: 0.43130 Accuracy train: 0.89420 Accuracy val: 0.86550\n","2020-09-27 13:00:43.916860 Epoch: 30, Trainin Loss: 0.43498 Accuracy train: 0.89670 Accuracy val: 0.86650\n","2020-09-27 13:00:45.782151 Epoch: 31, Trainin Loss: 0.71844 Accuracy train: 0.85230 Accuracy val: 0.82050\n","2020-09-27 13:00:47.637348 Epoch: 32, Trainin Loss: 0.63272 Accuracy train: 0.83950 Accuracy val: 0.82200\n","2020-09-27 13:00:49.495133 Epoch: 33, Trainin Loss: 0.93492 Accuracy train: 0.74080 Accuracy val: 0.71300\n","2020-09-27 13:00:51.343286 Epoch: 34, Trainin Loss: 0.57473 Accuracy train: 0.84620 Accuracy val: 0.84550\n","2020-09-27 13:00:53.199895 Epoch: 35, Trainin Loss: 0.35008 Accuracy train: 0.88170 Accuracy val: 0.87300\n","2020-09-27 13:00:55.037612 Epoch: 36, Trainin Loss: 0.44502 Accuracy train: 0.89960 Accuracy val: 0.88400\n","2020-09-27 13:00:56.893333 Epoch: 37, Trainin Loss: 0.45980 Accuracy train: 0.88030 Accuracy val: 0.85800\n","2020-09-27 13:00:58.750404 Epoch: 38, Trainin Loss: 0.31801 Accuracy train: 0.89490 Accuracy val: 0.86350\n","2020-09-27 13:01:00.585573 Epoch: 39, Trainin Loss: 0.46366 Accuracy train: 0.85150 Accuracy val: 0.83650\n","2020-09-27 13:01:02.435262 Epoch: 40, Trainin Loss: 0.31387 Accuracy train: 0.90040 Accuracy val: 0.88050\n","2020-09-27 13:01:04.281007 Epoch: 41, Trainin Loss: 0.32796 Accuracy train: 0.90080 Accuracy val: 0.87350\n","2020-09-27 13:01:06.122884 Epoch: 42, Trainin Loss: 0.52020 Accuracy train: 0.81650 Accuracy val: 0.80400\n","2020-09-27 13:01:07.972109 Epoch: 43, Trainin Loss: 0.25326 Accuracy train: 0.91310 Accuracy val: 0.88900\n","2020-09-27 13:01:09.818882 Epoch: 44, Trainin Loss: 0.29789 Accuracy train: 0.89000 Accuracy val: 0.87000\n","2020-09-27 13:01:11.672100 Epoch: 45, Trainin Loss: 0.42571 Accuracy train: 0.79530 Accuracy val: 0.77050\n","2020-09-27 13:01:13.523919 Epoch: 46, Trainin Loss: 0.48627 Accuracy train: 0.86670 Accuracy val: 0.83800\n","2020-09-27 13:01:15.360980 Epoch: 47, Trainin Loss: 0.29862 Accuracy train: 0.91770 Accuracy val: 0.89200\n","2020-09-27 13:01:17.224871 Epoch: 48, Trainin Loss: 0.49079 Accuracy train: 0.87940 Accuracy val: 0.85750\n","2020-09-27 13:01:19.097828 Epoch: 49, Trainin Loss: 0.30568 Accuracy train: 0.88330 Accuracy val: 0.87350\n","2020-09-27 13:01:20.960062 Epoch: 50, Trainin Loss: 0.58024 Accuracy train: 0.85560 Accuracy val: 0.84600\n","2020-09-27 13:01:22.812037 Epoch: 51, Trainin Loss: 0.58991 Accuracy train: 0.82030 Accuracy val: 0.79000\n","2020-09-27 13:01:24.650307 Epoch: 52, Trainin Loss: 0.26415 Accuracy train: 0.90780 Accuracy val: 0.88600\n","2020-09-27 13:01:26.495141 Epoch: 53, Trainin Loss: 0.62339 Accuracy train: 0.85840 Accuracy val: 0.83000\n","2020-09-27 13:01:28.366579 Epoch: 54, Trainin Loss: 0.53360 Accuracy train: 0.86040 Accuracy val: 0.83450\n","2020-09-27 13:01:30.225985 Epoch: 55, Trainin Loss: 0.36708 Accuracy train: 0.87280 Accuracy val: 0.84100\n","2020-09-27 13:01:32.103579 Epoch: 56, Trainin Loss: 0.38144 Accuracy train: 0.90370 Accuracy val: 0.85900\n","2020-09-27 13:01:33.949533 Epoch: 57, Trainin Loss: 0.43416 Accuracy train: 0.89490 Accuracy val: 0.87600\n","2020-09-27 13:01:35.802103 Epoch: 58, Trainin Loss: 0.46378 Accuracy train: 0.88440 Accuracy val: 0.85250\n","2020-09-27 13:01:37.646037 Epoch: 59, Trainin Loss: 0.26630 Accuracy train: 0.92220 Accuracy val: 0.88450\n","2020-09-27 13:01:39.503314 Epoch: 60, Trainin Loss: 0.49798 Accuracy train: 0.75120 Accuracy val: 0.72350\n","2020-09-27 13:01:41.338067 Epoch: 61, Trainin Loss: 0.58973 Accuracy train: 0.79900 Accuracy val: 0.77450\n","2020-09-27 13:01:43.180966 Epoch: 62, Trainin Loss: 0.38581 Accuracy train: 0.86990 Accuracy val: 0.84950\n","2020-09-27 13:01:45.036141 Epoch: 63, Trainin Loss: 0.44232 Accuracy train: 0.82460 Accuracy val: 0.79850\n","2020-09-27 13:01:46.908444 Epoch: 64, Trainin Loss: 0.64296 Accuracy train: 0.82440 Accuracy val: 0.80750\n","2020-09-27 13:01:48.744987 Epoch: 65, Trainin Loss: 0.34079 Accuracy train: 0.82450 Accuracy val: 0.80700\n","2020-09-27 13:01:50.610442 Epoch: 66, Trainin Loss: 0.61279 Accuracy train: 0.75460 Accuracy val: 0.73050\n","2020-09-27 13:01:52.469035 Epoch: 67, Trainin Loss: 0.29573 Accuracy train: 0.90100 Accuracy val: 0.87500\n","2020-09-27 13:01:54.315497 Epoch: 68, Trainin Loss: 0.50985 Accuracy train: 0.90550 Accuracy val: 0.87950\n","2020-09-27 13:01:56.145304 Epoch: 69, Trainin Loss: 0.31228 Accuracy train: 0.91090 Accuracy val: 0.87900\n","2020-09-27 13:01:57.983724 Epoch: 70, Trainin Loss: 0.41448 Accuracy train: 0.81240 Accuracy val: 0.77900\n","2020-09-27 13:01:59.822979 Epoch: 71, Trainin Loss: 0.61610 Accuracy train: 0.80790 Accuracy val: 0.78200\n","2020-09-27 13:02:01.672267 Epoch: 72, Trainin Loss: 0.36555 Accuracy train: 0.92410 Accuracy val: 0.89850\n","2020-09-27 13:02:03.544318 Epoch: 73, Trainin Loss: 0.24724 Accuracy train: 0.91570 Accuracy val: 0.87250\n","2020-09-27 13:02:05.400038 Epoch: 74, Trainin Loss: 0.37999 Accuracy train: 0.91940 Accuracy val: 0.88800\n","2020-09-27 13:02:07.290296 Epoch: 75, Trainin Loss: 0.44883 Accuracy train: 0.86120 Accuracy val: 0.81950\n","2020-09-27 13:02:09.159722 Epoch: 76, Trainin Loss: 0.37347 Accuracy train: 0.85490 Accuracy val: 0.83600\n","2020-09-27 13:02:11.015073 Epoch: 77, Trainin Loss: 0.48376 Accuracy train: 0.93020 Accuracy val: 0.89300\n","2020-09-27 13:02:12.864033 Epoch: 78, Trainin Loss: 0.61100 Accuracy train: 0.74770 Accuracy val: 0.71650\n","2020-09-27 13:02:14.718359 Epoch: 79, Trainin Loss: 0.41185 Accuracy train: 0.87550 Accuracy val: 0.84250\n","2020-09-27 13:02:16.568751 Epoch: 80, Trainin Loss: 0.42138 Accuracy train: 0.84890 Accuracy val: 0.81150\n","2020-09-27 13:02:18.436065 Epoch: 81, Trainin Loss: 0.34859 Accuracy train: 0.92290 Accuracy val: 0.88050\n","2020-09-27 13:02:20.295877 Epoch: 82, Trainin Loss: 0.58737 Accuracy train: 0.86460 Accuracy val: 0.80950\n","2020-09-27 13:02:22.150937 Epoch: 83, Trainin Loss: 0.22512 Accuracy train: 0.92610 Accuracy val: 0.88800\n","2020-09-27 13:02:24.002988 Epoch: 84, Trainin Loss: 0.31526 Accuracy train: 0.90250 Accuracy val: 0.86250\n","2020-09-27 13:02:25.859070 Epoch: 85, Trainin Loss: 0.36383 Accuracy train: 0.89660 Accuracy val: 0.85750\n","2020-09-27 13:02:27.722932 Epoch: 86, Trainin Loss: 0.31352 Accuracy train: 0.87160 Accuracy val: 0.84300\n","2020-09-27 13:02:29.586116 Epoch: 87, Trainin Loss: 0.45980 Accuracy train: 0.89570 Accuracy val: 0.84250\n","2020-09-27 13:02:31.442327 Epoch: 88, Trainin Loss: 0.24454 Accuracy train: 0.93260 Accuracy val: 0.89600\n","2020-09-27 13:02:33.300394 Epoch: 89, Trainin Loss: 0.48707 Accuracy train: 0.90280 Accuracy val: 0.86900\n","2020-09-27 13:02:35.138970 Epoch: 90, Trainin Loss: 0.22440 Accuracy train: 0.93780 Accuracy val: 0.89300\n","2020-09-27 13:02:36.988908 Epoch: 91, Trainin Loss: 0.25010 Accuracy train: 0.92150 Accuracy val: 0.89150\n","2020-09-27 13:02:38.858032 Epoch: 92, Trainin Loss: 0.55874 Accuracy train: 0.83390 Accuracy val: 0.80400\n","2020-09-27 13:02:40.720906 Epoch: 93, Trainin Loss: 0.52785 Accuracy train: 0.86740 Accuracy val: 0.82850\n","2020-09-27 13:02:42.573150 Epoch: 94, Trainin Loss: 0.45144 Accuracy train: 0.87210 Accuracy val: 0.84050\n","2020-09-27 13:02:44.415060 Epoch: 95, Trainin Loss: 0.31469 Accuracy train: 0.86870 Accuracy val: 0.84100\n","2020-09-27 13:02:46.264956 Epoch: 96, Trainin Loss: 0.30410 Accuracy train: 0.93420 Accuracy val: 0.88750\n","2020-09-27 13:02:48.116940 Epoch: 97, Trainin Loss: 0.26278 Accuracy train: 0.92540 Accuracy val: 0.87450\n","2020-09-27 13:02:49.989090 Epoch: 98, Trainin Loss: 0.40879 Accuracy train: 0.77300 Accuracy val: 0.73550\n","2020-09-27 13:02:51.847017 Epoch: 99, Trainin Loss: 0.50464 Accuracy train: 0.88000 Accuracy val: 0.84050\n","2020-09-27 13:02:53.716952 Epoch: 100, Trainin Loss: 0.23856 Accuracy train: 0.93950 Accuracy val: 0.89600\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2SLGrTB0-Q1X"},"source":["## ResNet-like NN model - *Test*"]},{"cell_type":"code","metadata":{"id":"W4WatKZ6-QGf"},"source":["model = NetResDeep()\n","\n","n_epochs = 100\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = torch.utils.data.DataLoader(\n","    cifar2, batch_size = 64, shuffle = True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    cifar2_val, batch_size = 64, shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtS7ZTDW-m_6","executionInfo":{"status":"ok","timestamp":1601211775829,"user_tz":-120,"elapsed":1032494,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"2b63e60d-3efa-4abe-94fc-80d78cdf19e0","colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NetResDeep(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (resblocks): Sequential(\n","    (0): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (4): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (5): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (6): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (7): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (8): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (9): ResBlock(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (fc1): Linear(in_features=2048, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"wTY3OJ0s-oJj","executionInfo":{"status":"ok","timestamp":1601211775830,"user_tz":-120,"elapsed":1032478,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"e3265757-de7a-41cc-9ce2-2a9643a4ef94","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","sum(numel_list), numel_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(75810, [864, 32, 9216, 32, 32, 65536, 32, 64, 2])"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"id":"DczzPIcD-ZND","executionInfo":{"status":"ok","timestamp":1601212248880,"user_tz":-120,"elapsed":1505509,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"5a60e626-efa2-4970-8b3b-63edf4fc823b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batched_convnet_training_loop(model.to(device = device), loss, optimizer, train_loader, val_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-27 13:02:58.498256 Epoch: 1, Trainin Loss: 0.14855 Accuracy train: 0.50200 Accuracy val: 0.50300\n","2020-09-27 13:03:03.231297 Epoch: 2, Trainin Loss: 0.12685 Accuracy train: 0.50070 Accuracy val: 0.50000\n","2020-09-27 13:03:07.960182 Epoch: 3, Trainin Loss: 0.27534 Accuracy train: 0.58940 Accuracy val: 0.59250\n","2020-09-27 13:03:12.693694 Epoch: 4, Trainin Loss: 0.37004 Accuracy train: 0.65660 Accuracy val: 0.65950\n","2020-09-27 13:03:17.423534 Epoch: 5, Trainin Loss: 0.36202 Accuracy train: 0.81760 Accuracy val: 0.81850\n","2020-09-27 13:03:22.163156 Epoch: 6, Trainin Loss: 0.45932 Accuracy train: 0.56580 Accuracy val: 0.56950\n","2020-09-27 13:03:26.892394 Epoch: 7, Trainin Loss: 0.46918 Accuracy train: 0.83480 Accuracy val: 0.83100\n","2020-09-27 13:03:31.623207 Epoch: 8, Trainin Loss: 0.30491 Accuracy train: 0.82600 Accuracy val: 0.82600\n","2020-09-27 13:03:36.353863 Epoch: 9, Trainin Loss: 0.18666 Accuracy train: 0.74550 Accuracy val: 0.74350\n","2020-09-27 13:03:41.082777 Epoch: 10, Trainin Loss: 0.09613 Accuracy train: 0.80310 Accuracy val: 0.81850\n","2020-09-27 13:03:45.813187 Epoch: 11, Trainin Loss: 0.13026 Accuracy train: 0.83620 Accuracy val: 0.83750\n","2020-09-27 13:03:50.548040 Epoch: 12, Trainin Loss: 0.15533 Accuracy train: 0.66650 Accuracy val: 0.67650\n","2020-09-27 13:03:55.272106 Epoch: 13, Trainin Loss: 0.79772 Accuracy train: 0.76570 Accuracy val: 0.76750\n","2020-09-27 13:03:59.984753 Epoch: 14, Trainin Loss: 0.13423 Accuracy train: 0.82810 Accuracy val: 0.81900\n","2020-09-27 13:04:04.714113 Epoch: 15, Trainin Loss: 0.31714 Accuracy train: 0.71420 Accuracy val: 0.72250\n","2020-09-27 13:04:09.452505 Epoch: 16, Trainin Loss: 0.07649 Accuracy train: 0.78980 Accuracy val: 0.78400\n","2020-09-27 13:04:14.185230 Epoch: 17, Trainin Loss: 0.13694 Accuracy train: 0.76790 Accuracy val: 0.76000\n","2020-09-27 13:04:18.911674 Epoch: 18, Trainin Loss: 0.06692 Accuracy train: 0.81310 Accuracy val: 0.80000\n","2020-09-27 13:04:23.636403 Epoch: 19, Trainin Loss: 0.03619 Accuracy train: 0.78900 Accuracy val: 0.78550\n","2020-09-27 13:04:28.371259 Epoch: 20, Trainin Loss: 0.20740 Accuracy train: 0.64390 Accuracy val: 0.64600\n","2020-09-27 13:04:33.088209 Epoch: 21, Trainin Loss: 0.13162 Accuracy train: 0.78250 Accuracy val: 0.77600\n","2020-09-27 13:04:37.826217 Epoch: 22, Trainin Loss: 0.17351 Accuracy train: 0.81270 Accuracy val: 0.81200\n","2020-09-27 13:04:42.562099 Epoch: 23, Trainin Loss: 0.00959 Accuracy train: 0.76460 Accuracy val: 0.76000\n","2020-09-27 13:04:47.291634 Epoch: 24, Trainin Loss: 0.40982 Accuracy train: 0.56780 Accuracy val: 0.58100\n","2020-09-27 13:04:52.032436 Epoch: 25, Trainin Loss: 0.02627 Accuracy train: 0.76280 Accuracy val: 0.75750\n","2020-09-27 13:04:56.767539 Epoch: 26, Trainin Loss: 0.04958 Accuracy train: 0.78990 Accuracy val: 0.78500\n","2020-09-27 13:05:01.498363 Epoch: 27, Trainin Loss: 0.02641 Accuracy train: 0.76140 Accuracy val: 0.75200\n","2020-09-27 13:05:06.229480 Epoch: 28, Trainin Loss: 0.04209 Accuracy train: 0.82600 Accuracy val: 0.81500\n","2020-09-27 13:05:10.961462 Epoch: 29, Trainin Loss: 0.08918 Accuracy train: 0.78600 Accuracy val: 0.76900\n","2020-09-27 13:05:15.693601 Epoch: 30, Trainin Loss: 0.13907 Accuracy train: 0.77810 Accuracy val: 0.77400\n","2020-09-27 13:05:20.431038 Epoch: 31, Trainin Loss: 0.03465 Accuracy train: 0.80510 Accuracy val: 0.78950\n","2020-09-27 13:05:25.158399 Epoch: 32, Trainin Loss: 0.00814 Accuracy train: 0.81980 Accuracy val: 0.79650\n","2020-09-27 13:05:29.887098 Epoch: 33, Trainin Loss: 0.03422 Accuracy train: 0.78350 Accuracy val: 0.77100\n","2020-09-27 13:05:34.632280 Epoch: 34, Trainin Loss: 0.00687 Accuracy train: 0.76970 Accuracy val: 0.76200\n","2020-09-27 13:05:39.354439 Epoch: 35, Trainin Loss: 0.10577 Accuracy train: 0.81730 Accuracy val: 0.80250\n","2020-09-27 13:05:44.088413 Epoch: 36, Trainin Loss: 0.18268 Accuracy train: 0.65240 Accuracy val: 0.66200\n","2020-09-27 13:05:48.821170 Epoch: 37, Trainin Loss: 0.00576 Accuracy train: 0.77260 Accuracy val: 0.77150\n","2020-09-27 13:05:53.557693 Epoch: 38, Trainin Loss: 0.06575 Accuracy train: 0.82010 Accuracy val: 0.80050\n","2020-09-27 13:05:58.280511 Epoch: 39, Trainin Loss: 0.01305 Accuracy train: 0.83040 Accuracy val: 0.81450\n","2020-09-27 13:06:03.015925 Epoch: 40, Trainin Loss: 0.01147 Accuracy train: 0.77410 Accuracy val: 0.77050\n","2020-09-27 13:06:07.743077 Epoch: 41, Trainin Loss: 0.03235 Accuracy train: 0.77390 Accuracy val: 0.76600\n","2020-09-27 13:06:12.471102 Epoch: 42, Trainin Loss: 0.03926 Accuracy train: 0.83280 Accuracy val: 0.83350\n","2020-09-27 13:06:17.192413 Epoch: 43, Trainin Loss: 0.00332 Accuracy train: 0.85550 Accuracy val: 0.84050\n","2020-09-27 13:06:21.929270 Epoch: 44, Trainin Loss: 0.01691 Accuracy train: 0.84050 Accuracy val: 0.82650\n","2020-09-27 13:06:26.656815 Epoch: 45, Trainin Loss: 0.01029 Accuracy train: 0.85830 Accuracy val: 0.83650\n","2020-09-27 13:06:31.390870 Epoch: 46, Trainin Loss: 0.01548 Accuracy train: 0.84460 Accuracy val: 0.82850\n","2020-09-27 13:06:36.125264 Epoch: 47, Trainin Loss: 0.01376 Accuracy train: 0.84440 Accuracy val: 0.82150\n","2020-09-27 13:06:40.854465 Epoch: 48, Trainin Loss: 0.02240 Accuracy train: 0.85130 Accuracy val: 0.82800\n","2020-09-27 13:06:45.579772 Epoch: 49, Trainin Loss: 0.03844 Accuracy train: 0.76230 Accuracy val: 0.76300\n","2020-09-27 13:06:50.316175 Epoch: 50, Trainin Loss: 0.12309 Accuracy train: 0.83580 Accuracy val: 0.82300\n","2020-09-27 13:06:55.052009 Epoch: 51, Trainin Loss: 0.10962 Accuracy train: 0.81430 Accuracy val: 0.80900\n","2020-09-27 13:06:59.776391 Epoch: 52, Trainin Loss: 0.00701 Accuracy train: 0.84480 Accuracy val: 0.81600\n","2020-09-27 13:07:04.505073 Epoch: 53, Trainin Loss: 0.15140 Accuracy train: 0.80780 Accuracy val: 0.81250\n","2020-09-27 13:07:09.239003 Epoch: 54, Trainin Loss: 0.07347 Accuracy train: 0.75310 Accuracy val: 0.75950\n","2020-09-27 13:07:13.976477 Epoch: 55, Trainin Loss: 0.00121 Accuracy train: 0.85010 Accuracy val: 0.83550\n","2020-09-27 13:07:18.707105 Epoch: 56, Trainin Loss: 0.00728 Accuracy train: 0.83630 Accuracy val: 0.83100\n","2020-09-27 13:07:23.442018 Epoch: 57, Trainin Loss: 0.00147 Accuracy train: 0.85110 Accuracy val: 0.83350\n","2020-09-27 13:07:28.167681 Epoch: 58, Trainin Loss: 0.00896 Accuracy train: 0.84570 Accuracy val: 0.82250\n","2020-09-27 13:07:32.890339 Epoch: 59, Trainin Loss: 0.00179 Accuracy train: 0.80740 Accuracy val: 0.79100\n","2020-09-27 13:07:37.626843 Epoch: 60, Trainin Loss: 0.00034 Accuracy train: 0.84690 Accuracy val: 0.82500\n","2020-09-27 13:07:42.353071 Epoch: 61, Trainin Loss: 0.00290 Accuracy train: 0.83140 Accuracy val: 0.82150\n","2020-09-27 13:07:47.090263 Epoch: 62, Trainin Loss: 0.00406 Accuracy train: 0.84360 Accuracy val: 0.82600\n","2020-09-27 13:07:51.818526 Epoch: 63, Trainin Loss: 0.00466 Accuracy train: 0.84650 Accuracy val: 0.82600\n","2020-09-27 13:07:56.543085 Epoch: 64, Trainin Loss: 0.01248 Accuracy train: 0.83240 Accuracy val: 0.81150\n","2020-09-27 13:08:01.265802 Epoch: 65, Trainin Loss: 0.00335 Accuracy train: 0.84440 Accuracy val: 0.82500\n","2020-09-27 13:08:05.993529 Epoch: 66, Trainin Loss: 0.00009 Accuracy train: 0.82410 Accuracy val: 0.81100\n","2020-09-27 13:08:10.719131 Epoch: 67, Trainin Loss: 0.00005 Accuracy train: 0.84170 Accuracy val: 0.82650\n","2020-09-27 13:08:15.454857 Epoch: 68, Trainin Loss: 0.00125 Accuracy train: 0.84490 Accuracy val: 0.82750\n","2020-09-27 13:08:20.188217 Epoch: 69, Trainin Loss: 0.00414 Accuracy train: 0.84710 Accuracy val: 0.83100\n","2020-09-27 13:08:24.907428 Epoch: 70, Trainin Loss: 0.00271 Accuracy train: 0.83500 Accuracy val: 0.82200\n","2020-09-27 13:08:29.636474 Epoch: 71, Trainin Loss: 0.00015 Accuracy train: 0.84370 Accuracy val: 0.82900\n","2020-09-27 13:08:34.367336 Epoch: 72, Trainin Loss: 0.00414 Accuracy train: 0.85270 Accuracy val: 0.83350\n","2020-09-27 13:08:39.095503 Epoch: 73, Trainin Loss: 0.00003 Accuracy train: 0.85000 Accuracy val: 0.83150\n","2020-09-27 13:08:43.828556 Epoch: 74, Trainin Loss: 0.00003 Accuracy train: 0.85090 Accuracy val: 0.82700\n","2020-09-27 13:08:48.552530 Epoch: 75, Trainin Loss: 0.00158 Accuracy train: 0.83050 Accuracy val: 0.81550\n","2020-09-27 13:08:53.291013 Epoch: 76, Trainin Loss: 0.00023 Accuracy train: 0.84880 Accuracy val: 0.83300\n","2020-09-27 13:08:58.008052 Epoch: 77, Trainin Loss: 0.00472 Accuracy train: 0.84930 Accuracy val: 0.82650\n","2020-09-27 13:09:02.738785 Epoch: 78, Trainin Loss: 0.00100 Accuracy train: 0.82960 Accuracy val: 0.81350\n","2020-09-27 13:09:07.459085 Epoch: 79, Trainin Loss: 0.00183 Accuracy train: 0.84660 Accuracy val: 0.82600\n","2020-09-27 13:09:12.187815 Epoch: 80, Trainin Loss: 0.00143 Accuracy train: 0.82280 Accuracy val: 0.80950\n","2020-09-27 13:09:16.915686 Epoch: 81, Trainin Loss: 0.01119 Accuracy train: 0.85010 Accuracy val: 0.82950\n","2020-09-27 13:09:21.646223 Epoch: 82, Trainin Loss: 0.00037 Accuracy train: 0.85060 Accuracy val: 0.83750\n","2020-09-27 13:09:26.381330 Epoch: 83, Trainin Loss: 0.00037 Accuracy train: 0.85370 Accuracy val: 0.83100\n","2020-09-27 13:09:31.119883 Epoch: 84, Trainin Loss: 0.05592 Accuracy train: 0.67650 Accuracy val: 0.66450\n","2020-09-27 13:09:35.849620 Epoch: 85, Trainin Loss: 0.11571 Accuracy train: 0.77930 Accuracy val: 0.78350\n","2020-09-27 13:09:40.585396 Epoch: 86, Trainin Loss: 0.07040 Accuracy train: 0.84140 Accuracy val: 0.82400\n","2020-09-27 13:09:45.309875 Epoch: 87, Trainin Loss: 0.15241 Accuracy train: 0.77790 Accuracy val: 0.77500\n","2020-09-27 13:09:50.028254 Epoch: 88, Trainin Loss: 0.05324 Accuracy train: 0.70070 Accuracy val: 0.70600\n","2020-09-27 13:09:54.751111 Epoch: 89, Trainin Loss: 0.44868 Accuracy train: 0.69050 Accuracy val: 0.68600\n","2020-09-27 13:09:59.476062 Epoch: 90, Trainin Loss: 0.00879 Accuracy train: 0.83860 Accuracy val: 0.82700\n","2020-09-27 13:10:04.204324 Epoch: 91, Trainin Loss: 0.00614 Accuracy train: 0.82960 Accuracy val: 0.81800\n","2020-09-27 13:10:08.934830 Epoch: 92, Trainin Loss: 0.01772 Accuracy train: 0.80140 Accuracy val: 0.80050\n","2020-09-27 13:10:13.656495 Epoch: 93, Trainin Loss: 0.02568 Accuracy train: 0.83740 Accuracy val: 0.81600\n","2020-09-27 13:10:18.385536 Epoch: 94, Trainin Loss: 0.01509 Accuracy train: 0.83810 Accuracy val: 0.82750\n","2020-09-27 13:10:23.111523 Epoch: 95, Trainin Loss: 0.00493 Accuracy train: 0.81730 Accuracy val: 0.80000\n","2020-09-27 13:10:27.839520 Epoch: 96, Trainin Loss: 0.00260 Accuracy train: 0.82690 Accuracy val: 0.81000\n","2020-09-27 13:10:32.559224 Epoch: 97, Trainin Loss: 0.07092 Accuracy train: 0.76380 Accuracy val: 0.75550\n","2020-09-27 13:10:37.292017 Epoch: 98, Trainin Loss: 0.16606 Accuracy train: 0.79610 Accuracy val: 0.79150\n","2020-09-27 13:10:42.009167 Epoch: 99, Trainin Loss: 0.11231 Accuracy train: 0.82930 Accuracy val: 0.81600\n","2020-09-27 13:10:46.733035 Epoch: 100, Trainin Loss: 0.19971 Accuracy train: 0.76560 Accuracy val: 0.76050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wkGc1E9g-cM0"},"source":["data_path = '/content/'\n","torch.save(model.state_dict(), data_path + 'ResNet_norm_batchnorm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"czekvB1N-j0A"},"source":["# data_path = '/content/'\n","# torch.save(model.state_dict(), data_path + 'ResNet_norm_batchnorm_birds_vs_airplane.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gu0sDu889AfK","executionInfo":{"status":"ok","timestamp":1601216713930,"user_tz":-120,"elapsed":1173,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"4c34a091-3ba4-40b3-f66c-aef0118777c8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.device_count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"4JydZol09GjU","executionInfo":{"status":"ok","timestamp":1601216739812,"user_tz":-120,"elapsed":949,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"2319f26d-eba6-4a1f-a34d-11b45ad1d0ec","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.current_device()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"7DC_D4S6sFy8"},"source":["## References\n","\n","- Pytorch Reference's Manual:\n"," - [torch.nn module](https://pytorch.org/docs/stable/nn.html)\n","\n","- Initialization Topic (Papers):\n","  - [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) by X. Glorot & Y.Bengio, which lead to default Pytorch's weights initialization knwon as *Xavier initialization* algorithm or scheme\n"," -  [Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/abs/1901.09321) by Hongyi Zhang, Yann N. Dauphin, Tengyu Ma, whose works allows to *get rid off batch normalization layers* with a given particular NN Arch, to still be able to train a NN arch with meaningful and confident results or performance.\n","\n","- Activation Functions (Papers):\n","  - [Deep Learning using Rectified Linear Units (ReLU)](https://arxiv.org/pdf/1803.08375.pdf)\n","\n","- Datasets:\n","  - [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n","\n","- Regularization techniques (Papers):\n","  - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shif](https://arxiv.org/abs/1502.03167)\n","  - [Dropout: A Simple Way to Prevent Neural Networks from\n","Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n","\n","- Archs Types (Papers):\n","  - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n","  - [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n","  - [Highway Networks\n","](https://arxiv.org/pdf/1505.00387.pdf)\n","  - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)\n","\n","- Some Third Party useful Tutorials:\n"," - [Imagenet example](https://github.com/pytorch/examples/blob/master/imagenet/main.py#L327)\n"," - [Writing a better code with pytorch and einops](https://arogozhnikov.github.io/einops/pytorch-examples.html)\n","\n","- Books\n","  - [List of books for improving Pytorch knowledge](https://bookauthority.org/books/best-pytorch-books)"]}]}