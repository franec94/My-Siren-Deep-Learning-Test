{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"siren_loop_over_BSD68_one_image_at_a_time.ipynb","provenance":[{"file_id":"1np6YBBmnB4LA560DnuIXYfKzcAqkY7gD","timestamp":1601710268312},{"file_id":"1EkWvZCwSs_XglEyzSmTBxLuPcl6SWhW0","timestamp":1601546282518}],"collapsed_sections":["laFJz7Zu9xaI","Yjsx1yjd9zwR","j62f3cAY-B0E","5K2_rjcLQ7r5","dC1utPkx-WDa","Gb19GFz--hg1","73gHw67dQB0v","ef9EGPkzA_IG","l6P06pMexFoK","qmMEVQfdnOK0","UgE6UqEN-zhD","8t7yjXAbtLlF"],"mount_file_id":"1FlpHZX-zV2R_RN79_TxaabS0UN0wmZSm","authorship_tag":"ABX9TyPS+1IZ72elqOFjuXP4grhF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KbBwYEm396cI","executionInfo":{"status":"ok","timestamp":1601714335191,"user_tz":-120,"elapsed":1513,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# !pip install visdom"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laFJz7Zu9xaI"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"Yjsx1yjd9zwR"},"source":["### Standard Imports"]},{"cell_type":"code","metadata":{"id":"IHt9ZFqF9s6w","executionInfo":{"status":"ok","timestamp":1601714335515,"user_tz":-120,"elapsed":1827,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["from __future__ import print_function\n","from __future__ import division\n","\n","from pprint import pprint\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as sts\n","\n","import argparse\n","import copy\n","import datetime\n","import os\n","import random\n","import skimage\n","import shutil\n","import time\n","# import visdom\n","import warnings"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j62f3cAY-B0E"},"source":["### Torch imports"]},{"cell_type":"code","metadata":{"id":"dIlC57oD-EQ8","executionInfo":{"status":"ok","timestamp":1601714335516,"user_tz":-120,"elapsed":1819,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["import torch\n","import torchvision\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lXzbFIoL07Kn"},"source":["## Setting Notebook"]},{"cell_type":"markdown","metadata":{"id":"5K2_rjcLQ7r5"},"source":["### Custom Argparser"]},{"cell_type":"code","metadata":{"id":"wybP1xvhQ9rw","executionInfo":{"status":"ok","timestamp":1601714335517,"user_tz":-120,"elapsed":1812,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"c3aec5fc-c063-48e9-fd22-2a4a91002d0e","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["parser = argparse.ArgumentParser(description='PyTorch SirenNet Training')\n","\"\"\"parser.add_argument('data', metavar='DIR',\n","                    help='path to dataset')\"\"\"\n","parser.add_argument('--epochs', default=90, type=int, metavar='N',\n","                    help='number of total epochs to run')\n","parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n","                    help='manual epoch number (useful on restarts)')\n","parser.add_argument('-b', '--batch-size', default=256, type=int,\n","                    metavar='N',\n","                    help='mini-batch size (default: 256), this is the total '\n","                         'batch size of all GPUs on the current node when '\n","                         'using Data Parallel or Distributed Data Parallel')\n","parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float,\n","                    metavar='LR', help='initial learning rate, (default: 1e-4)', dest='lr')\n","parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n","                    help='momentum')\n","parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n","                    metavar='W', help='weight decay (default: 1e-4)',\n","                    dest='weight_decay')\n","parser.add_argument('-p', '--print-freq', default=10, type=int,\n","                    metavar='N', help='print frequency (default: 10)')\n","parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n","                    help='evaluate model on validation set')\n","parser.add_argument('--seed', default=None, type=int,\n","                    help='seed for initializing training. ')\n","parser.add_argument('--gpu', default=None, type=int,\n","                    help='GPU id to use.')\n","parser.add_argument('--results-path', default=\"results\", type=str, dest=\"results_path\",\n","                    help='Local File System path where results will be stored.')\n","parser.add_argument('--image_path', type=str, dest=\"image_path\",\n","                    help='Local File System path where results will be stored.')\n","parser.add_argument('--num-trials-per-img', type=int, default=5, dest=\"num_trials\",\n","                    help='Number of trials per image, (default: 5).')\n","parser.add_argument('--compression-factor', type=int, default=128, dest=\"compression_factor\",\n","                    help='Image\\'s compression factor, (default: 128).')"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--num-trials-per-img'], dest='num_trials', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, help='Number of trials per image, (default: 5).', metavar=None)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"_dcwVnhBfw36","executionInfo":{"status":"ok","timestamp":1601714335517,"user_tz":-120,"elapsed":1803,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"f3904620-6549-49b1-cd88-c572c49ab8b9","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["args, unknown = parser.parse_known_args()\n","\n","pprint(args)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=256, epochs=90, evaluate=False, gpu=None, image_path=None, lr=0.0001, momentum=0.9, num_trials=5, print_freq=10, results_path='results', seed=None, start_epoch=0, weight_decay=0.0001)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b4wxatd1-Z0P","executionInfo":{"status":"ok","timestamp":1601714335518,"user_tz":-120,"elapsed":1795,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"3d2d0683-9efc-4e9f-c740-0769a0a3159b","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["PyTorch Version:  1.6.0+cu101\n","Torchvision Version:  0.7.0+cu101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dC1utPkx-WDa"},"source":["### Set seeds for repeatability"]},{"cell_type":"code","metadata":{"id":"bMjJBG5a-eIi","executionInfo":{"status":"ok","timestamp":1601714335520,"user_tz":-120,"elapsed":1788,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["if args.seed == None: args.seed = 0\n","\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed)\n","random.seed(args.seed)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","feature_extract = True"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gb19GFz--hg1"},"source":["### Set device - either gpu:0 or cpu"]},{"cell_type":"code","metadata":{"id":"e_PE_VJ7-hHT","executionInfo":{"status":"ok","timestamp":1601714335520,"user_tz":-120,"elapsed":1780,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"68a17d23-14a0-4cf6-e5ea-11df538cec88","colab":{"base_uri":"https://localhost:8080/","height":0}},"source":["# Detect if we have a GPU available\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = (torch.device('cuda:0') if torch.cuda.is_available()\n","    else torch.device('gpu'))\n","print(f\"Training on device {device}.\")\n","print(f\"# cuda device: {torch.cuda.device_count()}\")\n","print(f\"Id current device: {torch.cuda.current_device()}\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Training on device cuda:0.\n","# cuda device: 1\n","Id current device: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73gHw67dQB0v"},"source":["## Siren Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"_mhTSW7gQGhQ","executionInfo":{"status":"ok","timestamp":1601714335521,"user_tz":-120,"elapsed":1772,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# Siren's architecture Hyper-params\n","in_features = 2\n","out_features = 1\n","sidelength = args.compression_factor # 256\n","hidden_layers = 3\n","\n","# Training phase's Hyper-params\n","learning_rate = args.lr\n","epochs = args.epochs\n","\n","# Displaying Images\n","num_trials = args.num_trials\n","steps_til_summary = args.print_freq\n","\n","if args.image_path is None:\n","    # image_path = \"/content/drive/My Drive/Siren Deep Learning Analyses/testsets/BSD68/test001.png\"\n","    image_path = \"/content/test001.png\"\n","else: image_path = args.image_path"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_3snv48WKEx","executionInfo":{"status":"ok","timestamp":1601714335521,"user_tz":-120,"elapsed":1764,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"34b89f2c-dc14-486c-cb6d-6cfd675c16cf","colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["root_analisys = \"/content/drive/My Drive/Siren Deep Learning Analyses/\"\n","\n","results_path = \"results\"\n","dataset_name = \"BSD68\"\n","image_name = \"test001\"\n","\n","results_dataset_dir = os.path.join(root_analisys, results_path, dataset_name)\n","results_img_dir = os.path.join(root_analisys, results_path, dataset_name, image_name)\n","\n","try: os.makedirs(results_dataset_dir)\n","except: pass\n","\n","try: os.makedirs(results_img_dir)\n","except: pass\n","\n","df_results_path = os.path.join(results_dataset_dir, \"results.csv\")\n","if os.path.exists(df_results_path) and os.path.isfile(df_results_path):\n","    df_results = pd.pd.read_csv(df_results_path)\n","else:\n","    columns_df = \"timestamp;dataset;image;seed;last_train_loss;arch;args;\".split(\";\")\n","    df_results = pd.DataFrame(columns = columns_df)\n","df_results.head(5)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>dataset</th>\n","      <th>image</th>\n","      <th>seed</th>\n","      <th>last_train_loss</th>\n","      <th>arch</th>\n","      <th>args</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [timestamp, dataset, image, seed, last_train_loss, arch, args, ]\n","Index: []"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"ef9EGPkzA_IG"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"l6P06pMexFoK"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"bgYiW2fNdHf6","executionInfo":{"status":"ok","timestamp":1601714335522,"user_tz":-120,"elapsed":1756,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def get_all_images_from_path(path_images):\n","    # bsd68_path = \"/content/drive/My Drive/Siren Deep Learning Analyses/testsets/BSD68\"\n","    images = []\n","    \n","    for (dirpath, dirnames, filenames) in os.walk(path_images):\n","        full_file_path_list = list()\n","        for a_file in sorted(filenames):\n","            full_file_path_list.append(os.path.join(dirpath, a_file))\n","            pass\n","        images.extend(full_file_path_list)\n","        pass\n","    return images"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_8R0BaCy5vf","executionInfo":{"status":"ok","timestamp":1601714335522,"user_tz":-120,"elapsed":1748,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def show_hist_kde_train_loss(bins = 10, fig_name=\"hist_kde_train_loss.png\", resample_from_hist = False):\n","    samples = df['train_loss'].values\n","    n = len(samples)\n","    \n","    h, e = np.histogram(samples, bins=bins, density=True)\n","    x = np.linspace(e.min(), e.max())\n","\n","    # plot the histogram\n","    plt.figure(figsize=(8,6))\n","    plt.bar(e[:-1], h, width=np.diff(e), ec='k', align='edge', label='histogram')\n","\n","    # plot the real KDE\n","    kde = sts.gaussian_kde(samples)\n","    plt.plot(x, kde.pdf(x), c='C1', lw=8, label='KDE')\n","\n","    if resample_from_hist is True:\n","        # resample the histogram and find the KDE.\n","        resamples = np.random.choice((e[:-1] + e[1:])/2, size=n*5, p=h/h.sum())\n","        rkde = sts.gaussian_kde(resamples)\n","\n","    # plot the KDE\n","    plt.plot(x, rkde.pdf(x), '--', c='C3', lw=4, label='resampled KDE')\n","    plt.title('Train Loss: n = %d samples' % n)\n","    plt.legend()\n","    plt.savefig(fig_name)\n","    plt.show()\n","    pass"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDnbi3B2xDw3","executionInfo":{"status":"ok","timestamp":1601714335523,"user_tz":-120,"elapsed":1740,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def printImageAttributes(imageObject, imagePath):\n","\n","    # Retrieve the attributes of the image\n","\n","    fileFormat      = imageObject.format        # Format of the image\n","    imageMode       = imageObject.mode          # Mode of the image\n","    imageSize       = imageObject.size          # Size of the image - tupe of (width, height)\n","    colorPalette    = imageObject.palette       # Palette used in the image\n","\n","    # Print the attributes of the image\n","    print(\"Attributes of image:%s\"%imagePath)\n","    print(\"The file format of the image is:%s\"%fileFormat)\n","    print(\"The mode of the image is:%s\"%imageMode)\n","    print(\"The size of the image is:width %d pixels,height %d pixels\"%imageSize)\n","    print(\"Color palette used in image:%s\"%colorPalette)\n","    print(\"Keys from image.info dictionary:%s\")\n","\n","    for key, value in imageObject.info.items() :\n","        print(key); print(value)\n","        pass\n","    pass\n","\n","def get_cameraman_tensor(sidelength):\n","    # print(type(skimage.data.camera()))\n","    img = Image.fromarray(skimage.data.camera())\n","    \n","    # print(type(img))\n","    printImageAttributes(img, \"cameraman\")\n","\n","    transform = Compose([\n","        Resize(sidelength),\n","        ToTensor(),\n","        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","    ])\n","    img = transform(img)\n","    return img"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AxqxasEBCN6","executionInfo":{"status":"ok","timestamp":1601714335523,"user_tz":-120,"elapsed":1730,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def get_mgrid(sidelen, dim=2):\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Xl9dh8ln6rP","executionInfo":{"status":"ok","timestamp":1601714335524,"user_tz":-120,"elapsed":1722,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def get_model(in_features, out_features, hidden_features, hidden_layers):\n","    img_siren = Siren(\n","        in_features = in_features,\n","        out_features = out_features,\n","        hidden_features = hidden_features, \n","        hidden_layers = hidden_layers,\n","        outermost_linear=True)\n","    img_siren.cuda()\n","    return img_siren"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUbFJigcoIub","executionInfo":{"status":"ok","timestamp":1601714335524,"user_tz":-120,"elapsed":1713,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def get_information_model(model):\n","    model = model.to(device)\n","\n","    numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n","    print(model)\n","    print(sum(numel_list), numel_list)\n","\n","    params_to_update = model.parameters()\n","    print(\"Params to learn:\")\n","    if feature_extract:\n","        params_to_update = []\n","        for name,param in model.named_parameters():\n","            if param.requires_grad == True:\n","                params_to_update.append(param)\n","                print(\"\\t\",name)\n","    else:\n","        for name,param in model.named_parameters():\n","            if param.requires_grad == True:\n","                print(\"\\t\",name)\n","    pass"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qmMEVQfdnOK0"},"source":["### Trainining Loop: Show Image Estimate Progression"]},{"cell_type":"code","metadata":{"id":"IfO1Yw9sFIjU","executionInfo":{"status":"ok","timestamp":1601714336143,"user_tz":-120,"elapsed":2322,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def show_images(model_output, coords):\n","    img_grad = gradient(model_output, coords)\n","    img_laplacian = laplace(model_output, coords)\n","\n","    fig, axes = plt.subplots(1,3, figsize=(18,6))\n","    axes[0].imshow(model_output.cpu().view(sidelength, sidelength).detach().numpy())\n","    axes[1].imshow(img_grad.norm(dim=-1).cpu().view(sidelength, sidelength).detach().numpy())\n","    axes[2].imshow(img_laplacian.cpu().view(sidelength, sidelength).detach().numpy())\n","    plt.show()\n","    pass\n","\n","def basic_traininig_loop(optimizer, criterion, model, model_input, ground_truth, total_steps, steps_til_summary = 10):\n","    \n","    train_acc_history = [] # val_acc_history = []\n","    train_loss_history = [] # val_loss_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    model.train()  # Set model to training mode\n","\n","    for step in range(total_steps):\n","        # print('Epoch {}/{}'.format(step, total_steps - 1))\n","        # print('-' * 10)\n","\n","        model_output, coords = model(model_input)\n","        loss = criterion(model_output, ground_truth)  \n","        # loss = ((model_output - ground_truth)**2).mean()\n","    \n","        if not step % steps_til_summary:\n","            print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","            show_images(model_output, coords)\n","            pass\n","        \n","        train_loss_history.append(loss)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        pass\n","    \n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    # create history as python dictionary\n","    keys_history_list = \"train_loss\".split(\",\")\n","    values_history_list = [train_loss_history]\n","\n","    history = dict(zip(keys_history_list, values_history_list))\n","\n","    return model, history"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-un2QhR5nXmn"},"source":["### Plane Training Loop"]},{"cell_type":"code","metadata":{"id":"eFniZVE-SaKm","executionInfo":{"status":"ok","timestamp":1601714336144,"user_tz":-120,"elapsed":2314,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def plane_traininig_loop(optimizer, criterion, model, model_input, ground_truth, total_steps, verbose = 0):\n","    \n","    train_acc_history = [] # val_acc_history = []\n","    train_loss_history = [] # val_loss_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    model.train()  # Set model to training mode\n","\n","    phase = 'train'\n","    for step in range(total_steps):\n","        if verbose == 1:\n","            print('Epoch {}/{}'.format(step, total_steps - 1))\n","            print('-' * 10)\n","\n","        model_output, coords = model(model_input)    \n","        loss = criterion(model_output, ground_truth)\n","        # loss = ((model_output - ground_truth)**2).mean()\n","        \n","        if verbose == 1:\n","            print('{} Loss: {:.4f}'.format(phase, loss))\n","        train_loss_history.append(loss)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","        pass\n","    \n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    # create history as python dictionary\n","    keys_history_list = \"train_loss\".split(\",\")\n","    values_history_list = [train_loss_history]\n","\n","    history = dict(zip(keys_history_list, values_history_list))\n","\n","    return model, history"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sLX5vsuDX7f"},"source":["### Training Loop: Run through a whole set of images"]},{"cell_type":"code","metadata":{"id":"9TUkmxc_DYmN","executionInfo":{"status":"ok","timestamp":1601714336145,"user_tz":-120,"elapsed":2307,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def a_training_loop(images, first_image_pos, last_image_pos, sidelength = 128, lr = 1e-4, total_steps = 500, verbose = 0):\n","    records_list = []\n","    for _, image_path in enumerate(images[first_image_pos:last_image_pos]):\n","\n","        # Create a DataLoader Instance for current image to be fitted\n","        # -------------------------------------------------------------------- #\n","        image = ImageFitting(\n","            sidelength,\n","            image_path = image_path)\n","        dataloader = DataLoader(image,\n","            batch_size=1,\n","            pin_memory=True,\n","            num_workers=0)\n","\n","        img_siren = get_model(\n","            in_features = in_features,\n","            out_features = out_features,\n","            hidden_features = sidelength,\n","            hidden_layers = hidden_layers)\n","\n","        # Establish Number of steps, criterion, and loss function\n","        # -------------------------------------------------------------------- #\n","        # total_steps = 500 \n","        # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","\n","        criterion = nn.MSELoss()\n","        optim = torch.optim.Adam(lr=lr, params=img_siren.parameters())\n","\n","        model_input, ground_truth = next(iter(dataloader))\n","        model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","        # Proceed with training\n","        # -------------------------------------------------------------------- #\n","        start = time.time()\n","        # model, history = basic_traininig_loop(\n","        model, history = plane_traininig_loop(\n","            optimizer = optim,\n","            criterion = criterion,\n","            model = img_siren,\n","            model_input = model_input,\n","            ground_truth = ground_truth,\n","            # total_steps = total_steps, steps_til_summary = steps_til_summary)\n","            total_steps = total_steps)\n","        stop = time.time()\n","\n","        # times = (stop - start) * 1000\n","        times = (stop - start)\n","        if verbose == 1:\n","            print('-' * 40)\n","            # print('Run time takes %d miliseconds' % times) # print('Run time takes %.3f seconds' % times)\n","            print('Training complete in {:.0f}m {:.0f}s {:.0f}ms'\n","                .format(times // 60, times % 60, (times - int((times % 60))) * 1000))\n","\n","        # Save results for current trained image\n","        # -------------------------------------------------------------------- #\n","        image_name = os.path.basename(image_path)\n","        last_loss_train = history['train_loss'][-1]\n","        a_record = [image_name, last_loss_train.item(), times]\n","\n","        records_list.append(a_record)\n","        pass\n","    return model, history, records_list"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0sXMd_Sa3Xw","executionInfo":{"status":"ok","timestamp":1601714336146,"user_tz":-120,"elapsed":2299,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def run_over_images(num_trials, images, first_image_pos, last_image_pos, sidelength = 128, lr = 1e-4, total_steps = 500):\n","    df, tmp_df = None, None\n","    for ii, a_trial in enumerate(range(num_trials)):\n","        start = time.time()\n","\n","        model, history, records = a_training_loop(images, first_image_pos, last_image_pos, sidelength = sidelength, lr = 1e-4, total_steps = 500)\n","\n","        stop = time.time()\n","        times = (stop - start)\n","        print('-' * 40)\n","        print('[Trial no.{:.0f}] [Outer Loop] Training complete in {:.0f}m {:.0f}s {:.0f}ms'\n","            .format(a_trial, times // 60, times % 60, (times - int((times % 60))) * 1000))\n","    \n","    \n","        if df is None:\n","            columns = \"image,train_loss,time\".split(\",\")\n","            df = pd.DataFrame(data = records,  columns = columns, index = [f\"trial no.{ii}\"] * len(records))\n","            df_show_curr_stats = df\n","        else:\n","            columns = \"image,train_loss,time\".split(\",\")\n","            tmp_df = pd.DataFrame(data = records,  columns = columns, index = [f\"trial no.{ii}\"] * len(records))\n","            df_show_curr_stats = tmp_df\n","            df = pd.concat([df, tmp_df])\n","    \n","        print(df_show_curr_stats[['train_loss']].describe().T)\n","        pass\n","    return df"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgE6UqEN-zhD"},"source":["## Siren Classes\n","\n","Now, we code up the sine layer, which will be the basic building block of SIREN. This is a much more concise implementation than the one in the main code, as here, we aren't concerned with the baseline comparisons."]},{"cell_type":"code","metadata":{"id":"RMSzO1kWxST0","executionInfo":{"status":"ok","timestamp":1601714336146,"user_tz":-120,"elapsed":2291,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["class ImageFitting(Dataset):\n","    def __init__(self, sidelength, image_path = None):\n","        super().__init__()\n","        if image_path is None:\n","            img = get_cameraman_tensor(sidelength)\n","        else:\n","            imag = Image.open(image_path)\n","            imag = imag.resize((sidelength, sidelength))\n","            # printImageAttributes(imag, image_path)\n","            # imag = np.asarray(imag)\n","            transform = Compose([\n","                Resize(sidelength),\n","                ToTensor(),\n","                Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","            ])\n","            img = transform(imag)\n","            pass\n","        \n","        # print(type(img))\n","        # print(img.size())\n","\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","        pass\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):    \n","        if idx > 0: raise IndexError\n","            \n","        return self.coords, self.pixels\n","    pass"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyOSBFpp-_f6","executionInfo":{"status":"ok","timestamp":1601714336147,"user_tz":-120,"elapsed":2283,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)      \n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    def forward_with_intermediate(self, input): \n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):\n","            if isinstance(layer, SineLayer):\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTJvYEF__NcU"},"source":["And finally, differential operators that allow us to leverage autograd to compute gradients, the laplacian, etc."]},{"cell_type":"code","metadata":{"id":"LnGeVmLq_M62","executionInfo":{"status":"ok","timestamp":1601714336148,"user_tz":-120,"elapsed":2275,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def laplace(y, x):\n","    grad = gradient(y, x)\n","    return divergence(grad, x)\n","\n","\n","def divergence(y, x):\n","    div = 0.\n","    for i in range(y.shape[-1]):\n","        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n","    return div\n","\n","\n","def gradient(y, x, grad_outputs=None):\n","    if grad_outputs is None:\n","        grad_outputs = torch.ones_like(y)\n","    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n","    return grad"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lptl7BN5-1qd"},"source":["## Experiments"]},{"cell_type":"markdown","metadata":{"id":"K-wC41Ve_yeW"},"source":["### Fitting an image\n","\n","First, let's simply fit that image!\n","\n","We seek to parameterize a greyscale image $f(x)$ with pixel coordinates $x$ with a SIREN $\\Phi(x)$.\n","\n","That is we seek the function $\\Phi$ such that: $\\mathcal{L}=\\int_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x}$ is minimized, in which $\\Omega$ is the domain of the image.\n","\n","We write a little datast that does nothing except calculating per-pixel coordinates:"]},{"cell_type":"markdown","metadata":{"id":"kxxukLZsAam-"},"source":["Let's instantiate the dataset and our Siren. As pixel coordinates are 2D, the siren has 2 input features, and since the image is grayscale, it has one output channel."]},{"cell_type":"code","metadata":{"id":"wON0Gy1PdmIQ","executionInfo":{"status":"ok","timestamp":1601714394937,"user_tz":-120,"elapsed":61053,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"b7f7319a-10bc-4ab4-8ca3-a157a81a03d1","colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["last_image_pos, first_image_pos = 0, 1\n","\n","df = run_over_images(\n","    num_trials = num_trials,\n","    images = [image_path],\n","    first_image_pos = 0,\n","    last_image_pos = 1,\n","    sidelength = sidelength,\n","    lr = learning_rate,\n","    total_steps = epochs)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["----------------------------------------\n","[Trial no.0] [Outer Loop] Training complete in 0m 14s 229ms\n","            count      mean  std  ...       50%       75%       max\n","train_loss    1.0  0.003881  NaN  ...  0.003881  0.003881  0.003881\n","\n","[1 rows x 8 columns]\n","----------------------------------------\n","[Trial no.1] [Outer Loop] Training complete in 0m 11s 17ms\n","            count      mean  std  ...       50%       75%       max\n","train_loss    1.0  0.002387  NaN  ...  0.002387  0.002387  0.002387\n","\n","[1 rows x 8 columns]\n","----------------------------------------\n","[Trial no.2] [Outer Loop] Training complete in 0m 11s 21ms\n","            count      mean  std  ...       50%       75%       max\n","train_loss    1.0  0.003673  NaN  ...  0.003673  0.003673  0.003673\n","\n","[1 rows x 8 columns]\n","----------------------------------------\n","[Trial no.3] [Outer Loop] Training complete in 0m 11s 23ms\n","            count      mean  std  ...       50%       75%       max\n","train_loss    1.0  0.002834  NaN  ...  0.002834  0.002834  0.002834\n","\n","[1 rows x 8 columns]\n","----------------------------------------\n","[Trial no.4] [Outer Loop] Training complete in 0m 11s 17ms\n","            count      mean  std  ...       50%       75%       max\n","train_loss    1.0  0.002437  NaN  ...  0.002437  0.002437  0.002437\n","\n","[1 rows x 8 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vsqdu8fXrm5B","executionInfo":{"status":"ok","timestamp":1601714394938,"user_tz":-120,"elapsed":61038,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"f3309550-2462-418c-a678-b63e151cfdfd","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>train_loss</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>trial no.0</th>\n","      <td>test001.png</td>\n","      <td>0.003881</td>\n","      <td>10.885334</td>\n","    </tr>\n","    <tr>\n","      <th>trial no.1</th>\n","      <td>test001.png</td>\n","      <td>0.002387</td>\n","      <td>10.867910</td>\n","    </tr>\n","    <tr>\n","      <th>trial no.2</th>\n","      <td>test001.png</td>\n","      <td>0.003673</td>\n","      <td>10.869817</td>\n","    </tr>\n","    <tr>\n","      <th>trial no.3</th>\n","      <td>test001.png</td>\n","      <td>0.002834</td>\n","      <td>10.872827</td>\n","    </tr>\n","    <tr>\n","      <th>trial no.4</th>\n","      <td>test001.png</td>\n","      <td>0.002437</td>\n","      <td>10.866791</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  image  train_loss       time\n","trial no.0  test001.png    0.003881  10.885334\n","trial no.1  test001.png    0.002387  10.867910\n","trial no.2  test001.png    0.003673  10.869817\n","trial no.3  test001.png    0.002834  10.872827\n","trial no.4  test001.png    0.002437  10.866791"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"1g2GNXuhuXUZ","executionInfo":{"status":"ok","timestamp":1601714394938,"user_tz":-120,"elapsed":61025,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"af6076f4-7b58-4d2d-d325-6d34e66bd317","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["df.describe()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_loss</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.003042</td>\n","      <td>10.872536</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.000697</td>\n","      <td>0.007511</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.002387</td>\n","      <td>10.866791</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.002437</td>\n","      <td>10.867910</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.002834</td>\n","      <td>10.869817</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.003673</td>\n","      <td>10.872827</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.003881</td>\n","      <td>10.885334</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       train_loss       time\n","count    5.000000   5.000000\n","mean     0.003042  10.872536\n","std      0.000697   0.007511\n","min      0.002387  10.866791\n","25%      0.002437  10.867910\n","50%      0.002834  10.869817\n","75%      0.003673  10.872827\n","max      0.003881  10.885334"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"k5snm5SMLyhN","executionInfo":{"status":"ok","timestamp":1601714394940,"user_tz":-120,"elapsed":61016,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["tmp_df = df.copy()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ok1OufjKJ0p6","executionInfo":{"status":"ok","timestamp":1601714394940,"user_tz":-120,"elapsed":61007,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["num_images = last_image_pos - first_image_pos\n","sol = []\n","for ii in range(int(1)):\n","    indeces = np.arange(0, num_trials) * num_images + ii\n","    # print(indeces)\n","    ii_values = tmp_df[['train_loss']].iloc[indeces]['train_loss'].values\n","    ii_mean = np.mean(ii_values)\n","    sol.append([ii_mean])\n","    pass\n","\n","columns = \"train_loss\".split(\",\")\n","df = pd.DataFrame(data = sol,  columns = columns)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cl_npCbKltsO","executionInfo":{"status":"ok","timestamp":1601714394941,"user_tz":-120,"elapsed":60994,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"1719ef31-afc5-48b7-a8d3-52638ab32f77","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sol"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.003042292594909668]]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"VFuQ4Ppnvb-y","executionInfo":{"status":"error","timestamp":1601719872050,"user_tz":-120,"elapsed":642,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"869d9d23-d375-4359-9cd6-8bd0aabe327a","colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["boxplot = df.boxplot(column = ['train_loss'])"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-511792075568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboxplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"E1HCIsATyQA3","executionInfo":{"status":"error","timestamp":1601714394942,"user_tz":-120,"elapsed":60974,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"5454dd6d-8873-48a9-c654-df9fef16e344","colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["# hist = df.hist(column = ['train_loss'], bins = 10)\n","# ax = df[['train_loss']].plot.kde()\n","show_hist_kde_train_loss(bins = 10)"],"execution_count":31,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-7d740459dfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# hist = df.hist(column = ['train_loss'], bins = 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ax = df[['train_loss']].plot.kde()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_hist_kde_train_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-a9278877aacc>\u001b[0m in \u001b[0;36mshow_hist_kde_train_loss\u001b[0;34m(bins, fig_name, resample_from_hist)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# plot the real KDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KDE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`dataset` input should have multiple elements.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: `dataset` input should have multiple elements."]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"8t7yjXAbtLlF"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"Q5HPv4MQTLuZ"},"source":["### Compression Algorithms:\n","\n","- [zlib](http://www.zlib.net/)"]},{"cell_type":"markdown","metadata":{"id":"3XmvgkwENDdc"},"source":["### Tutorials:\n","- [Data To Fish](https://datatofish.com/)"]},{"cell_type":"markdown","metadata":{"id":"egnkME2pw0Jt"},"source":["### Statistics Topics:\n","\n","- [KDE](https://en.wikipedia.org/wiki/Kernel_density_estimation)\n","  - [Stack Overflow Example](https://stackoverflow.com/questions/53823349/how-can-you-create-a-kde-from-histogram-values-only)"]},{"cell_type":"markdown","metadata":{"id":"KLPW9SIbuuj8"},"source":["### Papers\n","\n","- [Siren](https://arxiv.org/abs/2006.09661)"]},{"cell_type":"markdown","metadata":{"id":"xfdxbBpMtOm0"},"source":["### Libraries\n","\n","- [Standard Python Library](https://docs.python.org/3/library/)\n","- [Pillow Lib](https://pillow.readthedocs.io/en/stable/index.html)\n","- [PyTorch Lib](https://pytorch.org/)\n","- [Pandas Lib](https://pandas.pydata.org/pandas-docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"W0D9eAUmu2jH"},"source":["## Citations\n","\n","@misc{sitzmann2020implicit,\n","    title={Implicit Neural Representations with Periodic Activation Functions},\n","    author={Vincent Sitzmann and Julien N. P. Martel and Alexander W. Bergman and David B. Lindell and Gordon Wetzstein},\n","    year={2020},\n","    eprint={2006.09661},\n","    archivePrefix={arXiv},\n","    primaryClass={cs.CV}\n","}"]}]}