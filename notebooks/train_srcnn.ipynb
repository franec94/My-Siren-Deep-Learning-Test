{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAtD6KGyt0M2"
      },
      "source": [
        "import torch\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import h5py\n",
        "import srcnn\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.utils import save_image\n",
        "matplotlib.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dataset module\n",
        "class SRCNNDataset(Dataset):\n",
        "    def __init__(self, image_data, labels):\n",
        "        self.image_data = image_data\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return (len(self.image_data))\n",
        "    def __getitem__(self, index):\n",
        "        image = self.image_data[index]\n",
        "        label = self.labels[index]\n",
        "        return (\n",
        "            torch.tensor(image, dtype=torch.float),\n",
        "            torch.tensor(label, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# learning parameters\n",
        "batch_size = 64 # batch size, reduce if facing OOM error\n",
        "epochs = 100 # number of epochs to train the SRCNN model for\n",
        "lr = 0.001 # the learning rate\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 33, 33\n",
        "out_rows, out_cols = 33, 33"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = h5py.File('../input/train_mscale.h5')\n",
        "# `in_train` has shape (21884, 33, 33, 1) which corresponds to\n",
        "# 21884 image patches of 33 pixels height & width and 1 color channel\n",
        "in_train = file['data'][:] # the training data\n",
        "out_train = file['label'][:] # the training labels\n",
        "file.close()\n",
        "# change the values to float32\n",
        "in_train = in_train.astype('float32')\n",
        "out_train = out_train.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, x_val, y_train, y_val) = train_test_split(in_train, out_train, test_size=0.25)\n",
        "print('Training samples: ', x_train.shape[0])\n",
        "print('Validation samples: ', x_val.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train and validation data\n",
        "train_data = SRCNNDataset(x_train, y_train)\n",
        "val_data = SRCNNDataset(x_val, y_val)\n",
        "# train and validation loaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize the model\n",
        "print('Computation device: ', device)\n",
        "model = srcnn.SRCNN().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# loss function \n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def psnr(label, outputs, max_val=1.):\n",
        "    \"\"\"\n",
        "    Compute Peak Signal to Noise Ratio (the higher the better).\n",
        "    PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n",
        "    https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition\n",
        "    First we need to convert torch tensors to NumPy operable.\n",
        "    \"\"\"\n",
        "    label = label.cpu().detach().numpy()\n",
        "    outputs = outputs.cpu().detach().numpy()\n",
        "    img_diff = outputs - label\n",
        "    rmse = math.sqrt(np.mean((img_diff) ** 2))\n",
        "    if rmse == 0:\n",
        "        return 100\n",
        "    else:\n",
        "        PSNR = 20 * math.log10(max_val / rmse)\n",
        "        return PSNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, dataloader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_psnr = 0.0\n",
        "    for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
        "        image_data = data[0].to(device)\n",
        "        label = data[1].to(device)\n",
        "        \n",
        "        # zero grad the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image_data)\n",
        "        loss = criterion(outputs, label)\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        # add loss of each item (total items in a batch = batch size)\n",
        "        running_loss += loss.item()\n",
        "        # calculate batch psnr (once every `batch_size` iterations)\n",
        "        batch_psnr =  psnr(label, outputs)\n",
        "        running_psnr += batch_psnr\n",
        "    final_loss = running_loss/len(dataloader.dataset)\n",
        "    final_psnr = running_psnr/int(len(train_data)/dataloader.batch_size)\n",
        "    return final_loss, final_psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, dataloader, epoch):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_psnr = 0.0\n",
        "    with torch.no_grad():\n",
        "        for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
        "            image_data = data[0].to(device)\n",
        "            label = data[1].to(device)\n",
        "            \n",
        "            outputs = model(image_data)\n",
        "            loss = criterion(outputs, label)\n",
        "            # add loss of each item (total items in a batch = batch size) \n",
        "            running_loss += loss.item()\n",
        "            # calculate batch psnr (once every `batch_size` iterations)\n",
        "            batch_psnr = psnr(label, outputs)\n",
        "            running_psnr += batch_psnr\n",
        "        outputs = outputs.cpu()\n",
        "        save_image(outputs, f\"../outputs/val_sr{epoch}.png\")\n",
        "    final_loss = running_loss/len(dataloader.dataset)\n",
        "    final_psnr = running_psnr/int(len(train_data)/dataloader.batch_size)\n",
        "    return final_loss, final_psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss, val_loss = [], []\n",
        "train_psnr, val_psnr = [], []\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_psnr = train(model, train_loader)\n",
        "    val_epoch_loss, val_epoch_psnr = validate(model, val_loader, epoch)\n",
        "    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n",
        "    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_psnr.append(train_epoch_psnr)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_psnr.append(val_epoch_psnr)\n",
        "end = time.time()\n",
        "print(f\"Finished training in: {((end-start)/60):.3f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validataion loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('../outputs/loss.png')\n",
        "plt.show()\n",
        "# psnr plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_psnr, color='green', label='train PSNR dB')\n",
        "plt.plot(val_psnr, color='blue', label='validataion PSNR dB')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('PSNR (dB)')\n",
        "plt.legend()\n",
        "plt.savefig('../outputs/psnr.png')\n",
        "plt.show()\n",
        "# save the model to disk\n",
        "print('Saving model...')\n",
        "torch.save(model.state_dict(), '../outputs/model.pth')"
      ]
    }
  ]
}