{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAtD6KGyt0M2"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import os\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dataset module\n",
        "class SirenDataset(Dataset):\n",
        "    def __init__(self, image_data, labels):\n",
        "        self.image_data = image_data\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return (len(self.image_data))\n",
        "    def __getitem__(self, index):\n",
        "        image = self.image_data[index]\n",
        "        label = self.labels[index]\n",
        "        return (\n",
        "            torch.tensor(image, dtype=torch.float),\n",
        "            torch.tensor(label, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SineLayer(nn.Module):\n",
        "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
        "    \n",
        "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
        "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
        "    # hyperparameter.\n",
        "    \n",
        "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
        "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
        "    \n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        \n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "        \n",
        "        self.init_weights()\n",
        "    \n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features, \n",
        "                                             1 / self.in_features)      \n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "    \n",
        "    def forward_with_intermediate(self, input): \n",
        "        # For visualization of activation distributions\n",
        "        intermediate = self.omega_0 * self.linear(input)\n",
        "        return torch.sin(intermediate), intermediate\n",
        "    \n",
        "    \n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
        "                 first_omega_0=30, hidden_omega_0=30.):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features, \n",
        "                                  is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear(hidden_features, out_features)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "                \n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features, \n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    \n",
        "    def forward(self, coords):\n",
        "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "        output = self.net(coords)\n",
        "        return output, coords        \n",
        "\n",
        "    def forward_with_activations(self, coords, retain_grad=False):\n",
        "        '''Returns not only model output, but also intermediate activations.\n",
        "        Only used for visualizing activations later!'''\n",
        "        activations = OrderedDict()\n",
        "\n",
        "        activation_count = 0\n",
        "        x = coords.clone().detach().requires_grad_(True)\n",
        "        activations['input'] = x\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, SineLayer):\n",
        "                x, intermed = layer.forward_with_intermediate(x)\n",
        "                \n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    intermed.retain_grad()\n",
        "                    \n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                activation_count += 1\n",
        "            else: \n",
        "                x = layer(x)\n",
        "                \n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    \n",
        "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "            activation_count += 1\n",
        "\n",
        "        return activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize the model\n",
        "print('Computation device: ', device)\n",
        "model = Siren(\n",
        "    in_features = 2,\n",
        "    hidden_features 256,\n",
        "    hidden_layers = 3,\n",
        "    out_features = 1,\n",
        "    outermost_linear = True, \n",
        "    first_omega_0 = 30,\n",
        "    hidden_omega_0 = 30.\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load('../outputs/model.pth'))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_paths = glob.glob('../input/bicubic_2x/*')\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    test_image_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = image.reshape(image.shape[0], image.shape[1], 1)\n",
        "    cv2.imwrite(f\"../outputs/test_{test_image_name}.png\", image)\n",
        "    image = image / 255. # normalize the pixel values\n",
        "    cv2.imshow('Greyscale image', image)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "        image = torch.tensor(image, dtype=torch.float).to(device)\n",
        "        image = image.unsqueeze(0)\n",
        "        outputs = model(image)\n",
        "\n",
        "    outputs = outputs.cpu()\n",
        "    save_image(outputs, f\"../outputs/output_{test_image_name}.png\")\n",
        "    outputs = outputs.detach().numpy()\n",
        "    outputs = outputs.reshape(outputs.shape[2], outputs.shape[3], outputs.shape[1])\n",
        "    print(outputs.shape)\n",
        "    cv2.imshow('Output', outputs)\n",
        "    cv2.waitKey(0)"
      ]
    }
  ]
}