{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"grid_search_repeat_training_n_times_siren_model.ipynb","provenance":[{"file_id":"1ZArJ-GOzIormqOKDZsY7xvsJexTG5ZMA","timestamp":1601893506087},{"file_id":"10iiihBAmnIgiXKCHB18x4Hsj1KrinYlR","timestamp":1601889710506}],"collapsed_sections":["EFukXirLxgZ4","8egEoZ3VyAGE","rqQpMJIS3yW9","HBUeItRxyN7r","wj2TARNNxoe8","_AVkq71rz5vK","XbRtGUOBxtHm","xgTt3anWxva3","u0kNKO0A3QI5"],"authorship_tag":"ABX9TyMbqBofKjy+sbCkGDCl1VT9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EFukXirLxgZ4"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"wcls5ysnvDcT","executionInfo":{"status":"ok","timestamp":1601906600882,"user_tz":-120,"elapsed":1613,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["from __future__ import print_function\n","from __future__ import division\n","\n","# Standard Library, plus some Third Party Libraries\n","from pprint import pprint\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import copy\n","import datetime\n","import h5py\n","import math\n","import os\n","import random\n","import sys\n","import time\n","# import visdom\n","\n","# Data Science and Machine Learning Libraries\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('ggplot')\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.model_selection import ParameterGrid\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","# TorchVision\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n","from torchvision.utils import save_image\n","\n","import torchsummary"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"vimb6xTtv-pq","executionInfo":{"status":"ok","timestamp":1601906600884,"user_tz":-120,"elapsed":1584,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"8c2a791f-c12b-47ba-96b8-39729cd315c1","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print(\"Numpy Version: \", np.__version__)\n","print(\"Pandas Version: \", pd.__version__)\n","print(\"Sklearn Version: \", sklearn.__version__)\n","\n","print(\"PyTorch Version: \", torch.__version__)\n","print(\"Torchvision Version: \", torchvision.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Numpy Version:  1.18.5\n","Pandas Version:  1.1.2\n","Sklearn Version:  0.22.2.post1\n","PyTorch Version:  1.6.0+cu101\n","Torchvision Version:  0.7.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fRfHcru9xZOT","executionInfo":{"status":"ok","timestamp":1601906600885,"user_tz":-120,"elapsed":1574,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"52e4b93d-a94a-45f2-a715-27c3be0dca65","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive; drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LGJ38AHkxjRY"},"source":["## Setup Notebook"]},{"cell_type":"markdown","metadata":{"id":"8egEoZ3VyAGE"},"source":["### Set Seeds & Set Device"]},{"cell_type":"code","metadata":{"id":"5Q7Pt3XtxV37","executionInfo":{"status":"ok","timestamp":1601906600885,"user_tz":-120,"elapsed":1558,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zp_5CtTFxdnd","executionInfo":{"status":"ok","timestamp":1601906600886,"user_tz":-120,"elapsed":1548,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}},"outputId":"1240fa68-e8a5-4aff-8f7a-e12c3a7013b2","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Detect if we have a GPU available\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = (torch.device('cuda:0') if torch.cuda.is_available()\n","    else torch.device('gpu'))\n","print(f\"Training on device {device}.\")\n","print(f\"# cuda device: {torch.cuda.device_count()}\")\n","print(f\"Id current device: {torch.cuda.current_device()}\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Training on device cuda:0.\n","# cuda device: 1\n","Id current device: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rqQpMJIS3yW9"},"source":["### Globals"]},{"cell_type":"code","metadata":{"id":"LlaZagGU31e9","executionInfo":{"status":"ok","timestamp":1601906600886,"user_tz":-120,"elapsed":1531,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["image_path = \"/content/test001.png\"\n","\n","if os.path.exists('/content/outputs/') is False:\n","    os.makedirs('/content/outputs/')\n","elif os.path.isdir('/content/outputs/') is False:\n","    raise Exception(\"'/content/outputs/' should be output directory aimed at recording output results, from performed analysis!\")\n","\n","model_state_path = '/content/outputs/model.pth' # '../outputs/model.pth'\n","loss_image_path = '/content/outputs/loss.png' # '../outputs/loss.png'\n","psnr_image_path = '/content/outputs/psnr.png' # '../outputs/psnr.png'"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBUeItRxyN7r"},"source":["### Functions"]},{"cell_type":"code","metadata":{"id":"Ge1tYZlZyUZX","executionInfo":{"status":"ok","timestamp":1601906600887,"user_tz":-120,"elapsed":1514,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def get_mgrid(sidelen, dim=2):\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYMpi5pH1jwt","executionInfo":{"status":"ok","timestamp":1601906600888,"user_tz":-120,"elapsed":1498,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def psnr(label, outputs, max_val=1.):\n","    \"\"\"\n","    Compute Peak Signal to Noise Ratio (the higher the better).\n","    PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n","    https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition\n","    First we need to convert torch tensors to NumPy operable.\n","    \"\"\"\n","    label = label.cpu().detach().numpy()\n","    outputs = outputs.cpu().detach().numpy()\n","    img_diff = outputs - label\n","    rmse = math.sqrt(np.mean((img_diff) ** 2))\n","    if rmse == 0:\n","        return 100\n","    else:\n","        PSNR = 20 * math.log10(max_val / rmse)\n","        return PSNR"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lSIYG7tvQiPI"},"source":["#### Graphics"]},{"cell_type":"code","metadata":{"id":"-A65_RGYyYxg","executionInfo":{"status":"ok","timestamp":1601906600888,"user_tz":-120,"elapsed":1481,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def show_graphic_series_via_plot(\n","    series,\n","    image_path = \"graphic_series.png\", figsize=(10, 7),\n","    title = \"Series Graphic\",\n","    color='orange', label='data series',\n","    xlabel = 'pos', ylabel = 'value'\n","    ):\n","    plt.figure(figsize=figsize)\n","    plt.plot(series, color=color, label=label)\n","    # plt.plot(val_loss, color='red', label='validataion loss')\n","    plt.title(title)\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.legend()\n","    plt.savefig(image_path)\n","    plt.show()\n","    pass\n","\n","def show_graphic_series_via_ax(\n","    series,\n","    ax,\n","    image_path = \"graphic_series.png\", figsize=(10, 7),\n","    title = \"Series Graphic\",\n","    color='orange', label='data series',\n","    xlabel = 'pos', ylabel = 'value'\n","    \n","    ):\n","    ax.plot(series, color=color, label=label)\n","    ax.set_title(title)\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel(ylabel)\n","    plt.legend()\n","    pass\n","\n","def show_graphic_series(\n","    series,\n","    image_path = \"graphic_series.png\", figsize=(10, 7),\n","    title = \"Series Graphic\",\n","    color='orange', label='data series',\n","    xlabel = 'pos', ylabel = 'value',\n","    ax = None\n","    ):\n","    if ax is None:\n","        show_graphic_series_via_plot(\n","        series = series,\n","        image_path = image_path,\n","        title = title,\n","        figsize = figsize,\n","        color = color,\n","        label = label,\n","        xlabel = xlabel,\n","        ylabel = ylabel\n","    )\n","    else:\n","        show_graphic_series_via_ax(\n","        series = series,\n","        ax = ax,\n","        image_path = image_path,\n","        title = title,\n","        figsize = figsize,\n","        color = color,\n","        label = label,\n","        xlabel = xlabel,\n","        ylabel = ylabel\n","    )\n","    pass\n","\n","def plot_loss_graphic(loss_data, config):\n","    show_graphic_series(\n","        series = loss_data,\n","        image_path = config.image_path,\n","        title = config.title,\n","        figsize = config.figsize,\n","        color = config.color,\n","        label = config.label,\n","        xlabel = config.xlabel,\n","        ylabel = config.ylabel\n","    )\n","    pass\n","\n","def plot_psnr_graphic(psnr_data, config):\n","    show_graphic_series(\n","        series = psnr_data,\n","        image_path = config.image_path,\n","        title = config.title,\n","        figsize = config.figsize,\n","        color = config.color,\n","        label = config.label,\n","        xlabel = config.xlabel,\n","        ylabel = config.ylabel\n","    )\n","    pass"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLhcPRyQOcye","executionInfo":{"status":"ok","timestamp":1601906600889,"user_tz":-120,"elapsed":1466,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def plot_complex_graphics_series(s, title = 'Comples Series'):\n","    fig, axs = plt.subplots(3, figsize=(10, 10))\n","    fig.suptitle(title)\n","\n","    s.plot(kind='hist', ax = axs[0])\n","    s.plot(kind='kde', ax=axs[0], secondary_y=True, label = f'{title} - kde') # ax = s.plot.kde()\n","    axs[0].set_title(f'{title}: Hist - KDE')\n","    plt.legend()\n","\n","    s.plot(kind='box', ax = axs[1], label='line')\n","    axs[1].set_title(f'{title}: Box Plot')\n","\n","    s.plot(kind='bar', ax = axs[2])\n","    s.plot(kind='line', ax=axs[2], secondary_y=False, color = 'blue', label = f'{title} - line') \n","    axs[2].set_title(f'{title}: Line - Bars')\n","\n","    plt.legend()\n","    pass"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wj2TARNNxoe8"},"source":["### Classes"]},{"cell_type":"markdown","metadata":{"id":"_AVkq71rz5vK"},"source":["#### Config Class"]},{"cell_type":"code","metadata":{"id":"fh8mkchvz8Mr","executionInfo":{"status":"ok","timestamp":1601906600889,"user_tz":-120,"elapsed":1453,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["class Config:  \n","    def __init__(self, **kwargs):\n","      for key, value in kwargs.items():\n","          setattr(self, key, value)\n","      pass\n","    pass\n","\n","class PlotConfig(Config):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        pass\n","    pass"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbRtGUOBxtHm"},"source":["#### Data Loaders"]},{"cell_type":"code","metadata":{"id":"E9M9hTYxxqFc","executionInfo":{"status":"ok","timestamp":1601906601109,"user_tz":-120,"elapsed":1656,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# the dataset module\n","class SirenDataset(Dataset):\n","    def __init__(self, image_data, labels):\n","        self.image_data = image_data\n","        self.labels = labels\n","    def __len__(self):\n","        return (len(self.image_data))\n","    def __getitem__(self, index):\n","        image = self.image_data[index]\n","        label = self.labels[index]\n","        return (\n","            torch.tensor(image, dtype=torch.float),\n","            torch.tensor(label, dtype=torch.float))\n","\n","class ImageFitting(Dataset):\n","    def __init__(self, sidelength, image_path = None):\n","        super().__init__()\n","        if image_path is None:\n","            img = get_cameraman_tensor(sidelength)\n","        else:\n","            imag = Image.open(image_path)\n","            imag = imag.resize((sidelength, sidelength))\n","            # printImageAttributes(imag, image_path)\n","            # imag = np.asarray(imag)\n","            transform = Compose([\n","                Resize(sidelength),\n","                ToTensor(),\n","                Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","            ])\n","            img = transform(imag)\n","            pass\n","        \n","        # print(type(img))\n","        # print(img.size())\n","\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","        pass\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):    \n","        if idx > 0: raise IndexError\n","            \n","        return self.coords, self.pixels\n","    pass"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgTt3anWxva3"},"source":["#### Siren Architecture"]},{"cell_type":"code","metadata":{"id":"vLHTdGVHxzgV","executionInfo":{"status":"ok","timestamp":1601906601110,"user_tz":-120,"elapsed":1641,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)      \n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    def forward_with_intermediate(self, input): \n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):\n","            if isinstance(layer, SineLayer):\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwMtAs8yx6tA"},"source":["## Run Notebook"]},{"cell_type":"markdown","metadata":{"id":"KjAZX_8S6Myj"},"source":["### Training and Validation Functions"]},{"cell_type":"code","metadata":{"id":"hmnIgH-a46AQ","executionInfo":{"status":"ok","timestamp":1601906601110,"user_tz":-120,"elapsed":1629,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def train(model, dataloader, criterion, optimizer, train_size, device):\n","    model.train()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    # for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n","    for bi, data in enumerate(dataloader):\n","        image_data = data[0].to(device)\n","        label = data[1].to(device)\n","\n","        \n","        outputs, coords = model(image_data)    \n","        loss = criterion(outputs, label)\n","\n","        optimizer.zero_grad()\n","            \n","        # add loss of each item (total items in a batch = batch size)\n","        running_loss += loss.item()\n","        # calculate batch psnr (once every `batch_size` iterations)\n","        batch_psnr =  psnr(label, outputs)\n","        running_psnr += batch_psnr\n","\n","        loss.backward()\n","        optimizer.step()\n","        pass\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/int(train_size/dataloader.batch_size)\n","    return final_loss, final_psnr"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBOECvqo472b","executionInfo":{"status":"ok","timestamp":1601906601111,"user_tz":-120,"elapsed":1622,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def validate(model, dataloader, epoch, criterion, train_size):\n","    model.eval()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    with torch.no_grad():\n","        # for bi, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n","        for bi, data in enumerate(dataloader):\n","            image_data = data[0].to(device)\n","            label = data[1].to(device)\n","            \n","            outputs = model(image_data)\n","            loss = criterion(outputs, label)\n","            # add loss of each item (total items in a batch = batch size) \n","            running_loss += loss.item()\n","            # calculate batch psnr (once every `batch_size` iterations)\n","            batch_psnr = psnr(label, outputs)\n","            running_psnr += batch_psnr\n","        outputs = outputs.cpu()\n","        save_image(outputs, f\"../outputs/val_sr{epoch}.png\")\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/int(train_size/dataloader.batch_size)\n","    return final_loss, final_psnr"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZDCGeW2CuWM","executionInfo":{"status":"ok","timestamp":1601906601112,"user_tz":-120,"elapsed":1614,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def training_loop(model, train_loader, criterion, optimizer, train_size, device, epochs = 100, verbose = 0):\n","    train_loss, val_loss = [], []\n","    train_psnr, val_psnr = [], []\n","\n","    globaliter = 0\n","    start = time.time()\n","    for epoch in range(epochs):\n","        if verbose == 1:\n","            print(f\"Epoch {epoch + 1} of {epochs}\")\n","        train_epoch_loss, train_epoch_psnr = train(model, train_loader, criterion, optimizer, train_size, device)\n","        # val_epoch_loss, val_epoch_psnr = validate(model, val_loader, epoch)\n","\n","        if verbose == 1:\n","            print(f\"Train Loss: {train_epoch_loss:.3f} | Train PSNR: {train_epoch_psnr:.3f}\")\n","            # print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n","    \n","        globaliter += 1\n","\n","        train_loss.append(train_epoch_loss) # val_loss.append(val_epoch_loss)\n","        train_psnr.append(train_epoch_psnr) # val_psnr.append(val_epoch_psnr)\n","        pass\n","    end = time.time()\n","    if verbose == 1:\n","        print(f\"Finished training in: {((end-start)/60):.3f} minutes\")\n","\n","    history_keys_list = 'train_loss;train_psnr'.split(\";\")\n","    history_values_list = [np.array(series) for series in [train_loss, train_psnr]]\n","    \n","    history = dict(zip(history_keys_list, history_values_list))\n","    return model, history"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"SECyVd4pElCT","executionInfo":{"status":"ok","timestamp":1601906601112,"user_tz":-120,"elapsed":1606,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def repeat_training_loop_siren(n_times, config_loader, config_model, config_hyperparams, verbose = 0):\n","\n","    train_loss, val_loss = [], []\n","    train_psnr, val_psnr = [], []\n","\n","    for trial_no in range(n_times):\n","        if verbose == 1:\n","            print(f\"Trial no. {trial_no + 1} of {n_times}\")\n","        \n","        # Fetch Data\n","        train_data = ImageFitting(config_loader.sidelenght, config_loader.image_path)\n","        train_loader = DataLoader(train_data,\n","            batch_size=1,\n","            pin_memory=True,\n","            num_workers=0)\n","        \n","        # Create Siren Model\n","        model = Siren(\n","            in_features = config_model.in_features,\n","            hidden_features = config_model.hidden_features,\n","            hidden_layers = config_model.hidden_layers,\n","            out_features = config_model.out_features,\n","            outermost_linear = True, \n","            first_omega_0 = 30,\n","            hidden_omega_0 = 30.\n","        ).to(config_model.device)\n","        # print(model)\n","\n","        # Optimizer Initialization\n","        optimizer = optim.Adam(model.parameters(),\n","            lr=config_hyperparams.lr)\n","        # Loss Function Initialization\n","        criterion = nn.MSELoss()\n","\n","        # Run training\n","        model, history = training_loop( \n","            model, train_loader,\n","            criterion, optimizer,\n","            train_size = len(train_data),\n","            device = config_model.device,\n","            epochs = config_hyperparams.epochs, verbose = config_hyperparams.verbose)\n","        \n","        train_loss.append(history['train_loss'][-1])\n","        train_psnr.append(history['train_psnr'][-1])\n","        if verbose == 1:\n","            print(f\"Train Loss: {history['train_loss'][-1]:.3f} | Train PSNR: {history['train_psnr'][-1]:.3f}\")\n","        \n","    keys_list = 'train_loss;train_psnr'.split(\";\")\n","    values_list = [np.array(series) for series in [train_loss, train_psnr]]\n","\n","    history = dict(zip(keys_list, values_list))\n","    return history"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIPRpQNgWkaj","executionInfo":{"status":"ok","timestamp":1601906601113,"user_tz":-120,"elapsed":1599,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["def grid_search_training_loop(params_grid, config_hyperparams, verbose = 0):\n","    records_list, indeces = [], []\n","\n","    n = len(list(params_grid))\n","    start_grid_search = time.time()\n","\n","    gs_list = list(params_grid)\n","    for ii, params_dict in tqdm(enumerate(gs_list), total=int(len(gs_list))):\n","    # for ii, params_dict in enumerate(list(params_grid)):\n","\n","        if verbose == 1:\n","            if ii != 0: print()\n","            print(f\"[*] Grid Search no. {ii + 1} / {n}\")\n","            print(\"=\" * 40)\n","\n","        # Set Seeds for varying weights initialization\n","        torch.manual_seed(params_dict['seed'])\n","        np.random.seed(params_dict['seed'])\n","        random.seed(params_dict['seed'])\n","\n","        # Setup Configs objects for performing train\n","        config_train_loop.config_loader.sidelenght = params_dict['compression']\n","        config_train_loop.config_model.hidden_layers = params_dict['hidden_layers']\n","        \n","        # Repeat n-times same train varying the weights values under same seed\n","        start = time.time()\n","        history = repeat_training_loop_siren(\n","            n_times = config_train_loop.n_times,\n","            config_loader = config_train_loop.config_loader,\n","            config_model = config_train_loop.config_model,\n","            config_hyperparams = config_train_loop.config_hyperparams,\n","            verbose = config_train_loop.verbose)\n","\n","        stop = time.time()\n","        times = (stop - start) # times = (stop - start) * 1000\n","        if verbose == 1:\n","            # print('Run time takes %d miliseconds' % times) # print('Run time takes %.3f seconds' % times)\n","            print('[+][Grid Search no. {}] Training complete in {:.0f}m {:.0f}s {:.0f}ms'\n","                .format(ii+1, times // 60, times % 60, (times - int((times % 60))) * 1000))\n","            pass\n","        \n","        # Collect data and record these values\n","        image_name = os.path.basename(config_train_loop.config_loader.image_path)\n","        a_record = [image_name, int(params_dict['compression']), int(params_dict['hidden_layers']), int(params_dict['seed'])]\n","\n","        trial_ith_records = [a_record + list(a_item) for a_item in zip(history['train_loss'], history['train_psnr'])]\n","        records_list.extend(trial_ith_records)\n","        pass\n","\n","    stop_grid_search = time.time()\n","    times = (stop_grid_search - start_grid_search)\n","    if verbose == 1:\n","        # print('Run time takes %d miliseconds' % times) # print('Run time takes %.3f seconds' % times)\n","        print('[+][Grid Search no. {}] Training complete in {:.0f}m {:.0f}s {:.0f}ms'\n","            .format(ii+1, times // 60, times % 60, (times - int((times % 60))) * 1000))\n","\n","    # Create pandas dataframe with results from running grid search\n","    columns = \"image;compression_factor;hidden_layers;seed;train_loss;train_psnr\".split(\";\")\n","    df = pd.DataFrame(data = records_list, columns = columns)\n","    return df"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DutLTwrC6Q24"},"source":["### Fit Model"]},{"cell_type":"code","metadata":{"id":"13FhNyxnGk6v","executionInfo":{"status":"ok","timestamp":1601906601331,"user_tz":-120,"elapsed":1807,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# Hyper-params\n","# left here just for reference\n","lr = 1e-4\n","sidelenght = 256\n","\n","epochs = 100\n","n_times = 10"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMGzoKJwVDuX","executionInfo":{"status":"ok","timestamp":1601906601332,"user_tz":-120,"elapsed":1800,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# Config Objects - Default Case\n","config_loader = Config(\n","    sidelenght = sidelenght,\n","    image_path = image_path\n",")\n","\n","config_model = Config(\n","    in_features = 2,\n","    hidden_features = sidelenght,\n","    hidden_layers = 3,\n","    out_features = 1,\n","    device = device,\n",")\n","\n","config_hyperparams = Config(\n","    lr = 1e-4,\n","    epochs = epochs,\n","    verbose = 0\n",")\n","\n","config_train_loop = Config(\n","    n_times = n_times,\n","    config_loader = config_loader,\n","    config_model = config_model,\n","    config_hyperparams = config_hyperparams,\n","    verbose = 0\n",")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"qD86WOtvUNfa","executionInfo":{"status":"ok","timestamp":1601906601333,"user_tz":-120,"elapsed":1793,"user":{"displayName":"francesco chiarlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDAIKCUiswKi29zv4U3Oejsg31qDN02lqmfaV9=s64","userId":"17164257904618749375"}}},"source":["# Grid Search Hyper-params\n","grid = {\n","    \"compression\":  (8, 16, 32, 64, 128, 256)[:], # np.power(np.ones(9, dtype = np.int32) * 2, np.arange(0, 9))[4:6],\n","    \"hidden_layers\": (2, 3, 5, 7, 9, 11, 13, 15, 17)[:],\n","    \"seed\": (0, 17, 42, 101, 123, 314, 1234)[:],\n","}\n","params_grid = ParameterGrid(grid)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERILY9LOX-d3","outputId":"8436585b-f383-44a7-dff9-78ebf548707c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["history_df = grid_search_training_loop(params_grid, config_hyperparams, verbose = 0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 57%|█████▋    | 217/378 [23:21<17:27,  6.50s/it]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BdlU1pNkaBrx"},"source":["history_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKHwis10d0dV"},"source":["groups = history_df.groupby(by = [\"compression_factor\", \"hidden_layers\", \"seed\"])\n","groups.mean()[[\"train_loss\", \"train_psnr\"]].head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDD8s5rEeVwP"},"source":["groups = history_df.groupby(by = [\"compression_factor\", \"hidden_layers\"])\n","groups.mean()[[\"train_loss\", \"train_psnr\"]].head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FT_-ZATPlu_F"},"source":["history_df.to_csv('/content/history.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2L6OOi7JHpE"},"source":["image_name = os.path.basename(image_path)\n","image_name = os.path.splitext(image_name)\n","history_df.to_csv(f'/content/history_{image_name}.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u0kNKO0A3QI5"},"source":["### Show Graphics"]},{"cell_type":"code","metadata":{"id":"DKMVO0ciCCfn"},"source":["attributes = ['train_loss', 'train_psnr']\n","graphics_kind = ['line', 'box', 'kde']\n","\n","rows = list(range(len(attributes)))\n","columns = list(range(len(graphics_kind)))\n","\n","comb = list(itertools.product(attributes, graphics_kind))\n","comb_axes = list(itertools.product(rows, columns))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0D_ahjbWCFqu"},"source":["groups = history_df.groupby(by = [\"compression_factor\", \"hidden_layers\"])\n","# groups.mean()[[\"train_loss\", \"train_psnr\"]].head(5).T\n","groups.mean()[[\"train_loss\", \"train_psnr\"]].head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NM4Q9rxCCPE6"},"source":["groups = history_df.groupby(by = [\"compression_factor\", \"hidden_layers\"])\n","fig, axes = plt.subplots(len(rows), len(columns), figsize = (10, 6))\n","\n","for ii, (k, kind) in enumerate(comb):\n","    groups.mean()[[k]].plot(kind=kind, ax = axes[comb_axes[ii]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfihakS4wJt_"},"source":["## References\n","\n","- Pytorch Reference's Manual:\n"," - [torch.nn module](https://pytorch.org/docs/stable/nn.html)\n"," - [TensorBoard Support](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n"," - [Train Example](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#model-training-and-validation-code)\n","\n","- Initialization Topic (Papers):\n","  - [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) by X. Glorot & Y.Bengio, which lead to default Pytorch's weights initialization knwon as *Xavier initialization* algorithm or scheme\n"," -  [Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/abs/1901.09321) by Hongyi Zhang, Yann N. Dauphin, Tengyu Ma, whose works allows to *get rid off batch normalization layers* with a given particular NN Arch, to still be able to train a NN arch with meaningful and confident results or performance.\n","\n","- Activation Functions (Papers):\n","  - [Deep Learning using Rectified Linear Units (ReLU)](https://arxiv.org/pdf/1803.08375.pdf)\n","\n","- Datasets:\n","  - [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n","\n","- Regularization techniques (Papers):\n","  - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shif](https://arxiv.org/abs/1502.03167)\n","  - [Dropout: A Simple Way to Prevent Neural Networks from\n","Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n","\n","- Archs Types (Papers):\n","  - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n","  - [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n","  - [Highway Networks\n","](https://arxiv.org/pdf/1505.00387.pdf)\n","  - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)\n","\n","- Some Third Party useful Tutorials:\n"," - [Imagenet example](https://github.com/pytorch/examples/blob/master/imagenet/main.py#L327)\n"," - [Writing a better code with pytorch and einops](https://arogozhnikov.github.io/einops/pytorch-examples.html)\n"," - [Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric - MEDIUM](https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8)\n"," - [Pytorch Example](https://pythonprogramming.net/analysis-visualization-deep-learning-neural-network-pytorch/)\n","\n","- Books\n","  - [List of books for improving Pytorch knowledge](https://bookauthority.org/books/best-pytorch-books)\n","\n","- GitHub Projetcs:\n","  - [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric)\n","  - [Minetorch](https://github.com/minetorch/minetorch)\n","  - [Pierogi](https://github.com/nalepae/pierogi/)\n","  - [Visdom](https://github.com/facebookresearch/visdom#vismatplot)\n","\n","- Tensorboard:\n","  - [A Quickstart Guide to TensorBoard](https://towardsdatascience.com/a-quickstart-guide-to-tensorboard-fb1ade69bbcf)\n","  - [How to use Tensorboard with PyTorch in Google Colab](https://medium.com/looka-engineering/how-to-use-tensorboard-with-pytorch-in-google-colab-1f76a938bc34)\n","  - [VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n","\n","- Standard / Third Party Libraries:\n"," - [itertools ](https://docs.python.org/2/library/itertools.html#itertools.product)\n"," - [tqdm](https://pypi.org/project/tqdm/)"]}]}